{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% data import\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "from pathlib import Path\n",
    "import tensorboardX as tbx\n",
    "import os\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% import data and its processing\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    train_data = pd.read_csv('titanic/train.csv')\n",
    "    test_data = pd.read_csv('titanic/test.csv')\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def predict_test_data(model, test_data):\n",
    "    # model = use_gpu(model)\n",
    "    model.eval()\n",
    "    pred = np.round(model.pred(test_data.values))\n",
    "    pred = np.clip(pred, 0, 1)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def load_data(enable_labels=None):\n",
    "    train_data, test_data = import_data()\n",
    "    if not enable_labels:\n",
    "        labels = train_data.columns.value\n",
    "        train_x = labels.delete('Survived')\n",
    "        test_x = test_data[enable_labels]\n",
    "    else:\n",
    "        train_x = train_data[enable_labels]\n",
    "        test_x = test_data[enable_labels]\n",
    "    \n",
    "    train_y = train_data['Survived']\n",
    "    # test_y = test_data['Survived']\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def get_null_index(data):\n",
    "    null_index = data.isnull().any(axis=1)\n",
    "    return null_index\n",
    "\n",
    "\n",
    "def remove_nan_preprocess(train_x, train_y):\n",
    "    # とりあえず一つでも欠損していればそのデータは有効にしないようにする\n",
    "    # train_x = train_x.values\n",
    "    null_index = get_null_index(train_x)\n",
    "    train_x = train_x[~null_index]\n",
    "    train_y = train_y[~null_index]\n",
    "\n",
    "    MALE = .0\n",
    "    FEMALE = 1.0\n",
    "    Q = .0\n",
    "    S = 1.0\n",
    "    C = 2.0\n",
    "\n",
    "    train_x = train_x.replace('male', MALE)\n",
    "    train_x = train_x.replace('female', FEMALE)\n",
    "    train_x = train_x.replace('Q', Q)\n",
    "    train_x = train_x.replace('S', S)\n",
    "    train_x = train_x.replace('C', C)\n",
    "\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def preprocess_from_startup(train_x, train_y, mapping_order=False):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/startupsci/titanic-data-science-solutions\n",
    "    で記述されているようなデータの前処理を行う．\n",
    "    :param train_x:\n",
    "    :param train_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # カテゴリ変数のマッピングについては，survivedに対する相関係数順にするほうがいい気がする\n",
    "    # 均等性を考慮して，survivedの平均にマッピングするようにした\n",
    "    if mapping_order:\n",
    "        # Mrs > Miss > Master > Rare > Mr\n",
    "        gender_mapping = {'male': 0.188908, 'female': 0.742038}\n",
    "        title_mapping = {\"Mr\": 0.156673, \"Rare\": 0.347826, \"Master\": 0.575000, \n",
    "                         \"Miss\": 0.702703, \"Mrs\": 0.793651}\n",
    "        embarkation_mapping = {'S': 0.336957, 'C': 0.553571, 'Q': 0.389610}\n",
    "    else:\n",
    "        gender_mapping = {'male': 1, 'female': 0}\n",
    "        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        embarkation_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
    "\n",
    "    # Ticketsは，相関性が見込めないため入力データには適していない\n",
    "    # Cabinは，欠損データが多く，入力データには適していない\n",
    "    # PassengerIdは，survivedに対して相関がほぼ無いため，予測に適していない．\n",
    "    # -->これらは無効にする\n",
    "    train_x = train_x.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "    # Title(敬称)から，新たに特徴量を生成にする\n",
    "    train_x['Title'] = train_x.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "    # 少数の敬称は全てRareで統一する\n",
    "    train_x['Title'] = train_x['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\n",
    "                                           'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    # 変形しているだけで同じ意味のものを変換しておく\n",
    "    train_x['Title'] = train_x['Title'].replace('Mlle', 'Miss')\n",
    "    train_x['Title'] = train_x['Title'].replace('Ms', 'Miss')\n",
    "    train_x['Title'] = train_x['Title'].replace('Mme', 'Mrs')\n",
    "    train_x['Title'] = train_x['Title'].map(title_mapping)\n",
    "    train_x['Title'] = train_x['Title'].fillna(0)\n",
    "\n",
    "    # 性別を数値データにマッピング\n",
    "    train_x['Sex'] = train_x['Sex'].map(gender_mapping)\n",
    "\n",
    "    # Nameは使用しないためdrop\n",
    "    train_x = train_x.drop(['Name'], axis=1)\n",
    "\n",
    "    # Ageの欠損値を，genderとPclass別の中央値で補完する\n",
    "    for i in gender_mapping.values():\n",
    "        for j in range(0, 3):\n",
    "            current_df = train_x[np.logical_and(train_x['Sex'] == i, train_x['Pclass'] == j + 1)]\n",
    "            guess_df = current_df['Age'].dropna()\n",
    "            med = np.round(np.median(guess_df))\n",
    "            # print(current_df['Age'].isnull().va)\n",
    "            # train_x.loc[train_x[np.logical_and(train_x['Sex'] == i, train_x['Pclass'] == j + 1)]\n",
    "            #             ['Age'].isnull(), 'Age'] = med\n",
    "            train_x.loc[(train_x.Age.isnull()) & (train_x.Sex == i) & (train_x.Pclass == j + 1), \\\n",
    "                        'Age'] = med\n",
    "\n",
    "    # 年齢層を示す特徴量Agebandを定義\n",
    "    # train_x['AgeBand'] = pd.cut(train_x['Age'], 5)\n",
    "    # 特徴量FareBandを定義する\n",
    "    # train_x['FareBand'] = pd.cut(train_x['Fare'], 4)\n",
    "\n",
    "    # 家族の人数を示す特徴量FamilySizeを定義する\n",
    "    # Parchは正の相関，SibSpは負の相関をsurvivedに対して持つため，parch + sibspはどうなんだろ\n",
    "    # FamilySizeにしてしまったことで，相関係数の絶対値が小さくなるけど...\n",
    "    train_x['FamilySize'] = train_x['Parch'] + train_x['SibSp'] + 1\n",
    "\n",
    "    # 新たな特徴量IsAlone，Age*Classを定義\n",
    "    train_x['IsAlone'] = 0\n",
    "    train_x.loc[train_x['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    train_x['Age*Class'] = train_x.Age * train_x.Pclass\n",
    "    train_x = train_x.drop(['Age', 'Pclass'], axis=1)\n",
    "\n",
    "    # Embarkedの欠損値を，最頻値で補完する\n",
    "    train_x['Embarked'] = train_x['Embarked'].map(embarkation_mapping)\n",
    "    embarkation_mode = train_x['Embarked'].dropna().mode()[0]\n",
    "    train_x['Embarked'] =train_x['Embarked'].fillna(embarkation_mode)\n",
    "\n",
    "    # Fareの欠損値を，中央値で補完にする\n",
    "    train_x['Fare'] = train_x['Fare'].fillna(train_x['Fare'].median())\n",
    "    return train_x, train_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% prediction model\n"
    }
   },
   "outputs": [],
   "source": [
    "class LNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LNN, self).__init__()\n",
    "        DEPTH = 8\n",
    "        UNITS = 128\n",
    "        self.filename = 'LNN.pth'\n",
    "        self.fc_input = nn.Linear(input_dim, UNITS)\n",
    "        self.fc_array = nn.ModuleList([nn.Linear(UNITS, UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.fc_output = nn.Linear(UNITS, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        y = F.relu(self.fc_input(x))\n",
    "        for layer in self.fc_array:\n",
    "            y = F.dropout(y, training=self.training)\n",
    "            y = F.relu(layer(y))\n",
    "        y = F.dropout(y, training=self.training)\n",
    "        y = self.fc_output(y)\n",
    "        return y\n",
    "\n",
    "    def pred(self, x):\n",
    "        x = torch.from_numpy(x).float()\n",
    "        return self.forward(x).detach().numpy()\n",
    "\n",
    "    def save(self, save_path):\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(self.state_dict(), f'{save_path}/{self.filename}')\n",
    "\n",
    "    def load(self, load_path):\n",
    "        if os.path.isfile(f'{load_path}/{self.filename}'):\n",
    "            self.load_state_dict(torch.load(f'{load_path}/{self.filename}'))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class ResLNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ResLNN, self).__init__()\n",
    "        DEPTH = 8\n",
    "        UNITS = 128\n",
    "        self.filename = 'ResLNN.pth'\n",
    "        self.fc_input = nn.Linear(input_dim, UNITS)\n",
    "        self.fc_array = nn.ModuleList([nn.Linear(UNITS, UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.fc_output = nn.Linear(UNITS, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        y = F.relu(self.fc_input(x))\n",
    "        res = y\n",
    "        for n, layer in enumerate(self.fc_array):\n",
    "            y = F.dropout(y, training=self.training)\n",
    "            y = F.relu(layer(y))\n",
    "            if n % 2 == 2 and n != 0:\n",
    "                y += res\n",
    "                res = y\n",
    "        y = F.dropout(y, training=self.training)\n",
    "        y = self.fc_output(y)\n",
    "        return y\n",
    "\n",
    "    def pred(self, x):\n",
    "        x = torch.from_numpy(x).float()\n",
    "        return self.forward(x).detach().numpy()\n",
    "\n",
    "    def save(self, save_path):\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(self.state_dict(), f'{save_path}/{self.filename}')\n",
    "\n",
    "    def load(self, load_path):\n",
    "        if os.path.isfile(f'{load_path}/{self.filename}'):\n",
    "            self.load_state_dict(torch.load(f'{load_path}/{self.filename}'))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class BNLNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BNLNN, self).__init__()\n",
    "        DEPTH = 8\n",
    "        UNITS = 128\n",
    "        self.filename = 'BnLNN.pth'\n",
    "        self.fc_input = nn.Linear(input_dim, UNITS)\n",
    "        self.fc_array = nn.ModuleList([nn.Linear(UNITS, UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.bn_array = nn.ModuleList([nn.BatchNorm1d(UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.fc_output = nn.Linear(UNITS, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.fc_input(x))\n",
    "        for layer, bn in zip(self.fc_array, self.bn_array):\n",
    "            y = F.relu(bn(layer(y)))\n",
    "        y = self.fc_output(y)\n",
    "        return y\n",
    "\n",
    "    def pred(self, x):\n",
    "        x = torch.from_numpy(x).float()\n",
    "        pred = self.forward(x).detach().numpy()\n",
    "        pred = np.clip(np.round(pred), 0, 1)\n",
    "        return pred\n",
    "\n",
    "    def save(self, save_path):\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(self.state_dict(), f'{save_path}/{self.filename}')\n",
    "\n",
    "    def load(self, load_path):\n",
    "        if os.path.isfile(f'{load_path}/{self.filename}'):\n",
    "            self.load_state_dict(torch.load(f'{load_path}/{self.filename}'))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class ResBNLNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ResBNLNN, self).__init__()\n",
    "        DEPTH = 8\n",
    "        UNITS = 128\n",
    "        self.filename = 'ResBnLNN.pth'\n",
    "        self.fc_input = nn.Linear(input_dim, UNITS)\n",
    "        self.fc_array = nn.ModuleList([nn.Linear(UNITS, UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.bn_array = nn.ModuleList([nn.BatchNorm1d(UNITS) for _ in range(DEPTH - 2)])\n",
    "        self.fc_output = nn.Linear(UNITS, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.fc_input(x))\n",
    "        res = y\n",
    "        n = 0\n",
    "        for layer, bn in zip(self.fc_array, self.bn_array):\n",
    "            y = F.relu(bn(layer(y)))\n",
    "\n",
    "            if n % 2 == 2 and n != 0:\n",
    "                y += res\n",
    "                res = y\n",
    "            n += 1\n",
    "\n",
    "        y = self.fc_output(y)\n",
    "        return y\n",
    "\n",
    "    def pred(self, x):\n",
    "        x = torch.from_numpy(x).float()\n",
    "        pred = self.forward(x).detach().numpy()\n",
    "        pred = np.clip(np.round(pred), 0, 1)\n",
    "        return pred\n",
    "\n",
    "    def save(self, save_path):\n",
    "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(self.state_dict(), f'{save_path}/{self.filename}')\n",
    "\n",
    "    def load(self, load_path):\n",
    "        if os.path.isfile(f'{load_path}/{self.filename}'):\n",
    "            self.load_state_dict(torch.load(f'{load_path}/{self.filename}'))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% training\n"
    }
   },
   "outputs": [],
   "source": [
    "def use_gpu(e):\n",
    "    if torch.cuda.is_available():\n",
    "        return e.cuda()\n",
    "    return e\n",
    "\n",
    "\n",
    "def train(model, loss_func, optimizer, trX, trY):\n",
    "    x = Variable(trX, requires_grad=False)\n",
    "    y = Variable(trY, requires_grad=False)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model.forward(x)\n",
    "    loss = loss_func(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data\n",
    "\n",
    "\n",
    "def training(model, train_x, train_y, epochs, batch_size, save_path, eval_num=20, visualize_num=10):\n",
    "    train_ = data.TensorDataset(torch.from_numpy(train_x).float(),\n",
    "                                torch.from_numpy(train_y).float())\n",
    "    train_iter = torch.utils.data.DataLoader(train_, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    Path(f'{save_path}/total_loss/').mkdir(exist_ok=True, parents=True)\n",
    "    Path(f'{save_path}/metrics/').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    if model.load(save_path):\n",
    "        print(f'loaded existing model file {save_path}')\n",
    "    else:\n",
    "        print(f'not found existing model file {save_path}')\n",
    "\n",
    "    # SummaryWriterのインスタンス作成[ポイント2]\n",
    "    writer = tbx.SummaryWriter(f'{save_path}/')\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model = use_gpu(model)\n",
    "        model.train()\n",
    "        loss = 0\n",
    "        for i, train_data in enumerate(train_iter):\n",
    "            inputs, labels = train_data\n",
    "            inputs = use_gpu(inputs)\n",
    "            labels = use_gpu(labels)\n",
    "            loss += train(model, criterion, optimizer, inputs, labels)\n",
    "            \n",
    "            # tensorboard用log出力設定1[ポイント3]\n",
    "            writer.add_scalar(f'{save_path}/total_loss', loss, (epoch + 1) * batch_size)\n",
    "                    # tensorboard用log出力設定2[ポイント4]\n",
    "            # writer.add_scalars('data/loss',\n",
    "            #                {\n",
    "            #                    'x': model.losses[\"x\"],\n",
    "            #                    'y': model.losses[\"y\"],\n",
    "            #                    'w': model.losses[\"w\"],\n",
    "            #                    'h': model.losses[\"h\"],\n",
    "            #                    'conf': model.losses[\"conf\"],\n",
    "            #                    'cls': model.losses[\"cls\"]},\n",
    "            #                (epoch + 1) * batch_size)\n",
    "            \n",
    "\n",
    "        if epoch % visualize_num == 0:\n",
    "            print(f'epoch {epoch}: loss {loss / batch_size}')\n",
    "\n",
    "        if epoch % eval_num == 0:\n",
    "            model.cpu()\n",
    "            model.eval()\n",
    "            pred = model.pred(train_x)\n",
    "            y = np.reshape(train_y, pred.shape)\n",
    "            res = np.sum(np.abs(pred - y), dtype=np.float32)\n",
    "            ratio = 1.0 - res / len(train_y)\n",
    "            print(f'{epoch} test percentage {ratio}')\n",
    "\n",
    "            model.save(save_path)\n",
    "            print(f'save model at {save_path}')\n",
    "            \n",
    "            # tensorboard用log出力設定3[ポイント5]\n",
    "            writer.add_scalar(f'{save_path}/metrics', ratio, epoch)\n",
    "    # tensorboard用の値のjsonファイルへの保存[ポイント6]\n",
    "    writer.export_scalars_to_json(f\"{save_path}/all_scalars.json\")\n",
    "    # SummaryWriterのclose[ポイント7]\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def training_LNN():\n",
    "    train_x, train_y = load_data(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
    "    train_x, train_y = remove_nan_preprocess(train_x, train_y)\n",
    "    model = LNN(7, 1)\n",
    "    training(model, train_x.values, train_y.values, 1000, 128, 'models/lnn/', eval_num=5)\n",
    "\n",
    "\n",
    "def training_BNLNN():\n",
    "    train_x, train_y = load_data(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
    "    train_x, train_y = remove_nan_preprocess(train_x, train_y)\n",
    "    model = BNLNN(7, 1)\n",
    "    training(model, train_x.values, train_y.values, 500, 128, 'models/bnlnn/', eval_num=50)\n",
    "\n",
    "\n",
    "def training_LNN_startup():\n",
    "    train, test = import_data()\n",
    "    train_y = train[['Survived']]\n",
    "    train_x = train.drop(['Survived'], axis=1)\n",
    "    train_x, train_y = preprocess_from_startup(train_x, train_y)\n",
    "    model = LNN(9, 1)\n",
    "    training(model, train_x.values, train_y.values, 10000, 128, 'models/lnn_startup/', eval_num=50)\n",
    "\n",
    "\n",
    "def training_BNLNN_startup():\n",
    "    train, test = import_data()\n",
    "    train_y = train[['Survived']]\n",
    "    train_x = train.drop(['Survived'], axis=1)\n",
    "    train_x, train_y = preprocess_from_startup(train_x, train_y)\n",
    "    model = BNLNN(9, 1)\n",
    "    training(model, train_x.values, train_y.values, 10000, 128, 'models/bnlnn_startup/', eval_num=50)\n",
    "\n",
    "\n",
    "def training_ResLNN_startup():\n",
    "    train, test = import_data()\n",
    "    train_y = train[['Survived']]\n",
    "    train_x = train.drop(['Survived'], axis=1)\n",
    "    train_x, train_y = preprocess_from_startup(train_x, train_y)\n",
    "    model = ResLNN(9, 1)\n",
    "    training(model, train_x.values, train_y.values, 10000, 128, 'models/Reslnn_startup/', eval_num=50)\n",
    "\n",
    "\n",
    "def training_ResBNLNN_startup():\n",
    "    train, test = import_data()\n",
    "    train_y = train[['Survived']]\n",
    "    train_x = train.drop(['Survived'], axis=1)\n",
    "    train_x, train_y = preprocess_from_startup(train_x, train_y)\n",
    "    model = ResBNLNN(9, 1)\n",
    "    training(model, train_x.values, train_y.values, 30000, 64, 'models/Resbnlnn_startup/', eval_num=200)\n",
    "\n",
    "\n",
    "def training_ResBNLNN_order():\n",
    "    train, test = import_data()\n",
    "    train_y = train[['Survived']]\n",
    "    train_x = train.drop(['Survived'], axis=1)\n",
    "    train_x, train_y = preprocess_from_startup(train_x, train_y, mapping_order=True)\n",
    "    model = ResBNLNN(9, 1)\n",
    "    training(model, train_x.values, train_y.values, 30000, 64, 'models/Resbnlnn_order/', eval_num=200)\n",
    "    \n",
    "\n",
    "def testing_ResBNLNN_startup():\n",
    "    train, test = import_data()\n",
    "    processd_test, __ = preprocess_from_startup(test, None, mapping_order=True)\n",
    "    model = ResBNLNN(9, 1)\n",
    "    model.load('models/Resbnlnn_startup/')\n",
    "    pred = predict_test_data(model, processd_test)\n",
    "    submission_pred = test['PassengerId']\n",
    "    pred = pd.DataFrame(pred, columns=['Survived'])\n",
    "    submission_pred = pd.concat([submission_pred, pred], axis=1)\n",
    "    # submission_pred['Survived'] = pred\n",
    "    submission_pred.to_csv(f'models/Resbnlnn_startup/gender_submission.csv', index=False)\n",
    "    print(submission_pred)    \n",
    "\n",
    "    \n",
    "def testing_ResBNLNN_order():\n",
    "    train, test = import_data()\n",
    "    processd_test, __ = preprocess_from_startup(test, None, mapping_order=True)\n",
    "    model = ResBNLNN(9, 1)\n",
    "    model.load('models/Resbnlnn_order/')\n",
    "    pred = predict_test_data(model, processd_test)\n",
    "    submission_pred = test['PassengerId']\n",
    "    pred = pd.DataFrame(pred, columns=['Survived'])\n",
    "    submission_pred = pd.concat([submission_pred, pred], axis=1)\n",
    "    # submission_pred['Survived'] = pred\n",
    "    submission_pred.to_csv(f'models/Resbnlnn_order/gender_submission.csv', index=False)\n",
    "    print(submission_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%% data analysis\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Sex           0\nSibSp         0\nParch         0\nFare          0\nEmbarked      0\nTitle         0\nFamilySize    0\nIsAlone       0\nAge*Class     0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "train_data, test = import_data()\n",
    "train_y = train_data[['Survived']]\n",
    "train_x = train_data.drop(['Survived'], axis=1)\n",
    "train_x, train_y = preprocess_from_startup(train_x, train_y, mapping_order=True)\n",
    "\n",
    "train_x.isnull().sum()\n",
    "\n",
    "# concat_train = pd.concat([train_x, train_y], axis=1)\n",
    "# concat_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            Pclass       Sex       Age     SibSp     Parch      Fare  \\\nPclass    1.000000 -0.150826 -0.365902  0.065187  0.023666 -0.552893   \nSex      -0.150826  1.000000 -0.099037  0.106296  0.249543  0.182457   \nAge      -0.365902 -0.099037  1.000000 -0.307351 -0.187896  0.093143   \nSibSp     0.065187  0.106296 -0.307351  1.000000  0.383338  0.139860   \nParch     0.023666  0.249543 -0.187896  0.383338  1.000000  0.206624   \nFare     -0.552893  0.182457  0.093143  0.139860  0.206624  1.000000   \nEmbarked -0.297517  0.077391  0.042340 -0.062028 -0.004120  0.286416   \nSurvived -0.356462  0.536762 -0.082446 -0.015523  0.095265  0.266100   \n\n          Embarked  Survived  \nPclass   -0.297517 -0.356462  \nSex       0.077391  0.536762  \nAge       0.042340 -0.082446  \nSibSp    -0.062028 -0.015523  \nParch    -0.004120  0.095265  \nFare      0.286416  0.266100  \nEmbarked  1.000000  0.189657  \nSurvived  0.189657  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pclass</th>\n      <td>1.000000</td>\n      <td>-0.150826</td>\n      <td>-0.365902</td>\n      <td>0.065187</td>\n      <td>0.023666</td>\n      <td>-0.552893</td>\n      <td>-0.297517</td>\n      <td>-0.356462</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>-0.150826</td>\n      <td>1.000000</td>\n      <td>-0.099037</td>\n      <td>0.106296</td>\n      <td>0.249543</td>\n      <td>0.182457</td>\n      <td>0.077391</td>\n      <td>0.536762</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>-0.365902</td>\n      <td>-0.099037</td>\n      <td>1.000000</td>\n      <td>-0.307351</td>\n      <td>-0.187896</td>\n      <td>0.093143</td>\n      <td>0.042340</td>\n      <td>-0.082446</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.065187</td>\n      <td>0.106296</td>\n      <td>-0.307351</td>\n      <td>1.000000</td>\n      <td>0.383338</td>\n      <td>0.139860</td>\n      <td>-0.062028</td>\n      <td>-0.015523</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>0.023666</td>\n      <td>0.249543</td>\n      <td>-0.187896</td>\n      <td>0.383338</td>\n      <td>1.000000</td>\n      <td>0.206624</td>\n      <td>-0.004120</td>\n      <td>0.095265</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>-0.552893</td>\n      <td>0.182457</td>\n      <td>0.093143</td>\n      <td>0.139860</td>\n      <td>0.206624</td>\n      <td>1.000000</td>\n      <td>0.286416</td>\n      <td>0.266100</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>-0.297517</td>\n      <td>0.077391</td>\n      <td>0.042340</td>\n      <td>-0.062028</td>\n      <td>-0.004120</td>\n      <td>0.286416</td>\n      <td>1.000000</td>\n      <td>0.189657</td>\n    </tr>\n    <tr>\n      <th>Survived</th>\n      <td>-0.356462</td>\n      <td>0.536762</td>\n      <td>-0.082446</td>\n      <td>-0.015523</td>\n      <td>0.095265</td>\n      <td>0.266100</td>\n      <td>0.189657</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "# print('-' * 60)\n",
    "\n",
    "train_x, train_y = load_data(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
    "train_x, train_y = remove_nan_preprocess(train_x, train_y)\n",
    "concat_train = pd.concat([train_x, train_y], axis=1)\n",
    "concat_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "not found existing model file models/Resbnlnn_order/",
      "\n",
      "epoch 10: loss 0.03671640530228615",
      "\n",
      "epoch 20: loss 0.03115258365869522",
      "\n",
      "epoch 30: loss 0.02929472178220749",
      "\n",
      "epoch 40: loss 0.02903510443866253",
      "\n",
      "epoch 50: loss 0.029054753482341766",
      "\n",
      "epoch 60: loss 0.02746296301484108",
      "\n",
      "epoch 70: loss 0.027412936091423035",
      "\n",
      "epoch 80: loss 0.026154065504670143",
      "\n",
      "epoch 90: loss 0.026517363265156746",
      "\n",
      "epoch 100: loss 0.025973858311772346",
      "\n",
      "epoch 110: loss 0.025617824867367744",
      "\n",
      "epoch 120: loss 0.02497652918100357",
      "\n",
      "epoch 130: loss 0.02483658492565155",
      "\n",
      "epoch 140: loss 0.023808080703020096",
      "\n",
      "epoch 150: loss 0.02437490224838257",
      "\n",
      "epoch 160: loss 0.0234282948076725",
      "\n",
      "epoch 170: loss 0.022944306954741478",
      "\n",
      "epoch 180: loss 0.022991295903921127",
      "\n",
      "epoch 190: loss 0.022987404838204384",
      "\n",
      "epoch 200: loss 0.022873295471072197",
      "\n",
      "200 test percentage 0.7888148486547331",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 210: loss 0.021760761737823486",
      "\n",
      "epoch 220: loss 0.02309596911072731",
      "\n",
      "epoch 230: loss 0.021320363506674767",
      "\n",
      "epoch 240: loss 0.021481765434145927",
      "\n",
      "epoch 250: loss 0.020813902840018272",
      "\n",
      "epoch 260: loss 0.0206013061106205",
      "\n",
      "epoch 270: loss 0.021229658275842667",
      "\n",
      "epoch 280: loss 0.020398598164319992",
      "\n",
      "epoch 290: loss 0.019803903996944427",
      "\n",
      "epoch 300: loss 0.02007184363901615",
      "\n",
      "epoch 310: loss 0.019420327618718147",
      "\n",
      "epoch 320: loss 0.020872166380286217",
      "\n",
      "epoch 330: loss 0.018840041011571884",
      "\n",
      "epoch 340: loss 0.019052773714065552",
      "\n",
      "epoch 350: loss 0.018758192658424377",
      "\n",
      "epoch 360: loss 0.018262144178152084",
      "\n",
      "epoch 370: loss 0.01818547584116459",
      "\n",
      "epoch 380: loss 0.017858535051345825",
      "\n",
      "epoch 390: loss 0.019511358812451363",
      "\n",
      "epoch 400: loss 0.019350387156009674",
      "\n",
      "400 test percentage 0.8206507108026884",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 410: loss 0.018128616735339165",
      "\n",
      "epoch 420: loss 0.017809193581342697",
      "\n",
      "epoch 430: loss 0.017266079783439636",
      "\n",
      "epoch 440: loss 0.017279252409934998",
      "\n",
      "epoch 450: loss 0.01698530651628971",
      "\n",
      "epoch 460: loss 0.01759185642004013",
      "\n",
      "epoch 470: loss 0.01654702052474022",
      "\n",
      "epoch 480: loss 0.01565716043114662",
      "\n",
      "epoch 490: loss 0.015598691999912262",
      "\n",
      "epoch 500: loss 0.01726786233484745",
      "\n",
      "epoch 510: loss 0.01669907197356224",
      "\n",
      "epoch 520: loss 0.017815828323364258",
      "\n",
      "epoch 530: loss 0.01696913130581379",
      "\n",
      "epoch 540: loss 0.015879806131124496",
      "\n",
      "epoch 550: loss 0.015080324374139309",
      "\n",
      "epoch 560: loss 0.015925124287605286",
      "\n",
      "epoch 570: loss 0.01514589972794056",
      "\n",
      "epoch 580: loss 0.01676025800406933",
      "\n",
      "epoch 590: loss 0.015002306550741196",
      "\n",
      "epoch 600: loss 0.014604608528316021",
      "\n",
      "600 test percentage 0.8558541072070531",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 610: loss 0.01566431298851967",
      "\n",
      "epoch 620: loss 0.014364013448357582",
      "\n",
      "epoch 630: loss 0.016650980338454247",
      "\n",
      "epoch 640: loss 0.015334558673202991",
      "\n",
      "epoch 650: loss 0.014661088585853577",
      "\n",
      "epoch 660: loss 0.015185358002781868",
      "\n",
      "epoch 670: loss 0.015107695944607258",
      "\n",
      "epoch 680: loss 0.016758881509304047",
      "\n",
      "epoch 690: loss 0.01453221496194601",
      "\n",
      "epoch 700: loss 0.013424764387309551",
      "\n",
      "epoch 710: loss 0.014367755502462387",
      "\n",
      "epoch 720: loss 0.014122012071311474",
      "\n",
      "epoch 730: loss 0.01325580757111311",
      "\n",
      "epoch 740: loss 0.014847895130515099",
      "\n",
      "epoch 750: loss 0.014046123251318932",
      "\n",
      "epoch 760: loss 0.01452139113098383",
      "\n",
      "epoch 770: loss 0.01777862384915352",
      "\n",
      "epoch 780: loss 0.012824077159166336",
      "\n",
      "epoch 790: loss 0.01507442444562912",
      "\n",
      "epoch 800: loss 0.01330643706023693",
      "\n",
      "800 test percentage 0.8732943893415492",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 810: loss 0.014581475406885147",
      "\n",
      "epoch 820: loss 0.014345485717058182",
      "\n",
      "epoch 830: loss 0.013673782348632812",
      "\n",
      "epoch 840: loss 0.012550445273518562",
      "\n",
      "epoch 850: loss 0.013035498559474945",
      "\n",
      "epoch 860: loss 0.013266259804368019",
      "\n",
      "epoch 870: loss 0.013970873318612576",
      "\n",
      "epoch 880: loss 0.013498700223863125",
      "\n",
      "epoch 890: loss 0.01417568139731884",
      "\n",
      "epoch 900: loss 0.011896820738911629",
      "\n",
      "epoch 910: loss 0.012766982428729534",
      "\n",
      "epoch 920: loss 0.012623150832951069",
      "\n",
      "epoch 930: loss 0.012465841136872768",
      "\n",
      "epoch 940: loss 0.013646937906742096",
      "\n",
      "epoch 950: loss 0.013380570337176323",
      "\n",
      "epoch 960: loss 0.013187751173973083",
      "\n",
      "epoch 970: loss 0.014955133199691772",
      "\n",
      "epoch 980: loss 0.012798447161912918",
      "\n",
      "epoch 990: loss 0.012783674523234367",
      "\n",
      "epoch 1000: loss 0.013637691736221313",
      "\n",
      "1000 test percentage 0.8699561995689316",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 1010: loss 0.013271634466946125",
      "\n",
      "epoch 1020: loss 0.013323647901415825",
      "\n",
      "epoch 1030: loss 0.012733054347336292",
      "\n",
      "epoch 1040: loss 0.012534702196717262",
      "\n",
      "epoch 1050: loss 0.012464980594813824",
      "\n",
      "epoch 1060: loss 0.012595124542713165",
      "\n",
      "epoch 1070: loss 0.011650494299829006",
      "\n",
      "epoch 1080: loss 0.013812138698995113",
      "\n",
      "epoch 1090: loss 0.011442594230175018",
      "\n",
      "epoch 1100: loss 0.01168062537908554",
      "\n",
      "epoch 1110: loss 0.012380179017782211",
      "\n",
      "epoch 1120: loss 0.013492293655872345",
      "\n",
      "epoch 1130: loss 0.012929585762321949",
      "\n",
      "epoch 1140: loss 0.012241033837199211",
      "\n",
      "epoch 1150: loss 0.011120948009192944",
      "\n",
      "epoch 1160: loss 0.012019135989248753",
      "\n",
      "epoch 1170: loss 0.01238269917666912",
      "\n",
      "epoch 1180: loss 0.011255878955125809",
      "\n",
      "epoch 1190: loss 0.012371351942420006",
      "\n",
      "epoch 1200: loss 0.012870172038674355",
      "\n",
      "1200 test percentage 0.8964181936416027",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 1210: loss 0.012962408363819122",
      "\n",
      "epoch 1220: loss 0.011705892160534859",
      "\n",
      "epoch 1230: loss 0.01192166842520237",
      "\n",
      "epoch 1240: loss 0.011153492145240307",
      "\n",
      "epoch 1250: loss 0.011752751655876637",
      "\n",
      "epoch 1260: loss 0.013208509422838688",
      "\n",
      "epoch 1270: loss 0.011977487243711948",
      "\n",
      "epoch 1280: loss 0.011296939104795456",
      "\n",
      "epoch 1290: loss 0.011582525447010994",
      "\n",
      "epoch 1300: loss 0.011621540412306786",
      "\n",
      "epoch 1310: loss 0.010711044073104858",
      "\n",
      "epoch 1320: loss 0.012379885651171207",
      "\n",
      "epoch 1330: loss 0.011623702012002468",
      "\n",
      "epoch 1340: loss 0.011398009024560452",
      "\n",
      "epoch 1350: loss 0.011521236039698124",
      "\n",
      "epoch 1360: loss 0.011849459260702133",
      "\n",
      "epoch 1370: loss 0.010856864973902702",
      "\n",
      "epoch 1380: loss 0.010552008636295795",
      "\n",
      "epoch 1390: loss 0.010856926441192627",
      "\n",
      "epoch 1400: loss 0.011308042332530022",
      "\n",
      "1400 test percentage 0.896810127027107",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 1410: loss 0.010597115382552147",
      "\n",
      "epoch 1420: loss 0.01046279352158308",
      "\n",
      "epoch 1430: loss 0.01088537648320198",
      "\n",
      "epoch 1440: loss 0.011039159260690212",
      "\n",
      "epoch 1450: loss 0.010581566020846367",
      "\n",
      "epoch 1460: loss 0.010296795517206192",
      "\n",
      "epoch 1470: loss 0.010461067780852318",
      "\n",
      "epoch 1480: loss 0.010701308958232403",
      "\n",
      "epoch 1490: loss 0.012260540388524532",
      "\n",
      "epoch 1500: loss 0.01071726344525814",
      "\n",
      "epoch 1510: loss 0.011024526320397854",
      "\n",
      "epoch 1520: loss 0.012059884145855904",
      "\n",
      "epoch 1530: loss 0.010601256974041462",
      "\n",
      "epoch 1540: loss 0.010059942491352558",
      "\n",
      "epoch 1550: loss 0.010715522803366184",
      "\n",
      "epoch 1560: loss 0.011018598452210426",
      "\n",
      "epoch 1570: loss 0.010245658457279205",
      "\n",
      "epoch 1580: loss 0.010598124004900455",
      "\n",
      "epoch 1590: loss 0.010322670452296734",
      "\n",
      "epoch 1600: loss 0.010146420449018478",
      "\n",
      "1600 test percentage 0.9079814016083141",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 1610: loss 0.011494124308228493",
      "\n",
      "epoch 1620: loss 0.01089514885097742",
      "\n",
      "epoch 1630: loss 0.010035723447799683",
      "\n",
      "epoch 1640: loss 0.009922879748046398",
      "\n",
      "epoch 1650: loss 0.009339569136500359",
      "\n",
      "epoch 1660: loss 0.011488045565783978",
      "\n",
      "epoch 1670: loss 0.010688064619898796",
      "\n",
      "epoch 1680: loss 0.010927538387477398",
      "\n",
      "epoch 1690: loss 0.010817103087902069",
      "\n",
      "epoch 1700: loss 0.010173984803259373",
      "\n",
      "epoch 1710: loss 0.011530915275216103",
      "\n",
      "epoch 1720: loss 0.010525381192564964",
      "\n",
      "epoch 1730: loss 0.01100834272801876",
      "\n",
      "epoch 1740: loss 0.00942249596118927",
      "\n",
      "epoch 1750: loss 0.009235995821654797",
      "\n",
      "epoch 1760: loss 0.011285360902547836",
      "\n",
      "epoch 1770: loss 0.010573053732514381",
      "\n",
      "epoch 1780: loss 0.011587392538785934",
      "\n",
      "epoch 1790: loss 0.01006804034113884",
      "\n",
      "epoch 1800: loss 0.010199381969869137",
      "\n",
      "1800 test percentage 0.9161246628338506",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 1810: loss 0.010942085646092892",
      "\n",
      "epoch 1820: loss 0.011156206950545311",
      "\n",
      "epoch 1830: loss 0.01092113833874464",
      "\n",
      "epoch 1840: loss 0.009412888437509537",
      "\n",
      "epoch 1850: loss 0.009635386988520622",
      "\n",
      "epoch 1860: loss 0.00965344998985529",
      "\n",
      "epoch 1870: loss 0.009493594989180565",
      "\n",
      "epoch 1880: loss 0.011576004326343536",
      "\n",
      "epoch 1890: loss 0.009764522314071655",
      "\n",
      "epoch 1900: loss 0.010605116374790668",
      "\n",
      "epoch 1910: loss 0.009861067868769169",
      "\n",
      "epoch 1920: loss 0.01156560517847538",
      "\n",
      "epoch 1930: loss 0.009306296706199646",
      "\n",
      "epoch 1940: loss 0.01059418823570013",
      "\n",
      "epoch 1950: loss 0.01028496865183115",
      "\n",
      "epoch 1960: loss 0.009303527884185314",
      "\n",
      "epoch 1970: loss 0.01065068505704403",
      "\n",
      "epoch 1980: loss 0.009744379669427872",
      "\n",
      "epoch 1990: loss 0.009375617839396",
      "\n",
      "epoch 2000: loss 0.008694103918969631",
      "\n",
      "2000 test percentage 0.9192045406594154",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 2010: loss 0.010899201035499573",
      "\n",
      "epoch 2020: loss 0.008905106224119663",
      "\n",
      "epoch 2030: loss 0.009058715775609016",
      "\n",
      "epoch 2040: loss 0.009400955401360989",
      "\n",
      "epoch 2050: loss 0.00880749337375164",
      "\n",
      "epoch 2060: loss 0.010755157098174095",
      "\n",
      "epoch 2070: loss 0.010448134504258633",
      "\n",
      "epoch 2080: loss 0.011571922339498997",
      "\n",
      "epoch 2090: loss 0.009471798315644264",
      "\n",
      "epoch 2100: loss 0.00968514010310173",
      "\n",
      "epoch 2110: loss 0.009345387108623981",
      "\n",
      "epoch 2120: loss 0.008960956707596779",
      "\n",
      "epoch 2130: loss 0.008920898661017418",
      "\n",
      "epoch 2140: loss 0.009588303044438362",
      "\n",
      "epoch 2150: loss 0.008465999737381935",
      "\n",
      "epoch 2160: loss 0.009212681092321873",
      "\n",
      "epoch 2170: loss 0.009825882501900196",
      "\n",
      "epoch 2180: loss 0.010172314010560513",
      "\n",
      "epoch 2190: loss 0.011155919171869755",
      "\n",
      "epoch 2200: loss 0.009913502261042595",
      "\n",
      "2200 test percentage 0.9109375822022306",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 2210: loss 0.008223229087889194",
      "\n",
      "epoch 2220: loss 0.00934300385415554",
      "\n",
      "epoch 2230: loss 0.009186845272779465",
      "\n",
      "epoch 2240: loss 0.008281094953417778",
      "\n",
      "epoch 2250: loss 0.01032671146094799",
      "\n",
      "epoch 2260: loss 0.010713493451476097",
      "\n",
      "epoch 2270: loss 0.009430012665688992",
      "\n",
      "epoch 2280: loss 0.009290168061852455",
      "\n",
      "epoch 2290: loss 0.009176609106361866",
      "\n",
      "epoch 2300: loss 0.009377550333738327",
      "\n",
      "epoch 2310: loss 0.010854038409888744",
      "\n",
      "epoch 2320: loss 0.008517797105014324",
      "\n",
      "epoch 2330: loss 0.008985470980405807",
      "\n",
      "epoch 2340: loss 0.009257159195840359",
      "\n",
      "epoch 2350: loss 0.01025981456041336",
      "\n",
      "epoch 2360: loss 0.008609678596258163",
      "\n",
      "epoch 2370: loss 0.00999407097697258",
      "\n",
      "epoch 2380: loss 0.009113635867834091",
      "\n",
      "epoch 2390: loss 0.009201823733747005",
      "\n",
      "epoch 2400: loss 0.008444787934422493",
      "\n",
      "2400 test percentage 0.9246808875155637",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 2410: loss 0.01102029625326395",
      "\n",
      "epoch 2420: loss 0.009925920516252518",
      "\n",
      "epoch 2430: loss 0.008437392301857471",
      "\n",
      "epoch 2440: loss 0.009842879138886929",
      "\n",
      "epoch 2450: loss 0.00914368499070406",
      "\n",
      "epoch 2460: loss 0.009117821231484413",
      "\n",
      "epoch 2470: loss 0.009283660911023617",
      "\n",
      "epoch 2480: loss 0.00921347551047802",
      "\n",
      "epoch 2490: loss 0.009233939461410046",
      "\n",
      "epoch 2500: loss 0.0093116145581007",
      "\n",
      "epoch 2510: loss 0.00886339507997036",
      "\n",
      "epoch 2520: loss 0.009948556311428547",
      "\n",
      "epoch 2530: loss 0.008311936631798744",
      "\n",
      "epoch 2540: loss 0.008942395448684692",
      "\n",
      "epoch 2550: loss 0.008128358982503414",
      "\n",
      "epoch 2560: loss 0.008801223710179329",
      "\n",
      "epoch 2570: loss 0.008570130914449692",
      "\n",
      "epoch 2580: loss 0.008850913494825363",
      "\n",
      "epoch 2590: loss 0.008576832711696625",
      "\n",
      "epoch 2600: loss 0.00893469899892807",
      "\n",
      "2600 test percentage 0.921546927472424",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 2610: loss 0.008304217830300331",
      "\n",
      "epoch 2620: loss 0.009191234596073627",
      "\n",
      "epoch 2630: loss 0.008561061695218086",
      "\n",
      "epoch 2640: loss 0.007483999710530043",
      "\n",
      "epoch 2650: loss 0.008439709432423115",
      "\n",
      "epoch 2660: loss 0.009688851423561573",
      "\n",
      "epoch 2670: loss 0.008563182316720486",
      "\n",
      "epoch 2680: loss 0.010011052712798119",
      "\n",
      "epoch 2690: loss 0.008772747591137886",
      "\n",
      "epoch 2700: loss 0.009212094359099865",
      "\n",
      "epoch 2710: loss 0.007923773489892483",
      "\n",
      "epoch 2720: loss 0.00799030251801014",
      "\n",
      "epoch 2730: loss 0.008915767073631287",
      "\n",
      "epoch 2740: loss 0.008285382762551308",
      "\n",
      "epoch 2750: loss 0.009182976558804512",
      "\n",
      "epoch 2760: loss 0.008927480317652225",
      "\n",
      "epoch 2770: loss 0.009362609125673771",
      "\n",
      "epoch 2780: loss 0.008524276316165924",
      "\n",
      "epoch 2790: loss 0.008431840687990189",
      "\n",
      "epoch 2800: loss 0.008568448014557362",
      "\n",
      "2800 test percentage 0.9056725807061501",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 2810: loss 0.008471373468637466",
      "\n",
      "epoch 2820: loss 0.007989192381501198",
      "\n",
      "epoch 2830: loss 0.008650179952383041",
      "\n",
      "epoch 2840: loss 0.008751876652240753",
      "\n",
      "epoch 2850: loss 0.00802043080329895",
      "\n",
      "epoch 2860: loss 0.008797495625913143",
      "\n",
      "epoch 2870: loss 0.008759557269513607",
      "\n",
      "epoch 2880: loss 0.01029642391949892",
      "\n",
      "epoch 2890: loss 0.008173305541276932",
      "\n",
      "epoch 2900: loss 0.008698792196810246",
      "\n",
      "epoch 2910: loss 0.008285348303616047",
      "\n",
      "epoch 2920: loss 0.008590004406869411",
      "\n",
      "epoch 2930: loss 0.008764263242483139",
      "\n",
      "epoch 2940: loss 0.007742294110357761",
      "\n",
      "epoch 2950: loss 0.007905392907559872",
      "\n",
      "epoch 2960: loss 0.008816908113658428",
      "\n",
      "epoch 2970: loss 0.008207675069570541",
      "\n",
      "epoch 2980: loss 0.008075340650975704",
      "\n",
      "epoch 2990: loss 0.009297058917582035",
      "\n",
      "epoch 3000: loss 0.008243300020694733",
      "\n",
      "3000 test percentage 0.9276883588763065",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 3010: loss 0.007501596584916115",
      "\n",
      "epoch 3020: loss 0.008426409214735031",
      "\n",
      "epoch 3030: loss 0.008758129552006721",
      "\n",
      "epoch 3040: loss 0.009850149042904377",
      "\n",
      "epoch 3050: loss 0.008454696275293827",
      "\n",
      "epoch 3060: loss 0.008161081932485104",
      "\n",
      "epoch 3070: loss 0.008357465267181396",
      "\n",
      "epoch 3080: loss 0.008158741518855095",
      "\n",
      "epoch 3090: loss 0.007864009588956833",
      "\n",
      "epoch 3100: loss 0.007667753379791975",
      "\n",
      "epoch 3110: loss 0.008567532524466515",
      "\n",
      "epoch 3120: loss 0.008038142696022987",
      "\n",
      "epoch 3130: loss 0.008184700272977352",
      "\n",
      "epoch 3140: loss 0.009799796156585217",
      "\n",
      "epoch 3150: loss 0.00859324261546135",
      "\n",
      "epoch 3160: loss 0.007932226173579693",
      "\n",
      "epoch 3170: loss 0.007636474445462227",
      "\n",
      "epoch 3180: loss 0.00862317718565464",
      "\n",
      "epoch 3190: loss 0.0070426203310489655",
      "\n",
      "epoch 3200: loss 0.007941481657326221",
      "\n",
      "3200 test percentage 0.9297903127274262",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 3210: loss 0.007877228781580925",
      "\n",
      "epoch 3220: loss 0.008666270412504673",
      "\n",
      "epoch 3230: loss 0.008225887082517147",
      "\n",
      "epoch 3240: loss 0.008022082038223743",
      "\n",
      "epoch 3250: loss 0.007581271231174469",
      "\n",
      "epoch 3260: loss 0.00883470568805933",
      "\n",
      "epoch 3270: loss 0.007525295950472355",
      "\n",
      "epoch 3280: loss 0.0073011466301977634",
      "\n",
      "epoch 3290: loss 0.008782356046140194",
      "\n",
      "epoch 3300: loss 0.00786395464092493",
      "\n",
      "epoch 3310: loss 0.007968303747475147",
      "\n",
      "epoch 3320: loss 0.007945751771330833",
      "\n",
      "epoch 3330: loss 0.009248499758541584",
      "\n",
      "epoch 3340: loss 0.007023820653557777",
      "\n",
      "epoch 3350: loss 0.007969514466822147",
      "\n",
      "epoch 3360: loss 0.007510394789278507",
      "\n",
      "epoch 3370: loss 0.008872529491782188",
      "\n",
      "epoch 3380: loss 0.007344938348978758",
      "\n",
      "epoch 3390: loss 0.008391181007027626",
      "\n",
      "epoch 3400: loss 0.007180119398981333",
      "\n",
      "3400 test percentage 0.926235091940455",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 3410: loss 0.007073036395013332",
      "\n",
      "epoch 3420: loss 0.008544274605810642",
      "\n",
      "epoch 3430: loss 0.00833199918270111",
      "\n",
      "epoch 3440: loss 0.008761422708630562",
      "\n",
      "epoch 3450: loss 0.007855932228267193",
      "\n",
      "epoch 3460: loss 0.007980437017977238",
      "\n",
      "epoch 3470: loss 0.008657759055495262",
      "\n",
      "epoch 3480: loss 0.008546070195734501",
      "\n",
      "epoch 3490: loss 0.0073513756506145",
      "\n",
      "epoch 3500: loss 0.008139586076140404",
      "\n",
      "epoch 3510: loss 0.006967836990952492",
      "\n",
      "epoch 3520: loss 0.007863668724894524",
      "\n",
      "epoch 3530: loss 0.007272025570273399",
      "\n",
      "epoch 3540: loss 0.007304182276129723",
      "\n",
      "epoch 3550: loss 0.008544348180294037",
      "\n",
      "epoch 3560: loss 0.007951682433485985",
      "\n",
      "epoch 3570: loss 0.008424499072134495",
      "\n",
      "epoch 3580: loss 0.008116505108773708",
      "\n",
      "epoch 3590: loss 0.007255272939801216",
      "\n",
      "epoch 3600: loss 0.009386347606778145",
      "\n",
      "3600 test percentage 0.9153738824606744",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 3610: loss 0.008766521699726582",
      "\n",
      "epoch 3620: loss 0.007165791466832161",
      "\n",
      "epoch 3630: loss 0.00798007845878601",
      "\n",
      "epoch 3640: loss 0.009593592956662178",
      "\n",
      "epoch 3650: loss 0.008519443683326244",
      "\n",
      "epoch 3660: loss 0.006966025568544865",
      "\n",
      "epoch 3670: loss 0.008462403900921345",
      "\n",
      "epoch 3680: loss 0.007048291619867086",
      "\n",
      "epoch 3690: loss 0.00741374958306551",
      "\n",
      "epoch 3700: loss 0.008209969848394394",
      "\n",
      "epoch 3710: loss 0.007658815942704678",
      "\n",
      "epoch 3720: loss 0.009310373105108738",
      "\n",
      "epoch 3730: loss 0.007738786283880472",
      "\n",
      "epoch 3740: loss 0.007292408961802721",
      "\n",
      "epoch 3750: loss 0.007826377637684345",
      "\n",
      "epoch 3760: loss 0.007214974611997604",
      "\n",
      "epoch 3770: loss 0.008323587477207184",
      "\n",
      "epoch 3780: loss 0.00810991134494543",
      "\n",
      "epoch 3790: loss 0.006575047969818115",
      "\n",
      "epoch 3800: loss 0.007122274488210678",
      "\n",
      "3800 test percentage 0.9218945572807064",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 3810: loss 0.007750099990516901",
      "\n",
      "epoch 3820: loss 0.007046010345220566",
      "\n",
      "epoch 3830: loss 0.006558878347277641",
      "\n",
      "epoch 3840: loss 0.00868859700858593",
      "\n",
      "epoch 3850: loss 0.007158458698540926",
      "\n",
      "epoch 3860: loss 0.008373590186238289",
      "\n",
      "epoch 3870: loss 0.0076824272982776165",
      "\n",
      "epoch 3880: loss 0.006758927367627621",
      "\n",
      "epoch 3890: loss 0.006603276822715998",
      "\n",
      "epoch 3900: loss 0.007685924414545298",
      "\n",
      "epoch 3910: loss 0.008056771010160446",
      "\n",
      "epoch 3920: loss 0.007767184637486935",
      "\n",
      "epoch 3930: loss 0.007317685522139072",
      "\n",
      "epoch 3940: loss 0.00701399240642786",
      "\n",
      "epoch 3950: loss 0.007755479775369167",
      "\n",
      "epoch 3960: loss 0.008299886249005795",
      "\n",
      "epoch 3970: loss 0.008044601418077946",
      "\n",
      "epoch 3980: loss 0.007490677293390036",
      "\n",
      "epoch 3990: loss 0.00685162702575326",
      "\n",
      "epoch 4000: loss 0.007005650550127029",
      "\n",
      "4000 test percentage 0.9273628894193673",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 4010: loss 0.007042264565825462",
      "\n",
      "epoch 4020: loss 0.008360270410776138",
      "\n",
      "epoch 4030: loss 0.007640254683792591",
      "\n",
      "epoch 4040: loss 0.007655309978872538",
      "\n",
      "epoch 4050: loss 0.006885386072099209",
      "\n",
      "epoch 4060: loss 0.006603819318115711",
      "\n",
      "epoch 4070: loss 0.007546796463429928",
      "\n",
      "epoch 4080: loss 0.007234702352434397",
      "\n",
      "epoch 4090: loss 0.006682463455945253",
      "\n",
      "epoch 4100: loss 0.007550416048616171",
      "\n",
      "epoch 4110: loss 0.007845048792660236",
      "\n",
      "epoch 4120: loss 0.008473296649754047",
      "\n",
      "epoch 4130: loss 0.00774864386767149",
      "\n",
      "epoch 4140: loss 0.0076239099726080894",
      "\n",
      "epoch 4150: loss 0.007047259248793125",
      "\n",
      "epoch 4160: loss 0.008065441623330116",
      "\n",
      "epoch 4170: loss 0.00717393821105361",
      "\n",
      "epoch 4180: loss 0.007872841320931911",
      "\n",
      "epoch 4190: loss 0.0073204669170081615",
      "\n",
      "epoch 4200: loss 0.007685460150241852",
      "\n",
      "4200 test percentage 0.9132680839427259",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 4210: loss 0.006829518359154463",
      "\n",
      "epoch 4220: loss 0.007396930828690529",
      "\n",
      "epoch 4230: loss 0.006283851806074381",
      "\n",
      "epoch 4240: loss 0.007232611998915672",
      "\n",
      "epoch 4250: loss 0.007147589698433876",
      "\n",
      "epoch 4260: loss 0.007262344006448984",
      "\n",
      "epoch 4270: loss 0.007182023953646421",
      "\n",
      "epoch 4280: loss 0.007685065269470215",
      "\n",
      "epoch 4290: loss 0.006277824752032757",
      "\n",
      "epoch 4300: loss 0.007510502822697163",
      "\n",
      "epoch 4310: loss 0.007169586606323719",
      "\n",
      "epoch 4320: loss 0.006803868804126978",
      "\n",
      "epoch 4330: loss 0.00813624169677496",
      "\n",
      "epoch 4340: loss 0.008482079952955246",
      "\n",
      "epoch 4350: loss 0.006308440584689379",
      "\n",
      "epoch 4360: loss 0.007106543984264135",
      "\n",
      "epoch 4370: loss 0.00711915735155344",
      "\n",
      "epoch 4380: loss 0.006658500991761684",
      "\n",
      "epoch 4390: loss 0.006636370904743671",
      "\n",
      "epoch 4400: loss 0.009256555698812008",
      "\n",
      "4400 test percentage 0.8968747157172857",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 4410: loss 0.00714449305087328",
      "\n",
      "epoch 4420: loss 0.007913904264569283",
      "\n",
      "epoch 4430: loss 0.007412167266011238",
      "\n",
      "epoch 4440: loss 0.007908666506409645",
      "\n",
      "epoch 4450: loss 0.006949414499104023",
      "\n",
      "epoch 4460: loss 0.007538444362580776",
      "\n",
      "epoch 4470: loss 0.00728866271674633",
      "\n",
      "epoch 4480: loss 0.00818733498454094",
      "\n",
      "epoch 4490: loss 0.008089258335530758",
      "\n",
      "epoch 4500: loss 0.007539381273090839",
      "\n",
      "epoch 4510: loss 0.006729386281222105",
      "\n",
      "epoch 4520: loss 0.007509586401283741",
      "\n",
      "epoch 4530: loss 0.008631478063762188",
      "\n",
      "epoch 4540: loss 0.006624036468565464",
      "\n",
      "epoch 4550: loss 0.006850021425634623",
      "\n",
      "epoch 4560: loss 0.00669353362172842",
      "\n",
      "epoch 4570: loss 0.007023196667432785",
      "\n",
      "epoch 4580: loss 0.006477032322436571",
      "\n",
      "epoch 4590: loss 0.006864556577056646",
      "\n",
      "epoch 4600: loss 0.008364997804164886",
      "\n",
      "4600 test percentage 0.9100455681215366",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 4610: loss 0.007437922991812229",
      "\n",
      "epoch 4620: loss 0.006284678820520639",
      "\n",
      "epoch 4630: loss 0.006630628369748592",
      "\n",
      "epoch 4640: loss 0.006417591590434313",
      "\n",
      "epoch 4650: loss 0.0067101214081048965",
      "\n",
      "epoch 4660: loss 0.00707855261862278",
      "\n",
      "epoch 4670: loss 0.007372054737061262",
      "\n",
      "epoch 4680: loss 0.006358304060995579",
      "\n",
      "epoch 4690: loss 0.00799937266856432",
      "\n",
      "epoch 4700: loss 0.007654867600649595",
      "\n",
      "epoch 4710: loss 0.007487868890166283",
      "\n",
      "epoch 4720: loss 0.007961711846292019",
      "\n",
      "epoch 4730: loss 0.006870762910693884",
      "\n",
      "epoch 4740: loss 0.0071184346452355385",
      "\n",
      "epoch 4750: loss 0.007011347450315952",
      "\n",
      "epoch 4760: loss 0.006679312791675329",
      "\n",
      "epoch 4770: loss 0.007304578088223934",
      "\n",
      "epoch 4780: loss 0.008181249722838402",
      "\n",
      "epoch 4790: loss 0.00663319556042552",
      "\n",
      "epoch 4800: loss 0.007181849330663681",
      "\n",
      "4800 test percentage 0.9264062010211709",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 4810: loss 0.0084074130281806",
      "\n",
      "epoch 4820: loss 0.0077045997604727745",
      "\n",
      "epoch 4830: loss 0.007728997617959976",
      "\n",
      "epoch 4840: loss 0.0060158842243254185",
      "\n",
      "epoch 4850: loss 0.007420066744089127",
      "\n",
      "epoch 4860: loss 0.006987080909311771",
      "\n",
      "epoch 4870: loss 0.0069461422972381115",
      "\n",
      "epoch 4880: loss 0.007642577867954969",
      "\n",
      "epoch 4890: loss 0.0066129425540566444",
      "\n",
      "epoch 4900: loss 0.006813834421336651",
      "\n",
      "epoch 4910: loss 0.007575562223792076",
      "\n",
      "epoch 4920: loss 0.00667007127776742",
      "\n",
      "epoch 4930: loss 0.007328688632696867",
      "\n",
      "epoch 4940: loss 0.006711742375046015",
      "\n",
      "epoch 4950: loss 0.006069453898817301",
      "\n",
      "epoch 4960: loss 0.007300675380975008",
      "\n",
      "epoch 4970: loss 0.00795982126146555",
      "\n",
      "epoch 4980: loss 0.007506869733333588",
      "\n",
      "epoch 4990: loss 0.006779349874705076",
      "\n",
      "epoch 5000: loss 0.0061154551804065704",
      "\n",
      "5000 test percentage 0.9223242865668403",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 5010: loss 0.007473398465663195",
      "\n",
      "epoch 5020: loss 0.0064293877221643925",
      "\n",
      "epoch 5030: loss 0.006641261279582977",
      "\n",
      "epoch 5040: loss 0.006704321596771479",
      "\n",
      "epoch 5050: loss 0.006946300622075796",
      "\n",
      "epoch 5060: loss 0.00699465861544013",
      "\n",
      "epoch 5070: loss 0.007453225553035736",
      "\n",
      "epoch 5080: loss 0.0069581978023052216",
      "\n",
      "epoch 5090: loss 0.007567705120891333",
      "\n",
      "epoch 5100: loss 0.0069349235855042934",
      "\n",
      "epoch 5110: loss 0.008132461458444595",
      "\n",
      "epoch 5120: loss 0.006462516728788614",
      "\n",
      "epoch 5130: loss 0.007200865540653467",
      "\n",
      "epoch 5140: loss 0.006491255015134811",
      "\n",
      "epoch 5150: loss 0.006837096530944109",
      "\n",
      "epoch 5160: loss 0.006372281350195408",
      "\n",
      "epoch 5170: loss 0.007547750137746334",
      "\n",
      "epoch 5180: loss 0.006657424382865429",
      "\n",
      "epoch 5190: loss 0.006926669739186764",
      "\n",
      "epoch 5200: loss 0.008368928916752338",
      "\n",
      "5200 test percentage 0.8953915648455036",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 5210: loss 0.007961172610521317",
      "\n",
      "epoch 5220: loss 0.006972496397793293",
      "\n",
      "epoch 5230: loss 0.0071692755445837975",
      "\n",
      "epoch 5240: loss 0.007252593990415335",
      "\n",
      "epoch 5250: loss 0.009509505704045296",
      "\n",
      "epoch 5260: loss 0.00586811313405633",
      "\n",
      "epoch 5270: loss 0.006508299615234137",
      "\n",
      "epoch 5280: loss 0.007351716514676809",
      "\n",
      "epoch 5290: loss 0.006406205706298351",
      "\n",
      "epoch 5300: loss 0.007907722145318985",
      "\n",
      "epoch 5310: loss 0.009222859516739845",
      "\n",
      "epoch 5320: loss 0.006775976158678532",
      "\n",
      "epoch 5330: loss 0.007210788782685995",
      "\n",
      "epoch 5340: loss 0.006470506079494953",
      "\n",
      "epoch 5350: loss 0.005950959399342537",
      "\n",
      "epoch 5360: loss 0.005475866608321667",
      "\n",
      "epoch 5370: loss 0.006772410124540329",
      "\n",
      "epoch 5380: loss 0.006785199977457523",
      "\n",
      "epoch 5390: loss 0.0065474677830934525",
      "\n",
      "epoch 5400: loss 0.006203328259289265",
      "\n",
      "5400 test percentage 0.9337140563896342",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 5410: loss 0.007338408380746841",
      "\n",
      "epoch 5420: loss 0.007735494989901781",
      "\n",
      "epoch 5430: loss 0.00711568258702755",
      "\n",
      "epoch 5440: loss 0.006825494579970837",
      "\n",
      "epoch 5450: loss 0.00656705629080534",
      "\n",
      "epoch 5460: loss 0.007128431461751461",
      "\n",
      "epoch 5470: loss 0.005915955640375614",
      "\n",
      "epoch 5480: loss 0.006328053306788206",
      "\n",
      "epoch 5490: loss 0.006815419066697359",
      "\n",
      "epoch 5500: loss 0.007063992787152529",
      "\n",
      "epoch 5510: loss 0.0070683457888662815",
      "\n",
      "epoch 5520: loss 0.006560348905622959",
      "\n",
      "epoch 5530: loss 0.005685368552803993",
      "\n",
      "epoch 5540: loss 0.007223727181553841",
      "\n",
      "epoch 5550: loss 0.006274377927184105",
      "\n",
      "epoch 5560: loss 0.00735245319083333",
      "\n",
      "epoch 5570: loss 0.00726541131734848",
      "\n",
      "epoch 5580: loss 0.006624924018979073",
      "\n",
      "epoch 5590: loss 0.006675568409264088",
      "\n",
      "epoch 5600: loss 0.007035939954221249",
      "\n",
      "5600 test percentage 0.9224392069978211",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 5610: loss 0.006319919601082802",
      "\n",
      "epoch 5620: loss 0.00732818990945816",
      "\n",
      "epoch 5630: loss 0.006899597123265266",
      "\n",
      "epoch 5640: loss 0.007245921064168215",
      "\n",
      "epoch 5650: loss 0.006688131019473076",
      "\n",
      "epoch 5660: loss 0.006629845127463341",
      "\n",
      "epoch 5670: loss 0.007238380610942841",
      "\n",
      "epoch 5680: loss 0.006857288535684347",
      "\n",
      "epoch 5690: loss 0.006450210232287645",
      "\n",
      "epoch 5700: loss 0.007654090411961079",
      "\n",
      "epoch 5710: loss 0.007799107115715742",
      "\n",
      "epoch 5720: loss 0.006682377774268389",
      "\n",
      "epoch 5730: loss 0.006605727598071098",
      "\n",
      "epoch 5740: loss 0.006795125547796488",
      "\n",
      "epoch 5750: loss 0.007042571436613798",
      "\n",
      "epoch 5760: loss 0.007051633205264807",
      "\n",
      "epoch 5770: loss 0.006804801523685455",
      "\n",
      "epoch 5780: loss 0.006609595380723476",
      "\n",
      "epoch 5790: loss 0.00633646734058857",
      "\n",
      "epoch 5800: loss 0.006851209327578545",
      "\n",
      "5800 test percentage 0.9364981603140783",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 5810: loss 0.006109874229878187",
      "\n",
      "epoch 5820: loss 0.006338924169540405",
      "\n",
      "epoch 5830: loss 0.006134216673672199",
      "\n",
      "epoch 5840: loss 0.006787826772779226",
      "\n",
      "epoch 5850: loss 0.006116671487689018",
      "\n",
      "epoch 5860: loss 0.006773192435503006",
      "\n",
      "epoch 5870: loss 0.007291411515325308",
      "\n",
      "epoch 5880: loss 0.006893731653690338",
      "\n",
      "epoch 5890: loss 0.006371817085891962",
      "\n",
      "epoch 5900: loss 0.006036687176674604",
      "\n",
      "epoch 5910: loss 0.006699497811496258",
      "\n",
      "epoch 5920: loss 0.006092040333896875",
      "\n",
      "epoch 5930: loss 0.008078581653535366",
      "\n",
      "epoch 5940: loss 0.006455902475863695",
      "\n",
      "epoch 5950: loss 0.006992772221565247",
      "\n",
      "epoch 5960: loss 0.006711754482239485",
      "\n",
      "epoch 5970: loss 0.006608293857425451",
      "\n",
      "epoch 5980: loss 0.006664127577096224",
      "\n",
      "epoch 5990: loss 0.006155322305858135",
      "\n",
      "epoch 6000: loss 0.0065134624019265175",
      "\n",
      "6000 test percentage 0.936609638526651",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 6010: loss 0.0064512258395552635",
      "\n",
      "epoch 6020: loss 0.007889186963438988",
      "\n",
      "epoch 6030: loss 0.007091581355780363",
      "\n",
      "epoch 6040: loss 0.005673338659107685",
      "\n",
      "epoch 6050: loss 0.007425873074680567",
      "\n",
      "epoch 6060: loss 0.006041313987225294",
      "\n",
      "epoch 6070: loss 0.006680037826299667",
      "\n",
      "epoch 6080: loss 0.00744203943759203",
      "\n",
      "epoch 6090: loss 0.006272159516811371",
      "\n",
      "epoch 6100: loss 0.007380736526101828",
      "\n",
      "epoch 6110: loss 0.006983776111155748",
      "\n",
      "epoch 6120: loss 0.006813656073063612",
      "\n",
      "epoch 6130: loss 0.0067023239098489285",
      "\n",
      "epoch 6140: loss 0.008523703552782536",
      "\n",
      "epoch 6150: loss 0.007328317500650883",
      "\n",
      "epoch 6160: loss 0.00643723551183939",
      "\n",
      "epoch 6170: loss 0.006550873164087534",
      "\n",
      "epoch 6180: loss 0.00664129015058279",
      "\n",
      "epoch 6190: loss 0.0066843717359006405",
      "\n",
      "epoch 6200: loss 0.00665290979668498",
      "\n",
      "6200 test percentage 0.9402797026800119",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 6210: loss 0.006387228146195412",
      "\n",
      "epoch 6220: loss 0.006303229369223118",
      "\n",
      "epoch 6230: loss 0.005513733718544245",
      "\n",
      "epoch 6240: loss 0.006875184830278158",
      "\n",
      "epoch 6250: loss 0.006059822626411915",
      "\n",
      "epoch 6260: loss 0.006722223944962025",
      "\n",
      "epoch 6270: loss 0.00626012310385704",
      "\n",
      "epoch 6280: loss 0.006745072081685066",
      "\n",
      "epoch 6290: loss 0.006753404159098864",
      "\n",
      "epoch 6300: loss 0.007277952507138252",
      "\n",
      "epoch 6310: loss 0.0076422980055212975",
      "\n",
      "epoch 6320: loss 0.007124028168618679",
      "\n",
      "epoch 6330: loss 0.006317395716905594",
      "\n",
      "epoch 6340: loss 0.006700375583022833",
      "\n",
      "epoch 6350: loss 0.006827394478023052",
      "\n",
      "epoch 6360: loss 0.006695176009088755",
      "\n",
      "epoch 6370: loss 0.007130281534045935",
      "\n",
      "epoch 6380: loss 0.006723323836922646",
      "\n",
      "epoch 6390: loss 0.00618252158164978",
      "\n",
      "epoch 6400: loss 0.007019490469247103",
      "\n",
      "6400 test percentage 0.9173727838278619",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 6410: loss 0.006063370034098625",
      "\n",
      "epoch 6420: loss 0.007112444844096899",
      "\n",
      "epoch 6430: loss 0.007058977615088224",
      "\n",
      "epoch 6440: loss 0.006358534563332796",
      "\n",
      "epoch 6450: loss 0.00583250168710947",
      "\n",
      "epoch 6460: loss 0.006663159932941198",
      "\n",
      "epoch 6470: loss 0.006201144773513079",
      "\n",
      "epoch 6480: loss 0.0077160499058663845",
      "\n",
      "epoch 6490: loss 0.006203126162290573",
      "\n",
      "epoch 6500: loss 0.0074178860522806644",
      "\n",
      "epoch 6510: loss 0.00682954303920269",
      "\n",
      "epoch 6520: loss 0.006807314231991768",
      "\n",
      "epoch 6530: loss 0.005993872880935669",
      "\n",
      "epoch 6540: loss 0.007213889621198177",
      "\n",
      "epoch 6550: loss 0.0069852834567427635",
      "\n",
      "epoch 6560: loss 0.006872460711747408",
      "\n",
      "epoch 6570: loss 0.0063812038861215115",
      "\n",
      "epoch 6580: loss 0.006020518485456705",
      "\n",
      "epoch 6590: loss 0.006164830178022385",
      "\n",
      "epoch 6600: loss 0.006584152579307556",
      "\n",
      "6600 test percentage 0.9296766210485388",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 6610: loss 0.0070999544113874435",
      "\n",
      "epoch 6620: loss 0.007429592777043581",
      "\n",
      "epoch 6630: loss 0.005934565793722868",
      "\n",
      "epoch 6640: loss 0.006352216005325317",
      "\n",
      "epoch 6650: loss 0.005373944994062185",
      "\n",
      "epoch 6660: loss 0.0055691953748464584",
      "\n",
      "epoch 6670: loss 0.006520858034491539",
      "\n",
      "epoch 6680: loss 0.005955687258392572",
      "\n",
      "epoch 6690: loss 0.00628729909658432",
      "\n",
      "epoch 6700: loss 0.005752808880060911",
      "\n",
      "epoch 6710: loss 0.005659706890583038",
      "\n",
      "epoch 6720: loss 0.00924105104058981",
      "\n",
      "epoch 6730: loss 0.006283903960138559",
      "\n",
      "epoch 6740: loss 0.00599743751809001",
      "\n",
      "epoch 6750: loss 0.005863689351826906",
      "\n",
      "epoch 6760: loss 0.006031720899045467",
      "\n",
      "epoch 6770: loss 0.006490676663815975",
      "\n",
      "epoch 6780: loss 0.007350534200668335",
      "\n",
      "epoch 6790: loss 0.0062592122703790665",
      "\n",
      "epoch 6800: loss 0.0066180420108139515",
      "\n",
      "6800 test percentage 0.9397442279306192",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 6810: loss 0.006493607070297003",
      "\n",
      "epoch 6820: loss 0.006430395878851414",
      "\n",
      "epoch 6830: loss 0.006420454476028681",
      "\n",
      "epoch 6840: loss 0.0060637458227574825",
      "\n",
      "epoch 6850: loss 0.006918470840901136",
      "\n",
      "epoch 6860: loss 0.006724459584802389",
      "\n",
      "epoch 6870: loss 0.006235818844288588",
      "\n",
      "epoch 6880: loss 0.006429015658795834",
      "\n",
      "epoch 6890: loss 0.0075145005248487",
      "\n",
      "epoch 6900: loss 0.006531257648020983",
      "\n",
      "epoch 6910: loss 0.006371490191668272",
      "\n",
      "epoch 6920: loss 0.00556291826069355",
      "\n",
      "epoch 6930: loss 0.006015189923346043",
      "\n",
      "epoch 6940: loss 0.007598128169775009",
      "\n",
      "epoch 6950: loss 0.006415798794478178",
      "\n",
      "epoch 6960: loss 0.006975890137255192",
      "\n",
      "epoch 6970: loss 0.005575568415224552",
      "\n",
      "epoch 6980: loss 0.005947629921138287",
      "\n",
      "epoch 6990: loss 0.006829488091170788",
      "\n",
      "epoch 7000: loss 0.0062936837784945965",
      "\n",
      "7000 test percentage 0.9273549945801329",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 7010: loss 0.006323480512946844",
      "\n",
      "epoch 7020: loss 0.006240161135792732",
      "\n",
      "epoch 7030: loss 0.006656145676970482",
      "\n",
      "epoch 7040: loss 0.0055276635102927685",
      "\n",
      "epoch 7050: loss 0.005698829423636198",
      "\n",
      "epoch 7060: loss 0.005853922571986914",
      "\n",
      "epoch 7070: loss 0.006314642261713743",
      "\n",
      "epoch 7080: loss 0.0054587749764323235",
      "\n",
      "epoch 7090: loss 0.006485901772975922",
      "\n",
      "epoch 7100: loss 0.00670419167727232",
      "\n",
      "epoch 7110: loss 0.007199241779744625",
      "\n",
      "epoch 7120: loss 0.006858970038592815",
      "\n",
      "epoch 7130: loss 0.006556920241564512",
      "\n",
      "epoch 7140: loss 0.006271380931138992",
      "\n",
      "epoch 7150: loss 0.006477903574705124",
      "\n",
      "epoch 7160: loss 0.006109977141022682",
      "\n",
      "epoch 7170: loss 0.006776471622288227",
      "\n",
      "epoch 7180: loss 0.005921980831772089",
      "\n",
      "epoch 7190: loss 0.0068384986370801926",
      "\n",
      "epoch 7200: loss 0.006360470782965422",
      "\n",
      "7200 test percentage 0.9219627423184755",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 7210: loss 0.005975269712507725",
      "\n",
      "epoch 7220: loss 0.006447755265980959",
      "\n",
      "epoch 7230: loss 0.005561393685638905",
      "\n",
      "epoch 7240: loss 0.006781414616852999",
      "\n",
      "epoch 7250: loss 0.006719582248479128",
      "\n",
      "epoch 7260: loss 0.006655913311988115",
      "\n",
      "epoch 7270: loss 0.006163344718515873",
      "\n",
      "epoch 7280: loss 0.0065096598118543625",
      "\n",
      "epoch 7290: loss 0.00620670709758997",
      "\n",
      "epoch 7300: loss 0.005501234903931618",
      "\n",
      "epoch 7310: loss 0.006767203100025654",
      "\n",
      "epoch 7320: loss 0.006884199567139149",
      "\n",
      "epoch 7330: loss 0.005701842717826366",
      "\n",
      "epoch 7340: loss 0.005600525066256523",
      "\n",
      "epoch 7350: loss 0.006730165798217058",
      "\n",
      "epoch 7360: loss 0.006643692962825298",
      "\n",
      "epoch 7370: loss 0.005657191388309002",
      "\n",
      "epoch 7380: loss 0.007084457203745842",
      "\n",
      "epoch 7390: loss 0.005660323891788721",
      "\n",
      "epoch 7400: loss 0.006975220516324043",
      "\n",
      "7400 test percentage 0.9313502798711946",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 7410: loss 0.006095114164054394",
      "\n",
      "epoch 7420: loss 0.007203917950391769",
      "\n",
      "epoch 7430: loss 0.005737376399338245",
      "\n",
      "epoch 7440: loss 0.006700387690216303",
      "\n",
      "epoch 7450: loss 0.006562239024788141",
      "\n",
      "epoch 7460: loss 0.006556190550327301",
      "\n",
      "epoch 7470: loss 0.007030183915048838",
      "\n",
      "epoch 7480: loss 0.006659114733338356",
      "\n",
      "epoch 7490: loss 0.006088956259191036",
      "\n",
      "epoch 7500: loss 0.006258146371692419",
      "\n",
      "epoch 7510: loss 0.006572807673364878",
      "\n",
      "epoch 7520: loss 0.0058784340508282185",
      "\n",
      "epoch 7530: loss 0.005364750977605581",
      "\n",
      "epoch 7540: loss 0.006736245937645435",
      "\n",
      "epoch 7550: loss 0.00578771298751235",
      "\n",
      "epoch 7560: loss 0.006356153637170792",
      "\n",
      "epoch 7570: loss 0.00684202229604125",
      "\n",
      "epoch 7580: loss 0.0057203518226742744",
      "\n",
      "epoch 7590: loss 0.006112791132181883",
      "\n",
      "epoch 7600: loss 0.006922967731952667",
      "\n",
      "7600 test percentage 0.9283820343873851",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 7610: loss 0.00639738654717803",
      "\n",
      "epoch 7620: loss 0.005198890343308449",
      "\n",
      "epoch 7630: loss 0.006200897973030806",
      "\n",
      "epoch 7640: loss 0.007037430536001921",
      "\n",
      "epoch 7650: loss 0.0069959103129804134",
      "\n",
      "epoch 7660: loss 0.005931243300437927",
      "\n",
      "epoch 7670: loss 0.005780238192528486",
      "\n",
      "epoch 7680: loss 0.006475151050835848",
      "\n",
      "epoch 7690: loss 0.006868277210742235",
      "\n",
      "epoch 7700: loss 0.005619308445602655",
      "\n",
      "epoch 7710: loss 0.005676869302988052",
      "\n",
      "epoch 7720: loss 0.005276941694319248",
      "\n",
      "epoch 7730: loss 0.005717207677662373",
      "\n",
      "epoch 7740: loss 0.006060955114662647",
      "\n",
      "epoch 7750: loss 0.005786677356809378",
      "\n",
      "epoch 7760: loss 0.006469793152064085",
      "\n",
      "epoch 7770: loss 0.006385974120348692",
      "\n",
      "epoch 7780: loss 0.006393032614141703",
      "\n",
      "epoch 7790: loss 0.005720517132431269",
      "\n",
      "epoch 7800: loss 0.006719786673784256",
      "\n",
      "7800 test percentage 0.921068878687592",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 7810: loss 0.005912038963288069",
      "\n",
      "epoch 7820: loss 0.0057924664579331875",
      "\n",
      "epoch 7830: loss 0.0061189476400613785",
      "\n",
      "epoch 7840: loss 0.006068935617804527",
      "\n",
      "epoch 7850: loss 0.006111448165029287",
      "\n",
      "epoch 7860: loss 0.006966249085962772",
      "\n",
      "epoch 7870: loss 0.0060090553015470505",
      "\n",
      "epoch 7880: loss 0.005675540305674076",
      "\n",
      "epoch 7890: loss 0.005738049279898405",
      "\n",
      "epoch 7900: loss 0.006043887231498957",
      "\n",
      "epoch 7910: loss 0.0060401554219424725",
      "\n",
      "epoch 7920: loss 0.005957035347819328",
      "\n",
      "epoch 7930: loss 0.005238817539066076",
      "\n",
      "epoch 7940: loss 0.005873651709407568",
      "\n",
      "epoch 7950: loss 0.006669805385172367",
      "\n",
      "epoch 7960: loss 0.007075791247189045",
      "\n",
      "epoch 7970: loss 0.006483257748186588",
      "\n",
      "epoch 7980: loss 0.006469442043453455",
      "\n",
      "epoch 7990: loss 0.006271529942750931",
      "\n",
      "epoch 8000: loss 0.005892655812203884",
      "\n",
      "8000 test percentage 0.9280999694207702",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 8010: loss 0.005742394831031561",
      "\n",
      "epoch 8020: loss 0.005184325389564037",
      "\n",
      "epoch 8030: loss 0.005890181288123131",
      "\n",
      "epoch 8040: loss 0.0051973736844956875",
      "\n",
      "epoch 8050: loss 0.006428394466638565",
      "\n",
      "epoch 8060: loss 0.005245652515441179",
      "\n",
      "epoch 8070: loss 0.006103859283030033",
      "\n",
      "epoch 8080: loss 0.006050091236829758",
      "\n",
      "epoch 8090: loss 0.00573308952152729",
      "\n",
      "epoch 8100: loss 0.005686050280928612",
      "\n",
      "epoch 8110: loss 0.0055675082840025425",
      "\n",
      "epoch 8120: loss 0.00569972163066268",
      "\n",
      "epoch 8130: loss 0.005408108700066805",
      "\n",
      "epoch 8140: loss 0.006069702561944723",
      "\n",
      "epoch 8150: loss 0.005787461530417204",
      "\n",
      "epoch 8160: loss 0.007012055721133947",
      "\n",
      "epoch 8170: loss 0.006555610336363316",
      "\n",
      "epoch 8180: loss 0.00610266113653779",
      "\n",
      "epoch 8190: loss 0.0068193115293979645",
      "\n",
      "epoch 8200: loss 0.005976158194243908",
      "\n",
      "8200 test percentage 0.9320819653512118",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 8210: loss 0.0059328507632017136",
      "\n",
      "epoch 8220: loss 0.0059727393090724945",
      "\n",
      "epoch 8230: loss 0.006308550480753183",
      "\n",
      "epoch 8240: loss 0.00613871356472373",
      "\n",
      "epoch 8250: loss 0.006590394303202629",
      "\n",
      "epoch 8260: loss 0.005359649192541838",
      "\n",
      "epoch 8270: loss 0.005700996611267328",
      "\n",
      "epoch 8280: loss 0.0062036700546741486",
      "\n",
      "epoch 8290: loss 0.005540461279451847",
      "\n",
      "epoch 8300: loss 0.006052252370864153",
      "\n",
      "epoch 8310: loss 0.006003974471241236",
      "\n",
      "epoch 8320: loss 0.006160635035485029",
      "\n",
      "epoch 8330: loss 0.005859639495611191",
      "\n",
      "epoch 8340: loss 0.006451404187828302",
      "\n",
      "epoch 8350: loss 0.005817088298499584",
      "\n",
      "epoch 8360: loss 0.005993901751935482",
      "\n",
      "epoch 8370: loss 0.006091048009693623",
      "\n",
      "epoch 8380: loss 0.005727140232920647",
      "\n",
      "epoch 8390: loss 0.006210546474903822",
      "\n",
      "epoch 8400: loss 0.006113172043114901",
      "\n",
      "8400 test percentage 0.9396659688382304",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 8410: loss 0.00705597223713994",
      "\n",
      "epoch 8420: loss 0.006590378005057573",
      "\n",
      "epoch 8430: loss 0.005544440820813179",
      "\n",
      "epoch 8440: loss 0.005526675842702389",
      "\n",
      "epoch 8450: loss 0.006088173016905785",
      "\n",
      "epoch 8460: loss 0.005348759703338146",
      "\n",
      "epoch 8470: loss 0.005733204074203968",
      "\n",
      "epoch 8480: loss 0.0058359671384096146",
      "\n",
      "epoch 8490: loss 0.005072095897048712",
      "\n",
      "epoch 8500: loss 0.005673232022672892",
      "\n",
      "epoch 8510: loss 0.005346319172531366",
      "\n",
      "epoch 8520: loss 0.0062698787078261375",
      "\n",
      "epoch 8530: loss 0.007245005574077368",
      "\n",
      "epoch 8540: loss 0.006038041785359383",
      "\n",
      "epoch 8550: loss 0.005614191293716431",
      "\n",
      "epoch 8560: loss 0.006564494222402573",
      "\n",
      "epoch 8570: loss 0.005546343978494406",
      "\n",
      "epoch 8580: loss 0.007435500621795654",
      "\n",
      "epoch 8590: loss 0.006144915707409382",
      "\n",
      "epoch 8600: loss 0.005680723115801811",
      "\n",
      "8600 test percentage 0.9080900455564762",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 8610: loss 0.0061963703483343124",
      "\n",
      "epoch 8620: loss 0.006092884112149477",
      "\n",
      "epoch 8630: loss 0.006269380450248718",
      "\n",
      "epoch 8640: loss 0.006395294331014156",
      "\n",
      "epoch 8650: loss 0.005799503531306982",
      "\n",
      "epoch 8660: loss 0.00637522479519248",
      "\n",
      "epoch 8670: loss 0.00601804256439209",
      "\n",
      "epoch 8680: loss 0.006442655343562365",
      "\n",
      "epoch 8690: loss 0.006460541859269142",
      "\n",
      "epoch 8700: loss 0.006449313834309578",
      "\n",
      "epoch 8710: loss 0.006507888436317444",
      "\n",
      "epoch 8720: loss 0.005497405771166086",
      "\n",
      "epoch 8730: loss 0.0064046611078083515",
      "\n",
      "epoch 8740: loss 0.006039999891072512",
      "\n",
      "epoch 8750: loss 0.00588949816301465",
      "\n",
      "epoch 8760: loss 0.00583078246563673",
      "\n",
      "epoch 8770: loss 0.0058097559958696365",
      "\n",
      "epoch 8780: loss 0.006201338488608599",
      "\n",
      "epoch 8790: loss 0.005947231315076351",
      "\n",
      "epoch 8800: loss 0.006508877035230398",
      "\n",
      "8800 test percentage 0.9184955121692182",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 8810: loss 0.006784612312912941",
      "\n",
      "epoch 8820: loss 0.00602643983438611",
      "\n",
      "epoch 8830: loss 0.0060069565661251545",
      "\n",
      "epoch 8840: loss 0.0052473233081400394",
      "\n",
      "epoch 8850: loss 0.00512797012925148",
      "\n",
      "epoch 8860: loss 0.005388143006712198",
      "\n",
      "epoch 8870: loss 0.00533260079100728",
      "\n",
      "epoch 8880: loss 0.0058731697499752045",
      "\n",
      "epoch 8890: loss 0.005687326658517122",
      "\n",
      "epoch 8900: loss 0.006596777122467756",
      "\n",
      "epoch 8910: loss 0.005697325337678194",
      "\n",
      "epoch 8920: loss 0.0064463228918612",
      "\n",
      "epoch 8930: loss 0.006287521682679653",
      "\n",
      "epoch 8940: loss 0.005585574544966221",
      "\n",
      "epoch 8950: loss 0.006932944059371948",
      "\n",
      "epoch 8960: loss 0.006871853955090046",
      "\n",
      "epoch 8970: loss 0.005968540441244841",
      "\n",
      "epoch 8980: loss 0.005499888211488724",
      "\n",
      "epoch 8990: loss 0.007473214995115995",
      "\n",
      "epoch 9000: loss 0.0054998802952468395",
      "\n",
      "9000 test percentage 0.9338278122890142",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 9010: loss 0.006167273037135601",
      "\n",
      "epoch 9020: loss 0.006155685521662235",
      "\n",
      "epoch 9030: loss 0.005748096387833357",
      "\n",
      "epoch 9040: loss 0.006144024431705475",
      "\n",
      "epoch 9050: loss 0.005328673869371414",
      "\n",
      "epoch 9060: loss 0.0062725539319217205",
      "\n",
      "epoch 9070: loss 0.005879119969904423",
      "\n",
      "epoch 9080: loss 0.005387703888118267",
      "\n",
      "epoch 9090: loss 0.005219731945544481",
      "\n",
      "epoch 9100: loss 0.005860835313796997",
      "\n",
      "epoch 9110: loss 0.0061198347248137",
      "\n",
      "epoch 9120: loss 0.0060598538257181644",
      "\n",
      "epoch 9130: loss 0.005564665887504816",
      "\n",
      "epoch 9140: loss 0.0064449976198375225",
      "\n",
      "epoch 9150: loss 0.005970757920295",
      "\n",
      "epoch 9160: loss 0.006086303386837244",
      "\n",
      "epoch 9170: loss 0.0056404536589980125",
      "\n",
      "epoch 9180: loss 0.005535867065191269",
      "\n",
      "epoch 9190: loss 0.006209614686667919",
      "\n",
      "epoch 9200: loss 0.005500775296241045",
      "\n",
      "9200 test percentage 0.9330315509629169",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 9210: loss 0.006607962306588888",
      "\n",
      "epoch 9220: loss 0.0061362613923847675",
      "\n",
      "epoch 9230: loss 0.006835601758211851",
      "\n",
      "epoch 9240: loss 0.005446685012429953",
      "\n",
      "epoch 9250: loss 0.006344526074826717",
      "\n",
      "epoch 9260: loss 0.0057220617309212685",
      "\n",
      "epoch 9270: loss 0.006057491526007652",
      "\n",
      "epoch 9280: loss 0.005964233539998531",
      "\n",
      "epoch 9290: loss 0.005593065172433853",
      "\n",
      "epoch 9300: loss 0.0058738612569868565",
      "\n",
      "epoch 9310: loss 0.0063698673620820045",
      "\n",
      "epoch 9320: loss 0.005520987324416637",
      "\n",
      "epoch 9330: loss 0.005375309847295284",
      "\n",
      "epoch 9340: loss 0.005607689265161753",
      "\n",
      "epoch 9350: loss 0.004887839779257774",
      "\n",
      "epoch 9360: loss 0.005768858827650547",
      "\n",
      "epoch 9370: loss 0.005772826261818409",
      "\n",
      "epoch 9380: loss 0.006483032833784819",
      "\n",
      "epoch 9390: loss 0.005543171428143978",
      "\n",
      "epoch 9400: loss 0.006391946692019701",
      "\n",
      "9400 test percentage 0.9302252139039044",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 9410: loss 0.006344528403133154",
      "\n",
      "epoch 9420: loss 0.006167038343846798",
      "\n",
      "epoch 9430: loss 0.0061925542540848255",
      "\n",
      "epoch 9440: loss 0.005873278249055147",
      "\n",
      "epoch 9450: loss 0.005035166162997484",
      "\n",
      "epoch 9460: loss 0.005086811259388924",
      "\n",
      "epoch 9470: loss 0.0068366630002856255",
      "\n",
      "epoch 9480: loss 0.006375001277774572",
      "\n",
      "epoch 9490: loss 0.005928636994212866",
      "\n",
      "epoch 9500: loss 0.0062263356521725655",
      "\n",
      "epoch 9510: loss 0.0065743401646614075",
      "\n",
      "epoch 9520: loss 0.006751505192369223",
      "\n",
      "epoch 9530: loss 0.006520067807286978",
      "\n",
      "epoch 9540: loss 0.006056474056094885",
      "\n",
      "epoch 9550: loss 0.0051387399435043335",
      "\n",
      "epoch 9560: loss 0.005894449073821306",
      "\n",
      "epoch 9570: loss 0.006144444923847914",
      "\n",
      "epoch 9580: loss 0.0050580804236233234",
      "\n",
      "epoch 9590: loss 0.006175157614052296",
      "\n",
      "epoch 9600: loss 0.006511333864182234",
      "\n",
      "9600 test percentage 0.908523045806371",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 9610: loss 0.006161833181977272",
      "\n",
      "epoch 9620: loss 0.005348084960132837",
      "\n",
      "epoch 9630: loss 0.005827606655657291",
      "\n",
      "epoch 9640: loss 0.005444194655865431",
      "\n",
      "epoch 9650: loss 0.005634428933262825",
      "\n",
      "epoch 9660: loss 0.006089560221880674",
      "\n",
      "epoch 9670: loss 0.00658178236335516",
      "\n",
      "epoch 9680: loss 0.005629932973533869",
      "\n",
      "epoch 9690: loss 0.006228901445865631",
      "\n",
      "epoch 9700: loss 0.006972255185246468",
      "\n",
      "epoch 9710: loss 0.006257952190935612",
      "\n",
      "epoch 9720: loss 0.006029568612575531",
      "\n",
      "epoch 9730: loss 0.005556812509894371",
      "\n",
      "epoch 9740: loss 0.005751863121986389",
      "\n",
      "epoch 9750: loss 0.0052168164402246475",
      "\n",
      "epoch 9760: loss 0.005795980803668499",
      "\n",
      "epoch 9770: loss 0.0057581947185099125",
      "\n",
      "epoch 9780: loss 0.0069571854546666145",
      "\n",
      "epoch 9790: loss 0.009824486449360847",
      "\n",
      "epoch 9800: loss 0.005401667673140764",
      "\n",
      "9800 test percentage 0.9350916330528045",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 9810: loss 0.005334219429641962",
      "\n",
      "epoch 9820: loss 0.005545526277273893",
      "\n",
      "epoch 9830: loss 0.005737101659178734",
      "\n",
      "epoch 9840: loss 0.0058478424325585365",
      "\n",
      "epoch 9850: loss 0.005745133850723505",
      "\n",
      "epoch 9860: loss 0.005519204307347536",
      "\n",
      "epoch 9870: loss 0.005515203811228275",
      "\n",
      "epoch 9880: loss 0.005602310411632061",
      "\n",
      "epoch 9890: loss 0.005148866213858128",
      "\n",
      "epoch 9900: loss 0.005836633499711752",
      "\n",
      "epoch 9910: loss 0.005065470933914185",
      "\n",
      "epoch 9920: loss 0.005041513126343489",
      "\n",
      "epoch 9930: loss 0.0053294445388019085",
      "\n",
      "epoch 9940: loss 0.005560792051255703",
      "\n",
      "epoch 9950: loss 0.005161627195775509",
      "\n",
      "epoch 9960: loss 0.0066468496806919575",
      "\n",
      "epoch 9970: loss 0.0058049955405294895",
      "\n",
      "epoch 9980: loss 0.004980751313269138",
      "\n",
      "epoch 9990: loss 0.00544727174565196",
      "\n",
      "epoch 10000: loss 0.006026184186339378",
      "\n",
      "10000 test percentage 0.9261312088714839",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 10010: loss 0.005373125895857811",
      "\n",
      "epoch 10020: loss 0.00542127201333642",
      "\n",
      "epoch 10030: loss 0.007469851989299059",
      "\n",
      "epoch 10040: loss 0.005908369552344084",
      "\n",
      "epoch 10050: loss 0.00531940208747983",
      "\n",
      "epoch 10060: loss 0.006543011404573917",
      "\n",
      "epoch 10070: loss 0.005797823891043663",
      "\n",
      "epoch 10080: loss 0.005399638321250677",
      "\n",
      "epoch 10090: loss 0.005868644919246435",
      "\n",
      "epoch 10100: loss 0.005736363120377064",
      "\n",
      "epoch 10110: loss 0.005613243672996759",
      "\n",
      "epoch 10120: loss 0.005561244208365679",
      "\n",
      "epoch 10130: loss 0.005868001841008663",
      "\n",
      "epoch 10140: loss 0.005648921709507704",
      "\n",
      "epoch 10150: loss 0.005621090531349182",
      "\n",
      "epoch 10160: loss 0.006153902038931847",
      "\n",
      "epoch 10170: loss 0.004767605569213629",
      "\n",
      "epoch 10180: loss 0.005251550581306219",
      "\n",
      "epoch 10190: loss 0.005677865352481604",
      "\n",
      "epoch 10200: loss 0.005906704813241959",
      "\n",
      "10200 test percentage 0.9112652694068506",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 10210: loss 0.005851514171808958",
      "\n",
      "epoch 10220: loss 0.0060715461149811745",
      "\n",
      "epoch 10230: loss 0.005348311737179756",
      "\n",
      "epoch 10240: loss 0.005428897216916084",
      "\n",
      "epoch 10250: loss 0.005900008603930473",
      "\n",
      "epoch 10260: loss 0.0062669385224580765",
      "\n",
      "epoch 10270: loss 0.005672331899404526",
      "\n",
      "epoch 10280: loss 0.0055716149508953094",
      "\n",
      "epoch 10290: loss 0.005178151652216911",
      "\n",
      "epoch 10300: loss 0.006156386807560921",
      "\n",
      "epoch 10310: loss 0.005311039742082357",
      "\n",
      "epoch 10320: loss 0.005566004663705826",
      "\n",
      "epoch 10330: loss 0.006504582706838846",
      "\n",
      "epoch 10340: loss 0.005768812261521816",
      "\n",
      "epoch 10350: loss 0.007747964467853308",
      "\n",
      "epoch 10360: loss 0.00566302053630352",
      "\n",
      "epoch 10370: loss 0.00566282169893384",
      "\n",
      "epoch 10380: loss 0.005709229968488216",
      "\n",
      "epoch 10390: loss 0.004927516914904118",
      "\n",
      "epoch 10400: loss 0.0052007162012159824",
      "\n",
      "10400 test percentage 0.9484016084510469",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 10410: loss 0.006177241913974285",
      "\n",
      "epoch 10420: loss 0.005605819635093212",
      "\n",
      "epoch 10430: loss 0.005097502842545509",
      "\n",
      "epoch 10440: loss 0.005937587004154921",
      "\n",
      "epoch 10450: loss 0.006157868076115847",
      "\n",
      "epoch 10460: loss 0.006069832015782595",
      "\n",
      "epoch 10470: loss 0.00625271862372756",
      "\n",
      "epoch 10480: loss 0.00536022474989295",
      "\n",
      "epoch 10490: loss 0.00592613173648715",
      "\n",
      "epoch 10500: loss 0.00558598292991519",
      "\n",
      "epoch 10510: loss 0.0056197308003902435",
      "\n",
      "epoch 10520: loss 0.005764828994870186",
      "\n",
      "epoch 10530: loss 0.005563246551901102",
      "\n",
      "epoch 10540: loss 0.005538912024348974",
      "\n",
      "epoch 10550: loss 0.005538530647754669",
      "\n",
      "epoch 10560: loss 0.0053173513151705265",
      "\n",
      "epoch 10570: loss 0.005816282704472542",
      "\n",
      "epoch 10580: loss 0.005249017849564552",
      "\n",
      "epoch 10590: loss 0.006722947582602501",
      "\n",
      "epoch 10600: loss 0.005020800046622753",
      "\n",
      "10600 test percentage 0.9352990695255506",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 10610: loss 0.005434878170490265",
      "\n",
      "epoch 10620: loss 0.00562702352181077",
      "\n",
      "epoch 10630: loss 0.006373334676027298",
      "\n",
      "epoch 10640: loss 0.005977516993880272",
      "\n",
      "epoch 10650: loss 0.005172119475901127",
      "\n",
      "epoch 10660: loss 0.005137954372912645",
      "\n",
      "epoch 10670: loss 0.005653614178299904",
      "\n",
      "epoch 10680: loss 0.00549724604934454",
      "\n",
      "epoch 10690: loss 0.0052691493183374405",
      "\n",
      "epoch 10700: loss 0.005504766944795847",
      "\n",
      "epoch 10710: loss 0.005394821986556053",
      "\n",
      "epoch 10720: loss 0.0056774853728711605",
      "\n",
      "epoch 10730: loss 0.005907677114009857",
      "\n",
      "epoch 10740: loss 0.0054223244078457355",
      "\n",
      "epoch 10750: loss 0.005284536629915237",
      "\n",
      "epoch 10760: loss 0.005601311102509499",
      "\n",
      "epoch 10770: loss 0.005884141195565462",
      "\n",
      "epoch 10780: loss 0.005556866060942411",
      "\n",
      "epoch 10790: loss 0.004902140703052282",
      "\n",
      "epoch 10800: loss 0.005926780868321657",
      "\n",
      "10800 test percentage 0.9436596785865381",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 10810: loss 0.0058405338786542416",
      "\n",
      "epoch 10820: loss 0.005812082905322313",
      "\n",
      "epoch 10830: loss 0.005607031751424074",
      "\n",
      "epoch 10840: loss 0.006990413181483746",
      "\n",
      "epoch 10850: loss 0.005952469538897276",
      "\n",
      "epoch 10860: loss 0.005641565658152103",
      "\n",
      "epoch 10870: loss 0.005772624164819717",
      "\n",
      "epoch 10880: loss 0.005907705519348383",
      "\n",
      "epoch 10890: loss 0.0062280925922095776",
      "\n",
      "epoch 10900: loss 0.005895198322832584",
      "\n",
      "epoch 10910: loss 0.005784096661955118",
      "\n",
      "epoch 10920: loss 0.005331143271178007",
      "\n",
      "epoch 10930: loss 0.00577851478010416",
      "\n",
      "epoch 10940: loss 0.004930767230689526",
      "\n",
      "epoch 10950: loss 0.006217888090759516",
      "\n",
      "epoch 10960: loss 0.005097904708236456",
      "\n",
      "epoch 10970: loss 0.00599875720217824",
      "\n",
      "epoch 10980: loss 0.005071500316262245",
      "\n",
      "epoch 10990: loss 0.004942767787724733",
      "\n",
      "epoch 11000: loss 0.005607457831501961",
      "\n",
      "11000 test percentage 0.93360130232994",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 11010: loss 0.005946452263742685",
      "\n",
      "epoch 11020: loss 0.004876956809312105",
      "\n",
      "epoch 11030: loss 0.006010286044329405",
      "\n",
      "epoch 11040: loss 0.006216641049832106",
      "\n",
      "epoch 11050: loss 0.005274221766740084",
      "\n",
      "epoch 11060: loss 0.0058797807432711124",
      "\n",
      "epoch 11070: loss 0.005676200147718191",
      "\n",
      "epoch 11080: loss 0.00573290791362524",
      "\n",
      "epoch 11090: loss 0.007077917922288179",
      "\n",
      "epoch 11100: loss 0.005142495036125183",
      "\n",
      "epoch 11110: loss 0.006165588274598122",
      "\n",
      "epoch 11120: loss 0.004758419468998909",
      "\n",
      "epoch 11130: loss 0.005439491011202335",
      "\n",
      "epoch 11140: loss 0.005102439783513546",
      "\n",
      "epoch 11150: loss 0.006211509928107262",
      "\n",
      "epoch 11160: loss 0.005985919386148453",
      "\n",
      "epoch 11170: loss 0.005645215976983309",
      "\n",
      "epoch 11180: loss 0.00660098809748888",
      "\n",
      "epoch 11190: loss 0.005234505049884319",
      "\n",
      "epoch 11200: loss 0.005024107173085213",
      "\n",
      "11200 test percentage 0.8927695106309405",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 11210: loss 0.006140141282230616",
      "\n",
      "epoch 11220: loss 0.005668404046446085",
      "\n",
      "epoch 11230: loss 0.005266232416033745",
      "\n",
      "epoch 11240: loss 0.005335614085197449",
      "\n",
      "epoch 11250: loss 0.004780518356710672",
      "\n",
      "epoch 11260: loss 0.005060297437012196",
      "\n",
      "epoch 11270: loss 0.005212598014622927",
      "\n",
      "epoch 11280: loss 0.006092899478971958",
      "\n",
      "epoch 11290: loss 0.005025028716772795",
      "\n",
      "epoch 11300: loss 0.0052954391576349735",
      "\n",
      "epoch 11310: loss 0.005928983446210623",
      "\n",
      "epoch 11320: loss 0.005322042852640152",
      "\n",
      "epoch 11330: loss 0.005134759936481714",
      "\n",
      "epoch 11340: loss 0.00659190071746707",
      "\n",
      "epoch 11350: loss 0.005278777331113815",
      "\n",
      "epoch 11360: loss 0.005421418230980635",
      "\n",
      "epoch 11370: loss 0.005533767864108086",
      "\n",
      "epoch 11380: loss 0.005853796377778053",
      "\n",
      "epoch 11390: loss 0.0056002940982580185",
      "\n",
      "epoch 11400: loss 0.005056599620729685",
      "\n",
      "11400 test percentage 0.9125413648474765",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 11410: loss 0.005033545196056366",
      "\n",
      "epoch 11420: loss 0.005549827590584755",
      "\n",
      "epoch 11430: loss 0.005271345842629671",
      "\n",
      "epoch 11440: loss 0.00552486814558506",
      "\n",
      "epoch 11450: loss 0.005260122939944267",
      "\n",
      "epoch 11460: loss 0.0054175639525055885",
      "\n",
      "epoch 11470: loss 0.00524069182574749",
      "\n",
      "epoch 11480: loss 0.005488118156790733",
      "\n",
      "epoch 11490: loss 0.005424596834927797",
      "\n",
      "epoch 11500: loss 0.005226225592195988",
      "\n",
      "epoch 11510: loss 0.005966498516499996",
      "\n",
      "epoch 11520: loss 0.005659845657646656",
      "\n",
      "epoch 11530: loss 0.005870921071618795",
      "\n",
      "epoch 11540: loss 0.0049505713395774364",
      "\n",
      "epoch 11550: loss 0.004936735611408949",
      "\n",
      "epoch 11560: loss 0.005610188469290733",
      "\n",
      "epoch 11570: loss 0.004881833214312792",
      "\n",
      "epoch 11580: loss 0.0064595541916787624",
      "\n",
      "epoch 11590: loss 0.005522832274436951",
      "\n",
      "epoch 11600: loss 0.0054997834376990795",
      "\n",
      "11600 test percentage 0.9352896462385903",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 11610: loss 0.0054145329631865025",
      "\n",
      "epoch 11620: loss 0.005419947672635317",
      "\n",
      "epoch 11630: loss 0.005855459254235029",
      "\n",
      "epoch 11640: loss 0.005677464883774519",
      "\n",
      "epoch 11650: loss 0.00495874835178256",
      "\n",
      "epoch 11660: loss 0.005027541425079107",
      "\n",
      "epoch 11670: loss 0.0048704128712415695",
      "\n",
      "epoch 11680: loss 0.005749912466853857",
      "\n",
      "epoch 11690: loss 0.00570607278496027",
      "\n",
      "epoch 11700: loss 0.0049872263334691525",
      "\n",
      "epoch 11710: loss 0.0060511198826134205",
      "\n",
      "epoch 11720: loss 0.005131425801664591",
      "\n",
      "epoch 11730: loss 0.005245171021670103",
      "\n",
      "epoch 11740: loss 0.0055745914578437805",
      "\n",
      "epoch 11750: loss 0.004759552422910929",
      "\n",
      "epoch 11760: loss 0.0049360692501068115",
      "\n",
      "epoch 11770: loss 0.004890798591077328",
      "\n",
      "epoch 11780: loss 0.0051294900476932526",
      "\n",
      "epoch 11790: loss 0.0048759751953184605",
      "\n",
      "epoch 11800: loss 0.005650250241160393",
      "\n",
      "11800 test percentage 0.9170512018514134",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 11810: loss 0.005581891164183617",
      "\n",
      "epoch 11820: loss 0.00549980578944087",
      "\n",
      "epoch 11830: loss 0.005011726636439562",
      "\n",
      "epoch 11840: loss 0.005114658270031214",
      "\n",
      "epoch 11850: loss 0.0050135827623307705",
      "\n",
      "epoch 11860: loss 0.007275471929460764",
      "\n",
      "epoch 11870: loss 0.00527537427842617",
      "\n",
      "epoch 11880: loss 0.005103190429508686",
      "\n",
      "epoch 11890: loss 0.0058883908204734325",
      "\n",
      "epoch 11900: loss 0.005308285355567932",
      "\n",
      "epoch 11910: loss 0.00539933517575264",
      "\n",
      "epoch 11920: loss 0.005084363278001547",
      "\n",
      "epoch 11930: loss 0.005245803855359554",
      "\n",
      "epoch 11940: loss 0.005768044386059046",
      "\n",
      "epoch 11950: loss 0.005226428154855967",
      "\n",
      "epoch 11960: loss 0.005646582692861557",
      "\n",
      "epoch 11970: loss 0.005520972888916731",
      "\n",
      "epoch 11980: loss 0.006712722592055798",
      "\n",
      "epoch 11990: loss 0.005758759565651417",
      "\n",
      "epoch 12000: loss 0.005172091070562601",
      "\n",
      "12000 test percentage 0.941862866265739",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 12010: loss 0.005696508102118969",
      "\n",
      "epoch 12020: loss 0.00574127584695816",
      "\n",
      "epoch 12030: loss 0.005595117807388306",
      "\n",
      "epoch 12040: loss 0.005768460687249899",
      "\n",
      "epoch 12050: loss 0.005390570033341646",
      "\n",
      "epoch 12060: loss 0.004818747751414776",
      "\n",
      "epoch 12070: loss 0.005810198839753866",
      "\n",
      "epoch 12080: loss 0.005279847886413336",
      "\n",
      "epoch 12090: loss 0.00641719251871109",
      "\n",
      "epoch 12100: loss 0.0054729958064854145",
      "\n",
      "epoch 12110: loss 0.004852380603551865",
      "\n",
      "epoch 12120: loss 0.004977196920663118",
      "\n",
      "epoch 12130: loss 0.0057615963742136955",
      "\n",
      "epoch 12140: loss 0.005574951414018869",
      "\n",
      "epoch 12150: loss 0.005705959629267454",
      "\n",
      "epoch 12160: loss 0.0053029474802315235",
      "\n",
      "epoch 12170: loss 0.0055085113272070885",
      "\n",
      "epoch 12180: loss 0.004887545481324196",
      "\n",
      "epoch 12190: loss 0.00596527149900794",
      "\n",
      "epoch 12200: loss 0.005503228399902582",
      "\n",
      "12200 test percentage 0.9453770630019817",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 12210: loss 0.005805314518511295",
      "\n",
      "epoch 12220: loss 0.005964676383882761",
      "\n",
      "epoch 12230: loss 0.006486649625003338",
      "\n",
      "epoch 12240: loss 0.005496394820511341",
      "\n",
      "epoch 12250: loss 0.005032889079302549",
      "\n",
      "epoch 12260: loss 0.006243016105145216",
      "\n",
      "epoch 12270: loss 0.006194098386913538",
      "\n",
      "epoch 12280: loss 0.005892932415008545",
      "\n",
      "epoch 12290: loss 0.006065918132662773",
      "\n",
      "epoch 12300: loss 0.005149643402546644",
      "\n",
      "epoch 12310: loss 0.004700480028986931",
      "\n",
      "epoch 12320: loss 0.0059624481946229935",
      "\n",
      "epoch 12330: loss 0.0060873813927173615",
      "\n",
      "epoch 12340: loss 0.005129639990627766",
      "\n",
      "epoch 12350: loss 0.005591158289462328",
      "\n",
      "epoch 12360: loss 0.00588812492787838",
      "\n",
      "epoch 12370: loss 0.005344065837562084",
      "\n",
      "epoch 12380: loss 0.0049585094675421715",
      "\n",
      "epoch 12390: loss 0.004916653968393803",
      "\n",
      "epoch 12400: loss 0.005834388080984354",
      "\n",
      "12400 test percentage 0.9370819459994366",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 12410: loss 0.004778850823640823",
      "\n",
      "epoch 12420: loss 0.005810313858091831",
      "\n",
      "epoch 12430: loss 0.005601292476058006",
      "\n",
      "epoch 12440: loss 0.006147908978164196",
      "\n",
      "epoch 12450: loss 0.0050900960341095924",
      "\n",
      "epoch 12460: loss 0.005323935765773058",
      "\n",
      "epoch 12470: loss 0.005027391016483307",
      "\n",
      "epoch 12480: loss 0.005129499360918999",
      "\n",
      "epoch 12490: loss 0.005143596790730953",
      "\n",
      "epoch 12500: loss 0.005387168377637863",
      "\n",
      "epoch 12510: loss 0.004514224827289581",
      "\n",
      "epoch 12520: loss 0.0047523160465061665",
      "\n",
      "epoch 12530: loss 0.005031069740653038",
      "\n",
      "epoch 12540: loss 0.00538614159449935",
      "\n",
      "epoch 12550: loss 0.005548004526644945",
      "\n",
      "epoch 12560: loss 0.004980112891644239",
      "\n",
      "epoch 12570: loss 0.004907527938485146",
      "\n",
      "epoch 12580: loss 0.005328221712261438",
      "\n",
      "epoch 12590: loss 0.004681338090449572",
      "\n",
      "epoch 12600: loss 0.005354525521397591",
      "\n",
      "12600 test percentage 0.9208585694181397",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 12610: loss 0.004794861190021038",
      "\n",
      "epoch 12620: loss 0.0049572112038731575",
      "\n",
      "epoch 12630: loss 0.005147838965058327",
      "\n",
      "epoch 12640: loss 0.005324805621057749",
      "\n",
      "epoch 12650: loss 0.004934276454150677",
      "\n",
      "epoch 12660: loss 0.004850928205996752",
      "\n",
      "epoch 12670: loss 0.0053288694471120834",
      "\n",
      "epoch 12680: loss 0.005144217051565647",
      "\n",
      "epoch 12690: loss 0.0053912741132080555",
      "\n",
      "epoch 12700: loss 0.005553797818720341",
      "\n",
      "epoch 12710: loss 0.005301708821207285",
      "\n",
      "epoch 12720: loss 0.0051035452634096146",
      "\n",
      "epoch 12730: loss 0.005819983780384064",
      "\n",
      "epoch 12740: loss 0.005421960260719061",
      "\n",
      "epoch 12750: loss 0.004715948831290007",
      "\n",
      "epoch 12760: loss 0.005042942240834236",
      "\n",
      "epoch 12770: loss 0.004698128905147314",
      "\n",
      "epoch 12780: loss 0.0048986016772687435",
      "\n",
      "epoch 12790: loss 0.0056109316647052765",
      "\n",
      "epoch 12800: loss 0.004644491244107485",
      "\n",
      "12800 test percentage 0.9310092091158986",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 12810: loss 0.005358361639082432",
      "\n",
      "epoch 12820: loss 0.005696538835763931",
      "\n",
      "epoch 12830: loss 0.004521810449659824",
      "\n",
      "epoch 12840: loss 0.004946919158101082",
      "\n",
      "epoch 12850: loss 0.005134626291692257",
      "\n",
      "epoch 12860: loss 0.0056486171670258045",
      "\n",
      "epoch 12870: loss 0.0065634665079414845",
      "\n",
      "epoch 12880: loss 0.0048416792415082455",
      "\n",
      "epoch 12890: loss 0.005501605104655027",
      "\n",
      "epoch 12900: loss 0.00564343947917223",
      "\n",
      "epoch 12910: loss 0.00615469878539443",
      "\n",
      "epoch 12920: loss 0.005340812727808952",
      "\n",
      "epoch 12930: loss 0.00517592579126358",
      "\n",
      "epoch 12940: loss 0.00492839515209198",
      "\n",
      "epoch 12950: loss 0.004731076769530773",
      "\n",
      "epoch 12960: loss 0.005094388499855995",
      "\n",
      "epoch 12970: loss 0.00556144816800952",
      "\n",
      "epoch 12980: loss 0.00457403901964426",
      "\n",
      "epoch 12990: loss 0.005329266656190157",
      "\n",
      "epoch 13000: loss 0.005357412155717611",
      "\n",
      "13000 test percentage 0.9160378196022727",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 13010: loss 0.005115114618092775",
      "\n",
      "epoch 13020: loss 0.004578057676553726",
      "\n",
      "epoch 13030: loss 0.004887774121016264",
      "\n",
      "epoch 13040: loss 0.004784297198057175",
      "\n",
      "epoch 13050: loss 0.005171357188373804",
      "\n",
      "epoch 13060: loss 0.005246659275144339",
      "\n",
      "epoch 13070: loss 0.0048687150701880455",
      "\n",
      "epoch 13080: loss 0.0056802514009177685",
      "\n",
      "epoch 13090: loss 0.005535233300179243",
      "\n",
      "epoch 13100: loss 0.005683771800249815",
      "\n",
      "epoch 13110: loss 0.005297350697219372",
      "\n",
      "epoch 13120: loss 0.005772648379206657",
      "\n",
      "epoch 13130: loss 0.005815260577946901",
      "\n",
      "epoch 13140: loss 0.004992115311324596",
      "\n",
      "epoch 13150: loss 0.004952503368258476",
      "\n",
      "epoch 13160: loss 0.004869661293923855",
      "\n",
      "epoch 13170: loss 0.005167071241885424",
      "\n",
      "epoch 13180: loss 0.005044833291321993",
      "\n",
      "epoch 13190: loss 0.005468332674354315",
      "\n",
      "epoch 13200: loss 0.00459651742130518",
      "\n",
      "13200 test percentage 0.915020541309909",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 13210: loss 0.006220145616680384",
      "\n",
      "epoch 13220: loss 0.005372110288590193",
      "\n",
      "epoch 13230: loss 0.005416409112513065",
      "\n",
      "epoch 13240: loss 0.0052478075958788395",
      "\n",
      "epoch 13250: loss 0.00537461880594492",
      "\n",
      "epoch 13260: loss 0.0045494986698031425",
      "\n",
      "epoch 13270: loss 0.004907097201794386",
      "\n",
      "epoch 13280: loss 0.004869680851697922",
      "\n",
      "epoch 13290: loss 0.0053036268800497055",
      "\n",
      "epoch 13300: loss 0.0052843545563519",
      "\n",
      "epoch 13310: loss 0.005370881408452988",
      "\n",
      "epoch 13320: loss 0.005559992045164108",
      "\n",
      "epoch 13330: loss 0.0050635188817977905",
      "\n",
      "epoch 13340: loss 0.0055486056953668594",
      "\n",
      "epoch 13350: loss 0.00558496406301856",
      "\n",
      "epoch 13360: loss 0.005557416006922722",
      "\n",
      "epoch 13370: loss 0.0055342912673950195",
      "\n",
      "epoch 13380: loss 0.005928169935941696",
      "\n",
      "epoch 13390: loss 0.005268011707812548",
      "\n",
      "epoch 13400: loss 0.005163239315152168",
      "\n",
      "13400 test percentage 0.9323362228444931",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 13410: loss 0.005766766611486673",
      "\n",
      "epoch 13420: loss 0.005075396038591862",
      "\n",
      "epoch 13430: loss 0.0054068369790911674",
      "\n",
      "epoch 13440: loss 0.005407464224845171",
      "\n",
      "epoch 13450: loss 0.005706116557121277",
      "\n",
      "epoch 13460: loss 0.004211760126054287",
      "\n",
      "epoch 13470: loss 0.004734760615974665",
      "\n",
      "epoch 13480: loss 0.005133507773280144",
      "\n",
      "epoch 13490: loss 0.005452459678053856",
      "\n",
      "epoch 13500: loss 0.004988254979252815",
      "\n",
      "epoch 13510: loss 0.004651051014661789",
      "\n",
      "epoch 13520: loss 0.005155849736183882",
      "\n",
      "epoch 13530: loss 0.005263905040919781",
      "\n",
      "epoch 13540: loss 0.004806479439139366",
      "\n",
      "epoch 13550: loss 0.005822011269629002",
      "\n",
      "epoch 13560: loss 0.005108024924993515",
      "\n",
      "epoch 13570: loss 0.005177952349185944",
      "\n",
      "epoch 13580: loss 0.004961655009537935",
      "\n",
      "epoch 13590: loss 0.0046323142014443874",
      "\n",
      "epoch 13600: loss 0.0049852775409817696",
      "\n",
      "13600 test percentage 0.9441789911786046",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 13610: loss 0.004713570233434439",
      "\n",
      "epoch 13620: loss 0.0059036859311163425",
      "\n",
      "epoch 13630: loss 0.005600603297352791",
      "\n",
      "epoch 13640: loss 0.005015497095882893",
      "\n",
      "epoch 13650: loss 0.005272031296044588",
      "\n",
      "epoch 13660: loss 0.004917433951050043",
      "\n",
      "epoch 13670: loss 0.005386170465499163",
      "\n",
      "epoch 13680: loss 0.005053402855992317",
      "\n",
      "epoch 13690: loss 0.005641707219183445",
      "\n",
      "epoch 13700: loss 0.004930050577968359",
      "\n",
      "epoch 13710: loss 0.005266477353870869",
      "\n",
      "epoch 13720: loss 0.005572004243731499",
      "\n",
      "epoch 13730: loss 0.004493068438023329",
      "\n",
      "epoch 13740: loss 0.005193097982555628",
      "\n",
      "epoch 13750: loss 0.004401667509227991",
      "\n",
      "epoch 13760: loss 0.005642535164952278",
      "\n",
      "epoch 13770: loss 0.005176337901502848",
      "\n",
      "epoch 13780: loss 0.0049690138548612595",
      "\n",
      "epoch 13790: loss 0.0053353444673120975",
      "\n",
      "epoch 13800: loss 0.005122814793139696",
      "\n",
      "13800 test percentage 0.9466930436499325",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 13810: loss 0.004861279856413603",
      "\n",
      "epoch 13820: loss 0.0049482183530926704",
      "\n",
      "epoch 13830: loss 0.00520162470638752",
      "\n",
      "epoch 13840: loss 0.004464802332222462",
      "\n",
      "epoch 13850: loss 0.004869819153100252",
      "\n",
      "epoch 13860: loss 0.0060411845333874226",
      "\n",
      "epoch 13870: loss 0.005349217914044857",
      "\n",
      "epoch 13880: loss 0.005212353076785803",
      "\n",
      "epoch 13890: loss 0.005003477446734905",
      "\n",
      "epoch 13900: loss 0.0053382758051157",
      "\n",
      "epoch 13910: loss 0.005865718703716993",
      "\n",
      "epoch 13920: loss 0.004895257763564587",
      "\n",
      "epoch 13930: loss 0.005395686719566584",
      "\n",
      "epoch 13940: loss 0.005843079648911953",
      "\n",
      "epoch 13950: loss 0.0052832686342298985",
      "\n",
      "epoch 13960: loss 0.005987715907394886",
      "\n",
      "epoch 13970: loss 0.004800043068826199",
      "\n",
      "epoch 13980: loss 0.004671759903430939",
      "\n",
      "epoch 13990: loss 0.005224268883466721",
      "\n",
      "epoch 14000: loss 0.006004110909998417",
      "\n",
      "14000 test percentage 0.94803604399984",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 14010: loss 0.0050426688976585865",
      "\n",
      "epoch 14020: loss 0.004886128939688206",
      "\n",
      "epoch 14030: loss 0.004650707356631756",
      "\n",
      "epoch 14040: loss 0.0049437182024121284",
      "\n",
      "epoch 14050: loss 0.004782370291650295",
      "\n",
      "epoch 14060: loss 0.0052051059901714325",
      "\n",
      "epoch 14070: loss 0.006375686265528202",
      "\n",
      "epoch 14080: loss 0.0043445760384202",
      "\n",
      "epoch 14090: loss 0.00498731667175889",
      "\n",
      "epoch 14100: loss 0.005683021619915962",
      "\n",
      "epoch 14110: loss 0.005008096806704998",
      "\n",
      "epoch 14120: loss 0.004924720153212547",
      "\n",
      "epoch 14130: loss 0.0056809005327522755",
      "\n",
      "epoch 14140: loss 0.005979008972644806",
      "\n",
      "epoch 14150: loss 0.004830676130950451",
      "\n",
      "epoch 14160: loss 0.005056297406554222",
      "\n",
      "epoch 14170: loss 0.005386322736740112",
      "\n",
      "epoch 14180: loss 0.0054717701859772205",
      "\n",
      "epoch 14190: loss 0.005861898418515921",
      "\n",
      "epoch 14200: loss 0.005201517138630152",
      "\n",
      "14200 test percentage 0.948292827499167",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 14210: loss 0.0052681113593280315",
      "\n",
      "epoch 14220: loss 0.006476758047938347",
      "\n",
      "epoch 14230: loss 0.005065123084932566",
      "\n",
      "epoch 14240: loss 0.0045493957586586475",
      "\n",
      "epoch 14250: loss 0.006049572490155697",
      "\n",
      "epoch 14260: loss 0.005404830910265446",
      "\n",
      "epoch 14270: loss 0.005418985150754452",
      "\n",
      "epoch 14280: loss 0.005122482776641846",
      "\n",
      "epoch 14290: loss 0.005646720994263887",
      "\n",
      "epoch 14300: loss 0.005190595518797636",
      "\n",
      "epoch 14310: loss 0.0056451777927577496",
      "\n",
      "epoch 14320: loss 0.0046172793954610825",
      "\n",
      "epoch 14330: loss 0.004819207359105349",
      "\n",
      "epoch 14340: loss 0.006826766300946474",
      "\n",
      "epoch 14350: loss 0.005667711142450571",
      "\n",
      "epoch 14360: loss 0.0055664656683802605",
      "\n",
      "epoch 14370: loss 0.005189850460737944",
      "\n",
      "epoch 14380: loss 0.005154490936547518",
      "\n",
      "epoch 14390: loss 0.004518777597695589",
      "\n",
      "epoch 14400: loss 0.005301884841173887",
      "\n",
      "14400 test percentage 0.9453947835765971",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 14410: loss 0.004677681718021631",
      "\n",
      "epoch 14420: loss 0.00498849106952548",
      "\n",
      "epoch 14430: loss 0.005422049667686224",
      "\n",
      "epoch 14440: loss 0.005096044857054949",
      "\n",
      "epoch 14450: loss 0.006012692116200924",
      "\n",
      "epoch 14460: loss 0.00512644462287426",
      "\n",
      "epoch 14470: loss 0.004637246020138264",
      "\n",
      "epoch 14480: loss 0.004732782021164894",
      "\n",
      "epoch 14490: loss 0.004722930956631899",
      "\n",
      "epoch 14500: loss 0.0050045340321958065",
      "\n",
      "epoch 14510: loss 0.0049351174384355545",
      "\n",
      "epoch 14520: loss 0.005888594780117273",
      "\n",
      "epoch 14530: loss 0.004814871586859226",
      "\n",
      "epoch 14540: loss 0.005413639359176159",
      "\n",
      "epoch 14550: loss 0.006031001452356577",
      "\n",
      "epoch 14560: loss 0.005304543301463127",
      "\n",
      "epoch 14570: loss 0.005165437236428261",
      "\n",
      "epoch 14580: loss 0.004393518436700106",
      "\n",
      "epoch 14590: loss 0.0057555860839784145",
      "\n",
      "epoch 14600: loss 0.00436966959387064",
      "\n",
      "14600 test percentage 0.9543556358945356",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 14610: loss 0.005155292805284262",
      "\n",
      "epoch 14620: loss 0.004788556601852179",
      "\n",
      "epoch 14630: loss 0.004925002343952656",
      "\n",
      "epoch 14640: loss 0.005803491920232773",
      "\n",
      "epoch 14650: loss 0.004851809237152338",
      "\n",
      "epoch 14660: loss 0.005116503685712814",
      "\n",
      "epoch 14670: loss 0.0051033287309110165",
      "\n",
      "epoch 14680: loss 0.005919549148529768",
      "\n",
      "epoch 14690: loss 0.004750856664031744",
      "\n",
      "epoch 14700: loss 0.005067341960966587",
      "\n",
      "epoch 14710: loss 0.004730097949504852",
      "\n",
      "epoch 14720: loss 0.005790418013930321",
      "\n",
      "epoch 14730: loss 0.004236213862895966",
      "\n",
      "epoch 14740: loss 0.004784286022186279",
      "\n",
      "epoch 14750: loss 0.006190659012645483",
      "\n",
      "epoch 14760: loss 0.00535149360075593",
      "\n",
      "epoch 14770: loss 0.004922498483210802",
      "\n",
      "epoch 14780: loss 0.0045873308554291725",
      "\n",
      "epoch 14790: loss 0.005449438933283091",
      "\n",
      "epoch 14800: loss 0.005199171137064695",
      "\n",
      "14800 test percentage 0.9332940243978961",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 14810: loss 0.0052570137195289135",
      "\n",
      "epoch 14820: loss 0.004728357307612896",
      "\n",
      "epoch 14830: loss 0.006440829951316118",
      "\n",
      "epoch 14840: loss 0.0052382019348442554",
      "\n",
      "epoch 14850: loss 0.005239412188529968",
      "\n",
      "epoch 14860: loss 0.005160789005458355",
      "\n",
      "epoch 14870: loss 0.00505101028829813",
      "\n",
      "epoch 14880: loss 0.004756774287670851",
      "\n",
      "epoch 14890: loss 0.004627550952136517",
      "\n",
      "epoch 14900: loss 0.0049811070784926414",
      "\n",
      "epoch 14910: loss 0.005599960684776306",
      "\n",
      "epoch 14920: loss 0.0047356560826301575",
      "\n",
      "epoch 14930: loss 0.00512316357344389",
      "\n",
      "epoch 14940: loss 0.0046871439553797245",
      "\n",
      "epoch 14950: loss 0.00476804981008172",
      "\n",
      "epoch 14960: loss 0.005275100003927946",
      "\n",
      "epoch 14970: loss 0.006158972624689341",
      "\n",
      "epoch 14980: loss 0.005257825367152691",
      "\n",
      "epoch 14990: loss 0.00590866943821311",
      "\n",
      "epoch 15000: loss 0.00480635417625308",
      "\n",
      "15000 test percentage 0.9468433067587222",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 15010: loss 0.005522015504539013",
      "\n",
      "epoch 15020: loss 0.005253657232969999",
      "\n",
      "epoch 15030: loss 0.004942185711115599",
      "\n",
      "epoch 15040: loss 0.005146116483956575",
      "\n",
      "epoch 15050: loss 0.004910656251013279",
      "\n",
      "epoch 15060: loss 0.004622083157300949",
      "\n",
      "epoch 15070: loss 0.006012891884893179",
      "\n",
      "epoch 15080: loss 0.005317377857863903",
      "\n",
      "epoch 15090: loss 0.004533766768872738",
      "\n",
      "epoch 15100: loss 0.0044641438871622086",
      "\n",
      "epoch 15110: loss 0.005770908668637276",
      "\n",
      "epoch 15120: loss 0.006047497037798166",
      "\n",
      "epoch 15130: loss 0.005021262913942337",
      "\n",
      "epoch 15140: loss 0.004454626236110926",
      "\n",
      "epoch 15150: loss 0.005596201866865158",
      "\n",
      "epoch 15160: loss 0.005226483102887869",
      "\n",
      "epoch 15170: loss 0.00454337801784277",
      "\n",
      "epoch 15180: loss 0.004316364414989948",
      "\n",
      "epoch 15190: loss 0.006461411714553833",
      "\n",
      "epoch 15200: loss 0.005734815262258053",
      "\n",
      "15200 test percentage 0.9479346055909573",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 15210: loss 0.004758815281093121",
      "\n",
      "epoch 15220: loss 0.004909873940050602",
      "\n",
      "epoch 15230: loss 0.005210378672927618",
      "\n",
      "epoch 15240: loss 0.00481033930554986",
      "\n",
      "epoch 15250: loss 0.005329350475221872",
      "\n",
      "epoch 15260: loss 0.004945801571011543",
      "\n",
      "epoch 15270: loss 0.0050828722305595875",
      "\n",
      "epoch 15280: loss 0.0048022945411503315",
      "\n",
      "epoch 15290: loss 0.004964042454957962",
      "\n",
      "epoch 15300: loss 0.005116073414683342",
      "\n",
      "epoch 15310: loss 0.0051803262904286385",
      "\n",
      "epoch 15320: loss 0.005477867554873228",
      "\n",
      "epoch 15330: loss 0.004692265763878822",
      "\n",
      "epoch 15340: loss 0.006084189284592867",
      "\n",
      "epoch 15350: loss 0.00517489155754447",
      "\n",
      "epoch 15360: loss 0.005531250964850187",
      "\n",
      "epoch 15370: loss 0.004788685590028763",
      "\n",
      "epoch 15380: loss 0.004803608637303114",
      "\n",
      "epoch 15390: loss 0.0048657869920134544",
      "\n",
      "epoch 15400: loss 0.005166064947843552",
      "\n",
      "15400 test percentage 0.9313971008917298",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 15410: loss 0.004717507865279913",
      "\n",
      "epoch 15420: loss 0.004928068723529577",
      "\n",
      "epoch 15430: loss 0.006461207754909992",
      "\n",
      "epoch 15440: loss 0.0045804367400705814",
      "\n",
      "epoch 15450: loss 0.005479970946907997",
      "\n",
      "epoch 15460: loss 0.0048135011456906796",
      "\n",
      "epoch 15470: loss 0.005427873693406582",
      "\n",
      "epoch 15480: loss 0.005173579789698124",
      "\n",
      "epoch 15490: loss 0.004515360109508038",
      "\n",
      "epoch 15500: loss 0.005351482890546322",
      "\n",
      "epoch 15510: loss 0.004817817360162735",
      "\n",
      "epoch 15520: loss 0.005392405204474926",
      "\n",
      "epoch 15530: loss 0.0051848022267222404",
      "\n",
      "epoch 15540: loss 0.005616375710815191",
      "\n",
      "epoch 15550: loss 0.004365354776382446",
      "\n",
      "epoch 15560: loss 0.004587728064507246",
      "\n",
      "epoch 15570: loss 0.005542214494198561",
      "\n",
      "epoch 15580: loss 0.0049598789773881435",
      "\n",
      "epoch 15590: loss 0.00535510154440999",
      "\n",
      "epoch 15600: loss 0.004584422335028648",
      "\n",
      "15600 test percentage 0.937787682119042",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 15610: loss 0.004423315636813641",
      "\n",
      "epoch 15620: loss 0.004597983788698912",
      "\n",
      "epoch 15630: loss 0.005041060037910938",
      "\n",
      "epoch 15640: loss 0.004652740433812141",
      "\n",
      "epoch 15650: loss 0.004069556947797537",
      "\n",
      "epoch 15660: loss 0.005635492037981749",
      "\n",
      "epoch 15670: loss 0.004831569269299507",
      "\n",
      "epoch 15680: loss 0.005157261621206999",
      "\n",
      "epoch 15690: loss 0.004646590445190668",
      "\n",
      "epoch 15700: loss 0.0050193388015031815",
      "\n",
      "epoch 15710: loss 0.005418180953711271",
      "\n",
      "epoch 15720: loss 0.004786073695868254",
      "\n",
      "epoch 15730: loss 0.0045496695674955845",
      "\n",
      "epoch 15740: loss 0.004708761349320412",
      "\n",
      "epoch 15750: loss 0.005312227178364992",
      "\n",
      "epoch 15760: loss 0.005918802227824926",
      "\n",
      "epoch 15770: loss 0.004848708864301443",
      "\n",
      "epoch 15780: loss 0.004406994208693504",
      "\n",
      "epoch 15790: loss 0.004692693240940571",
      "\n",
      "epoch 15800: loss 0.004901017993688583",
      "\n",
      "15800 test percentage 0.9339507217492854",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 15810: loss 0.005342444404959679",
      "\n",
      "epoch 15820: loss 0.0050558121874928474",
      "\n",
      "epoch 15830: loss 0.005573329050093889",
      "\n",
      "epoch 15840: loss 0.004583746660500765",
      "\n",
      "epoch 15850: loss 0.006500133313238621",
      "\n",
      "epoch 15860: loss 0.0047605326399207115",
      "\n",
      "epoch 15870: loss 0.005237093195319176",
      "\n",
      "epoch 15880: loss 0.005133781116455793",
      "\n",
      "epoch 15890: loss 0.005080200731754303",
      "\n",
      "epoch 15900: loss 0.005268140230327845",
      "\n",
      "epoch 15910: loss 0.00468451576307416",
      "\n",
      "epoch 15920: loss 0.005262753926217556",
      "\n",
      "epoch 15930: loss 0.005145451053977013",
      "\n",
      "epoch 15940: loss 0.004761018790304661",
      "\n",
      "epoch 15950: loss 0.0049316976219415665",
      "\n",
      "epoch 15960: loss 0.004418099764734507",
      "\n",
      "epoch 15970: loss 0.004834427032619715",
      "\n",
      "epoch 15980: loss 0.005036602262407541",
      "\n",
      "epoch 15990: loss 0.00518483342602849",
      "\n",
      "epoch 16000: loss 0.006375695113092661",
      "\n",
      "16000 test percentage 0.9259657426313921",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 16010: loss 0.005743972957134247",
      "\n",
      "epoch 16020: loss 0.004774373956024647",
      "\n",
      "epoch 16030: loss 0.005300574935972691",
      "\n",
      "epoch 16040: loss 0.005069221369922161",
      "\n",
      "epoch 16050: loss 0.003995170816779137",
      "\n",
      "epoch 16060: loss 0.004823613911867142",
      "\n",
      "epoch 16070: loss 0.0050679827108979225",
      "\n",
      "epoch 16080: loss 0.005407944321632385",
      "\n",
      "epoch 16090: loss 0.006063241511583328",
      "\n",
      "epoch 16100: loss 0.004772585816681385",
      "\n",
      "epoch 16110: loss 0.00452124048024416",
      "\n",
      "epoch 16120: loss 0.004898362793028355",
      "\n",
      "epoch 16130: loss 0.006114335265010595",
      "\n",
      "epoch 16140: loss 0.005032836925238371",
      "\n",
      "epoch 16150: loss 0.005476977676153183",
      "\n",
      "epoch 16160: loss 0.004334345459938049",
      "\n",
      "epoch 16170: loss 0.0046146335080266",
      "\n",
      "epoch 16180: loss 0.004928735550493002",
      "\n",
      "epoch 16190: loss 0.00430016266182065",
      "\n",
      "epoch 16200: loss 0.005425230599939823",
      "\n",
      "16200 test percentage 0.9259112151517344",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 16210: loss 0.004528059158474207",
      "\n",
      "epoch 16220: loss 0.005001591518521309",
      "\n",
      "epoch 16230: loss 0.004323413595557213",
      "\n",
      "epoch 16240: loss 0.005630857311189175",
      "\n",
      "epoch 16250: loss 0.00557731743901968",
      "\n",
      "epoch 16260: loss 0.0055512017570436",
      "\n",
      "epoch 16270: loss 0.005108366720378399",
      "\n",
      "epoch 16280: loss 0.004511100705713034",
      "\n",
      "epoch 16290: loss 0.004615501035004854",
      "\n",
      "epoch 16300: loss 0.005800442770123482",
      "\n",
      "epoch 16310: loss 0.004637951031327248",
      "\n",
      "epoch 16320: loss 0.005173008423298597",
      "\n",
      "epoch 16330: loss 0.005035872105509043",
      "\n",
      "epoch 16340: loss 0.005047909915447235",
      "\n",
      "epoch 16350: loss 0.006087239366024733",
      "\n",
      "epoch 16360: loss 0.005451475735753775",
      "\n",
      "epoch 16370: loss 0.0057730344124138355",
      "\n",
      "epoch 16380: loss 0.005187732167541981",
      "\n",
      "epoch 16390: loss 0.004811078310012817",
      "\n",
      "epoch 16400: loss 0.004692611750215292",
      "\n",
      "16400 test percentage 0.9482447777265384",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 16410: loss 0.005556466989219189",
      "\n",
      "epoch 16420: loss 0.00534079410135746",
      "\n",
      "epoch 16430: loss 0.005162748973816633",
      "\n",
      "epoch 16440: loss 0.005612731911242008",
      "\n",
      "epoch 16450: loss 0.004340874496847391",
      "\n",
      "epoch 16460: loss 0.004998703487217426",
      "\n",
      "epoch 16470: loss 0.004936797544360161",
      "\n",
      "epoch 16480: loss 0.004433801397681236",
      "\n",
      "epoch 16490: loss 0.005235010292381048",
      "\n",
      "epoch 16500: loss 0.004925404209643602",
      "\n",
      "epoch 16510: loss 0.004647158086299896",
      "\n",
      "epoch 16520: loss 0.005632795859128237",
      "\n",
      "epoch 16530: loss 0.004995399620383978",
      "\n",
      "epoch 16540: loss 0.0044012656435370445",
      "\n",
      "epoch 16550: loss 0.005306092090904713",
      "\n",
      "epoch 16560: loss 0.0052983518689870834",
      "\n",
      "epoch 16570: loss 0.005291457753628492",
      "\n",
      "epoch 16580: loss 0.005238801706582308",
      "\n",
      "epoch 16590: loss 0.005165547132492065",
      "\n",
      "epoch 16600: loss 0.005087554454803467",
      "\n",
      "16600 test percentage 0.9446125822570322",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 16610: loss 0.004930941388010979",
      "\n",
      "epoch 16620: loss 0.005232823081314564",
      "\n",
      "epoch 16630: loss 0.005631322972476482",
      "\n",
      "epoch 16640: loss 0.005684427917003632",
      "\n",
      "epoch 16650: loss 0.00462909834459424",
      "\n",
      "epoch 16660: loss 0.005258180201053619",
      "\n",
      "epoch 16670: loss 0.006005346775054932",
      "\n",
      "epoch 16680: loss 0.005246913060545921",
      "\n",
      "epoch 16690: loss 0.004681018181145191",
      "\n",
      "epoch 16700: loss 0.004207264631986618",
      "\n",
      "epoch 16710: loss 0.00435582734644413",
      "\n",
      "epoch 16720: loss 0.004939096514135599",
      "\n",
      "epoch 16730: loss 0.004852518439292908",
      "\n",
      "epoch 16740: loss 0.004366777837276459",
      "\n",
      "epoch 16750: loss 0.005032137036323547",
      "\n",
      "epoch 16760: loss 0.004802389070391655",
      "\n",
      "epoch 16770: loss 0.00524162920191884",
      "\n",
      "epoch 16780: loss 0.005648009013384581",
      "\n",
      "epoch 16790: loss 0.004602373577654362",
      "\n",
      "epoch 16800: loss 0.0045776814222335815",
      "\n",
      "16800 test percentage 0.9508525407407955",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 16810: loss 0.005394350737333298",
      "\n",
      "epoch 16820: loss 0.005385230295360088",
      "\n",
      "epoch 16830: loss 0.0046533686108887196",
      "\n",
      "epoch 16840: loss 0.005395316984504461",
      "\n",
      "epoch 16850: loss 0.0041899834759533405",
      "\n",
      "epoch 16860: loss 0.00413600355386734",
      "\n",
      "epoch 16870: loss 0.00533005315810442",
      "\n",
      "epoch 16880: loss 0.00494791753590107",
      "\n",
      "epoch 16890: loss 0.004825424402952194",
      "\n",
      "epoch 16900: loss 0.0059459093026816845",
      "\n",
      "epoch 16910: loss 0.005825545638799667",
      "\n",
      "epoch 16920: loss 0.004493658896535635",
      "\n",
      "epoch 16930: loss 0.0039051382336765528",
      "\n",
      "epoch 16940: loss 0.004548503551632166",
      "\n",
      "epoch 16950: loss 0.005374461878091097",
      "\n",
      "epoch 16960: loss 0.00466674380004406",
      "\n",
      "epoch 16970: loss 0.006574270315468311",
      "\n",
      "epoch 16980: loss 0.005630628205835819",
      "\n",
      "epoch 16990: loss 0.00475411769002676",
      "\n",
      "epoch 17000: loss 0.005432347301393747",
      "\n",
      "17000 test percentage 0.9508292458274148",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 17010: loss 0.0044125947169959545",
      "\n",
      "epoch 17020: loss 0.0054899887181818485",
      "\n",
      "epoch 17030: loss 0.004539964254945517",
      "\n",
      "epoch 17040: loss 0.003992671612650156",
      "\n",
      "epoch 17050: loss 0.004371390677988529",
      "\n",
      "epoch 17060: loss 0.005181252025067806",
      "\n",
      "epoch 17070: loss 0.005059330724179745",
      "\n",
      "epoch 17080: loss 0.004806223325431347",
      "\n",
      "epoch 17090: loss 0.0048823123797774315",
      "\n",
      "epoch 17100: loss 0.004698514007031918",
      "\n",
      "epoch 17110: loss 0.0055536916479468346",
      "\n",
      "epoch 17120: loss 0.004555198363959789",
      "\n",
      "epoch 17130: loss 0.005400320515036583",
      "\n",
      "epoch 17140: loss 0.00465793814510107",
      "\n",
      "epoch 17150: loss 0.004767698235809803",
      "\n",
      "epoch 17160: loss 0.004416970536112785",
      "\n",
      "epoch 17170: loss 0.0048211743123829365",
      "\n",
      "epoch 17180: loss 0.004911168944090605",
      "\n",
      "epoch 17190: loss 0.005441426299512386",
      "\n",
      "epoch 17200: loss 0.0051836720667779446",
      "\n",
      "17200 test percentage 0.8971021504514547",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 17210: loss 0.005450357683002949",
      "\n",
      "epoch 17220: loss 0.005338692106306553",
      "\n",
      "epoch 17230: loss 0.005163702182471752",
      "\n",
      "epoch 17240: loss 0.004574614576995373",
      "\n",
      "epoch 17250: loss 0.006430124863982201",
      "\n",
      "epoch 17260: loss 0.004861754365265369",
      "\n",
      "epoch 17270: loss 0.005311579443514347",
      "\n",
      "epoch 17280: loss 0.005379228387027979",
      "\n",
      "epoch 17290: loss 0.004875788930803537",
      "\n",
      "epoch 17300: loss 0.0063586002215743065",
      "\n",
      "epoch 17310: loss 0.004642011597752571",
      "\n",
      "epoch 17320: loss 0.004968167748302221",
      "\n",
      "epoch 17330: loss 0.0054024988785386086",
      "\n",
      "epoch 17340: loss 0.0044661215506494045",
      "\n",
      "epoch 17350: loss 0.004884038586169481",
      "\n",
      "epoch 17360: loss 0.0048102145083248615",
      "\n",
      "epoch 17370: loss 0.004365978762507439",
      "\n",
      "epoch 17380: loss 0.004959847778081894",
      "\n",
      "epoch 17390: loss 0.004824488423764706",
      "\n",
      "epoch 17400: loss 0.004738891497254372",
      "\n",
      "17400 test percentage 0.9475250886345552",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 17410: loss 0.005825914908200502",
      "\n",
      "epoch 17420: loss 0.0054199909791350365",
      "\n",
      "epoch 17430: loss 0.00533038517460227",
      "\n",
      "epoch 17440: loss 0.00500310305505991",
      "\n",
      "epoch 17450: loss 0.005026054102927446",
      "\n",
      "epoch 17460: loss 0.005174304824322462",
      "\n",
      "epoch 17470: loss 0.004907957743853331",
      "\n",
      "epoch 17480: loss 0.00477784825488925",
      "\n",
      "epoch 17490: loss 0.004708724562078714",
      "\n",
      "epoch 17500: loss 0.005198970437049866",
      "\n",
      "epoch 17510: loss 0.005820142105221748",
      "\n",
      "epoch 17520: loss 0.0047653731890022755",
      "\n",
      "epoch 17530: loss 0.004708157852292061",
      "\n",
      "epoch 17540: loss 0.00470023462548852",
      "\n",
      "epoch 17550: loss 0.004667116794735193",
      "\n",
      "epoch 17560: loss 0.004655377473682165",
      "\n",
      "epoch 17570: loss 0.0048343767412006855",
      "\n",
      "epoch 17580: loss 0.004670743830502033",
      "\n",
      "epoch 17590: loss 0.004504492972046137",
      "\n",
      "epoch 17600: loss 0.00490965973585844",
      "\n",
      "17600 test percentage 0.9488956010435299",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 17610: loss 0.0055220830254256725",
      "\n",
      "epoch 17620: loss 0.00471846666187048",
      "\n",
      "epoch 17630: loss 0.004565986804664135",
      "\n",
      "epoch 17640: loss 0.005004232749342918",
      "\n",
      "epoch 17650: loss 0.0047810012474656105",
      "\n",
      "epoch 17660: loss 0.0061435215175151825",
      "\n",
      "epoch 17670: loss 0.00458401208743453",
      "\n",
      "epoch 17680: loss 0.0057108839973807335",
      "\n",
      "epoch 17690: loss 0.004880615975707769",
      "\n",
      "epoch 17700: loss 0.005728327669203281",
      "\n",
      "epoch 17710: loss 0.0046252901665866375",
      "\n",
      "epoch 17720: loss 0.004780404735356569",
      "\n",
      "epoch 17730: loss 0.004844612907618284",
      "\n",
      "epoch 17740: loss 0.00516385305672884",
      "\n",
      "epoch 17750: loss 0.004120168276131153",
      "\n",
      "epoch 17760: loss 0.00484356377273798",
      "\n",
      "epoch 17770: loss 0.005129029508680105",
      "\n",
      "epoch 17780: loss 0.005027522798627615",
      "\n",
      "epoch 17790: loss 0.004730029497295618",
      "\n",
      "epoch 17800: loss 0.005094609223306179",
      "\n",
      "17800 test percentage 0.9374740720464191",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 17810: loss 0.004609726369380951",
      "\n",
      "epoch 17820: loss 0.0046309009194374084",
      "\n",
      "epoch 17830: loss 0.004486499819904566",
      "\n",
      "epoch 17840: loss 0.006408886518329382",
      "\n",
      "epoch 17850: loss 0.005473761353641748",
      "\n",
      "epoch 17860: loss 0.005552978720515966",
      "\n",
      "epoch 17870: loss 0.004890337586402893",
      "\n",
      "epoch 17880: loss 0.005033534951508045",
      "\n",
      "epoch 17890: loss 0.005332589615136385",
      "\n",
      "epoch 17900: loss 0.004689207300543785",
      "\n",
      "epoch 17910: loss 0.005300287157297134",
      "\n",
      "epoch 17920: loss 0.005771307740360498",
      "\n",
      "epoch 17930: loss 0.004442247562110424",
      "\n",
      "epoch 17940: loss 0.004584584850817919",
      "\n",
      "epoch 17950: loss 0.0051365080289542675",
      "\n",
      "epoch 17960: loss 0.0045746853575110435",
      "\n",
      "epoch 17970: loss 0.004455194808542728",
      "\n",
      "epoch 17980: loss 0.0048229387030005455",
      "\n",
      "epoch 17990: loss 0.004877565894275904",
      "\n",
      "epoch 18000: loss 0.004427528474479914",
      "\n",
      "18000 test percentage 0.9536037637729837",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 18010: loss 0.005428235046565533",
      "\n",
      "epoch 18020: loss 0.005090927705168724",
      "\n",
      "epoch 18030: loss 0.005327059421688318",
      "\n",
      "epoch 18040: loss 0.004729945212602615",
      "\n",
      "epoch 18050: loss 0.005014203488826752",
      "\n",
      "epoch 18060: loss 0.005020055919885635",
      "\n",
      "epoch 18070: loss 0.005147556308656931",
      "\n",
      "epoch 18080: loss 0.005352680571377277",
      "\n",
      "epoch 18090: loss 0.004701552912592888",
      "\n",
      "epoch 18100: loss 0.004822228103876114",
      "\n",
      "epoch 18110: loss 0.004437713883817196",
      "\n",
      "epoch 18120: loss 0.004328390583395958",
      "\n",
      "epoch 18130: loss 0.004640527069568634",
      "\n",
      "epoch 18140: loss 0.005004268139600754",
      "\n",
      "epoch 18150: loss 0.004736373666673899",
      "\n",
      "epoch 18160: loss 0.004889359697699547",
      "\n",
      "epoch 18170: loss 0.004555908497422934",
      "\n",
      "epoch 18180: loss 0.005132813937962055",
      "\n",
      "epoch 18190: loss 0.0045587229542434216",
      "\n",
      "epoch 18200: loss 0.005427130032330751",
      "\n",
      "18200 test percentage 0.9107666358134294",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 18210: loss 0.004701792262494564",
      "\n",
      "epoch 18220: loss 0.005778271239250898",
      "\n",
      "epoch 18230: loss 0.004796287976205349",
      "\n",
      "epoch 18240: loss 0.005189075134694576",
      "\n",
      "epoch 18250: loss 0.005777197889983654",
      "\n",
      "epoch 18260: loss 0.004629878327250481",
      "\n",
      "epoch 18270: loss 0.005677569191902876",
      "\n",
      "epoch 18280: loss 0.004517672583460808",
      "\n",
      "epoch 18290: loss 0.004256176296621561",
      "\n",
      "epoch 18300: loss 0.004744270816445351",
      "\n",
      "epoch 18310: loss 0.0051698158495128155",
      "\n",
      "epoch 18320: loss 0.004859967157244682",
      "\n",
      "epoch 18330: loss 0.004835222382098436",
      "\n",
      "epoch 18340: loss 0.00495349895209074",
      "\n",
      "epoch 18350: loss 0.00533327367156744",
      "\n",
      "epoch 18360: loss 0.004589205142110586",
      "\n",
      "epoch 18370: loss 0.004531953949481249",
      "\n",
      "epoch 18380: loss 0.0049195061437785625",
      "\n",
      "epoch 18390: loss 0.004767220932990313",
      "\n",
      "epoch 18400: loss 0.00481117470189929",
      "\n",
      "18400 test percentage 0.9006221099065744",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 18410: loss 0.004958753474056721",
      "\n",
      "epoch 18420: loss 0.004477578215301037",
      "\n",
      "epoch 18430: loss 0.005099269095808268",
      "\n",
      "epoch 18440: loss 0.00471739936619997",
      "\n",
      "epoch 18450: loss 0.005003615748137236",
      "\n",
      "epoch 18460: loss 0.004826230462640524",
      "\n",
      "epoch 18470: loss 0.004893315490335226",
      "\n",
      "epoch 18480: loss 0.004745542071759701",
      "\n",
      "epoch 18490: loss 0.0044915396720170975",
      "\n",
      "epoch 18500: loss 0.004701482597738504",
      "\n",
      "epoch 18510: loss 0.004965946078300476",
      "\n",
      "epoch 18520: loss 0.005612116307020187",
      "\n",
      "epoch 18530: loss 0.005678645335137844",
      "\n",
      "epoch 18540: loss 0.004713742062449455",
      "\n",
      "epoch 18550: loss 0.0050166333094239235",
      "\n",
      "epoch 18560: loss 0.004738218151032925",
      "\n",
      "epoch 18570: loss 0.004638264421373606",
      "\n",
      "epoch 18580: loss 0.004229770973324776",
      "\n",
      "epoch 18590: loss 0.004591041244566441",
      "\n",
      "epoch 18600: loss 0.004761795978993177",
      "\n",
      "18600 test percentage 0.9545549420529076",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 18610: loss 0.004448532126843929",
      "\n",
      "epoch 18620: loss 0.004956269171088934",
      "\n",
      "epoch 18630: loss 0.004732584115117788",
      "\n",
      "epoch 18640: loss 0.004195728804916143",
      "\n",
      "epoch 18650: loss 0.004926919937133789",
      "\n",
      "epoch 18660: loss 0.005043203476816416",
      "\n",
      "epoch 18670: loss 0.004950389266014099",
      "\n",
      "epoch 18680: loss 0.004906125366687775",
      "\n",
      "epoch 18690: loss 0.005733679048717022",
      "\n",
      "epoch 18700: loss 0.004817316774278879",
      "\n",
      "epoch 18710: loss 0.0047082966193556786",
      "\n",
      "epoch 18720: loss 0.004366827663034201",
      "\n",
      "epoch 18730: loss 0.004374479874968529",
      "\n",
      "epoch 18740: loss 0.005241852719336748",
      "\n",
      "epoch 18750: loss 0.004869465716183186",
      "\n",
      "epoch 18760: loss 0.004445275757461786",
      "\n",
      "epoch 18770: loss 0.00432921526953578",
      "\n",
      "epoch 18780: loss 0.004429839551448822",
      "\n",
      "epoch 18790: loss 0.005043470300734043",
      "\n",
      "epoch 18800: loss 0.004357911646366119",
      "\n",
      "18800 test percentage 0.9406967591222556",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 18810: loss 0.004497170448303223",
      "\n",
      "epoch 18820: loss 0.004993012174963951",
      "\n",
      "epoch 18830: loss 0.005195841193199158",
      "\n",
      "epoch 18840: loss 0.004514970816671848",
      "\n",
      "epoch 18850: loss 0.005017191171646118",
      "\n",
      "epoch 18860: loss 0.004699768964201212",
      "\n",
      "epoch 18870: loss 0.00492918211966753",
      "\n",
      "epoch 18880: loss 0.004834984894841909",
      "\n",
      "epoch 18890: loss 0.005044528748840094",
      "\n",
      "epoch 18900: loss 0.005054427310824394",
      "\n",
      "epoch 18910: loss 0.00520740170031786",
      "\n",
      "epoch 18920: loss 0.00435060728341341",
      "\n",
      "epoch 18930: loss 0.005029898136854172",
      "\n",
      "epoch 18940: loss 0.004849995952099562",
      "\n",
      "epoch 18950: loss 0.004769460763782263",
      "\n",
      "epoch 18960: loss 0.004096228163689375",
      "\n",
      "epoch 18970: loss 0.0062415278516709805",
      "\n",
      "epoch 18980: loss 0.004927479196339846",
      "\n",
      "epoch 18990: loss 0.005319218151271343",
      "\n",
      "epoch 19000: loss 0.005023638717830181",
      "\n",
      "19000 test percentage 0.9405548489588813",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 19010: loss 0.00504085561260581",
      "\n",
      "epoch 19020: loss 0.004357568453997374",
      "\n",
      "epoch 19030: loss 0.005082475952804089",
      "\n",
      "epoch 19040: loss 0.0048822504468262196",
      "\n",
      "epoch 19050: loss 0.004811142571270466",
      "\n",
      "epoch 19060: loss 0.005123171955347061",
      "\n",
      "epoch 19070: loss 0.0053792367689311504",
      "\n",
      "epoch 19080: loss 0.004326054826378822",
      "\n",
      "epoch 19090: loss 0.0050411648117005825",
      "\n",
      "epoch 19100: loss 0.005027608014643192",
      "\n",
      "epoch 19110: loss 0.005145065486431122",
      "\n",
      "epoch 19120: loss 0.004827912896871567",
      "\n",
      "epoch 19130: loss 0.005323082208633423",
      "\n",
      "epoch 19140: loss 0.004935076460242271",
      "\n",
      "epoch 19150: loss 0.004251598846167326",
      "\n",
      "epoch 19160: loss 0.004937563557177782",
      "\n",
      "epoch 19170: loss 0.004556110128760338",
      "\n",
      "epoch 19180: loss 0.004665892571210861",
      "\n",
      "epoch 19190: loss 0.004349408205598593",
      "\n",
      "epoch 19200: loss 0.004840182140469551",
      "\n",
      "19200 test percentage 0.9542112596642423",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 19210: loss 0.004420658107846975",
      "\n",
      "epoch 19220: loss 0.0047674402594566345",
      "\n",
      "epoch 19230: loss 0.0052194069139659405",
      "\n",
      "epoch 19240: loss 0.004817446693778038",
      "\n",
      "epoch 19250: loss 0.00507871899753809",
      "\n",
      "epoch 19260: loss 0.005186271388083696",
      "\n",
      "epoch 19270: loss 0.004518032539635897",
      "\n",
      "epoch 19280: loss 0.004769626073539257",
      "\n",
      "epoch 19290: loss 0.00492281885817647",
      "\n",
      "epoch 19300: loss 0.004723666235804558",
      "\n",
      "epoch 19310: loss 0.005527305882424116",
      "\n",
      "epoch 19320: loss 0.004666069522500038",
      "\n",
      "epoch 19330: loss 0.004623617976903915",
      "\n",
      "epoch 19340: loss 0.004265924450010061",
      "\n",
      "epoch 19350: loss 0.004247051198035479",
      "\n",
      "epoch 19360: loss 0.0048849014565348625",
      "\n",
      "epoch 19370: loss 0.005373718217015266",
      "\n",
      "epoch 19380: loss 0.005075634922832251",
      "\n",
      "epoch 19390: loss 0.004836109466850758",
      "\n",
      "epoch 19400: loss 0.004784459248185158",
      "\n",
      "19400 test percentage 0.9357715268461525",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 19410: loss 0.0049721733666956425",
      "\n",
      "epoch 19420: loss 0.005272961221635342",
      "\n",
      "epoch 19430: loss 0.004476408939808607",
      "\n",
      "epoch 19440: loss 0.004583194851875305",
      "\n",
      "epoch 19450: loss 0.004752649459987879",
      "\n",
      "epoch 19460: loss 0.00589377386495471",
      "\n",
      "epoch 19470: loss 0.005148250609636307",
      "\n",
      "epoch 19480: loss 0.00452019739896059",
      "\n",
      "epoch 19490: loss 0.005280790850520134",
      "\n",
      "epoch 19500: loss 0.004601479973644018",
      "\n",
      "epoch 19510: loss 0.004819557536393404",
      "\n",
      "epoch 19520: loss 0.005054373759776354",
      "\n",
      "epoch 19530: loss 0.005450360011309385",
      "\n",
      "epoch 19540: loss 0.004907436203211546",
      "\n",
      "epoch 19550: loss 0.004838381893932819",
      "\n",
      "epoch 19560: loss 0.0049138255417346954",
      "\n",
      "epoch 19570: loss 0.005047481507062912",
      "\n",
      "epoch 19580: loss 0.004769252147525549",
      "\n",
      "epoch 19590: loss 0.0050644949078559875",
      "\n",
      "epoch 19600: loss 0.00552283925935626",
      "\n",
      "19600 test percentage 0.9223053971792579",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 19610: loss 0.004464035388082266",
      "\n",
      "epoch 19620: loss 0.004900345578789711",
      "\n",
      "epoch 19630: loss 0.004454138223081827",
      "\n",
      "epoch 19640: loss 0.0049793776124715805",
      "\n",
      "epoch 19650: loss 0.0059651159681379795",
      "\n",
      "epoch 19660: loss 0.0050362818874418736",
      "\n",
      "epoch 19670: loss 0.004164393059909344",
      "\n",
      "epoch 19680: loss 0.004894673824310303",
      "\n",
      "epoch 19690: loss 0.005344682838767767",
      "\n",
      "epoch 19700: loss 0.004661021288484335",
      "\n",
      "epoch 19710: loss 0.005305815953761339",
      "\n",
      "epoch 19720: loss 0.005182132590562105",
      "\n",
      "epoch 19730: loss 0.004661796614527702",
      "\n",
      "epoch 19740: loss 0.004891258664429188",
      "\n",
      "epoch 19750: loss 0.004897648468613625",
      "\n",
      "epoch 19760: loss 0.0044210623018443584",
      "\n",
      "epoch 19770: loss 0.004465982783585787",
      "\n",
      "epoch 19780: loss 0.004782384727150202",
      "\n",
      "epoch 19790: loss 0.005410407204180956",
      "\n",
      "epoch 19800: loss 0.005136049352586269",
      "\n",
      "19800 test percentage 0.9084481904000947",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 19810: loss 0.005506940186023712",
      "\n",
      "epoch 19820: loss 0.004654265008866787",
      "\n",
      "epoch 19830: loss 0.004398499149829149",
      "\n",
      "epoch 19840: loss 0.005521381739526987",
      "\n",
      "epoch 19850: loss 0.004689051769673824",
      "\n",
      "epoch 19860: loss 0.004561824258416891",
      "\n",
      "epoch 19870: loss 0.004526245873421431",
      "\n",
      "epoch 19880: loss 0.005583082791417837",
      "\n",
      "epoch 19890: loss 0.004795651882886887",
      "\n",
      "epoch 19900: loss 0.004617258440703154",
      "\n",
      "epoch 19910: loss 0.004614387638866901",
      "\n",
      "epoch 19920: loss 0.004616217687726021",
      "\n",
      "epoch 19930: loss 0.004190040286630392",
      "\n",
      "epoch 19940: loss 0.0042388890869915485",
      "\n",
      "epoch 19950: loss 0.004842342343181372",
      "\n",
      "epoch 19960: loss 0.004030383192002773",
      "\n",
      "epoch 19970: loss 0.004551773425191641",
      "\n",
      "epoch 19980: loss 0.004042763262987137",
      "\n",
      "epoch 19990: loss 0.004185667727142572",
      "\n",
      "epoch 20000: loss 0.005093603394925594",
      "\n",
      "20000 test percentage 0.9189970827798383",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 20010: loss 0.004475098103284836",
      "\n",
      "epoch 20020: loss 0.004719221964478493",
      "\n",
      "epoch 20030: loss 0.005805982276797295",
      "\n",
      "epoch 20040: loss 0.004866595380008221",
      "\n",
      "epoch 20050: loss 0.004620307125151157",
      "\n",
      "epoch 20060: loss 0.00537519995123148",
      "\n",
      "epoch 20070: loss 0.0050217402167618275",
      "\n",
      "epoch 20080: loss 0.0053620063699781895",
      "\n",
      "epoch 20090: loss 0.00443267822265625",
      "\n",
      "epoch 20100: loss 0.005233034025877714",
      "\n",
      "epoch 20110: loss 0.004706535488367081",
      "\n",
      "epoch 20120: loss 0.004597561899572611",
      "\n",
      "epoch 20130: loss 0.0047314101830124855",
      "\n",
      "epoch 20140: loss 0.00429182592779398",
      "\n",
      "epoch 20150: loss 0.005381968338042498",
      "\n",
      "epoch 20160: loss 0.004342154134064913",
      "\n",
      "epoch 20170: loss 0.004687169101089239",
      "\n",
      "epoch 20180: loss 0.005057553760707378",
      "\n",
      "epoch 20190: loss 0.007234516087919474",
      "\n",
      "epoch 20200: loss 0.005969622638076544",
      "\n",
      "20200 test percentage 0.9497189591361751",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 20210: loss 0.004256779327988625",
      "\n",
      "epoch 20220: loss 0.004513148684054613",
      "\n",
      "epoch 20230: loss 0.0046902671456336975",
      "\n",
      "epoch 20240: loss 0.004645568784326315",
      "\n",
      "epoch 20250: loss 0.005072961561381817",
      "\n",
      "epoch 20260: loss 0.004367966670542955",
      "\n",
      "epoch 20270: loss 0.005256342701613903",
      "\n",
      "epoch 20280: loss 0.005065690726041794",
      "\n",
      "epoch 20290: loss 0.0049958243034780025",
      "\n",
      "epoch 20300: loss 0.004465352278202772",
      "\n",
      "epoch 20310: loss 0.005777166225016117",
      "\n",
      "epoch 20320: loss 0.004840372130274773",
      "\n",
      "epoch 20330: loss 0.004656621720641851",
      "\n",
      "epoch 20340: loss 0.004725365899503231",
      "\n",
      "epoch 20350: loss 0.0052353027276694775",
      "\n",
      "epoch 20360: loss 0.004822134040296078",
      "\n",
      "epoch 20370: loss 0.005234084092080593",
      "\n",
      "epoch 20380: loss 0.005057916045188904",
      "\n",
      "epoch 20390: loss 0.005926585290580988",
      "\n",
      "epoch 20400: loss 0.004549989011138678",
      "\n",
      "20400 test percentage 0.9288762324854447",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 20410: loss 0.004085714463144541",
      "\n",
      "epoch 20420: loss 0.005011268891394138",
      "\n",
      "epoch 20430: loss 0.004691947717219591",
      "\n",
      "epoch 20440: loss 0.004651880823075771",
      "\n",
      "epoch 20450: loss 0.0047526974231004715",
      "\n",
      "epoch 20460: loss 0.004651430528610945",
      "\n",
      "epoch 20470: loss 0.004253494553267956",
      "\n",
      "epoch 20480: loss 0.005215945653617382",
      "\n",
      "epoch 20490: loss 0.00474259490147233",
      "\n",
      "epoch 20500: loss 0.00432653957977891",
      "\n",
      "epoch 20510: loss 0.0045874095521867275",
      "\n",
      "epoch 20520: loss 0.005105677526444197",
      "\n",
      "epoch 20530: loss 0.004737806040793657",
      "\n",
      "epoch 20540: loss 0.0052206977270543575",
      "\n",
      "epoch 20550: loss 0.005188797600567341",
      "\n",
      "epoch 20560: loss 0.004932665266096592",
      "\n",
      "epoch 20570: loss 0.004158706869930029",
      "\n",
      "epoch 20580: loss 0.004482178017497063",
      "\n",
      "epoch 20590: loss 0.004419931676238775",
      "\n",
      "epoch 20600: loss 0.004406743682920933",
      "\n",
      "20600 test percentage 0.8248027112213717",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 20610: loss 0.004434026777744293",
      "\n",
      "epoch 20620: loss 0.004725275095552206",
      "\n",
      "epoch 20630: loss 0.004307270515710115",
      "\n",
      "epoch 20640: loss 0.005106235388666391",
      "\n",
      "epoch 20650: loss 0.004400038160383701",
      "\n",
      "epoch 20660: loss 0.004653425887227058",
      "\n",
      "epoch 20670: loss 0.0045235250145196915",
      "\n",
      "epoch 20680: loss 0.00534878158941865",
      "\n",
      "epoch 20690: loss 0.004516505636274815",
      "\n",
      "epoch 20700: loss 0.005064358469098806",
      "\n",
      "epoch 20710: loss 0.004935659933835268",
      "\n",
      "epoch 20720: loss 0.00433620810508728",
      "\n",
      "epoch 20730: loss 0.005284333601593971",
      "\n",
      "epoch 20740: loss 0.005116393323987722",
      "\n",
      "epoch 20750: loss 0.005159485619515181",
      "\n",
      "epoch 20760: loss 0.004890762735158205",
      "\n",
      "epoch 20770: loss 0.004283673595637083",
      "\n",
      "epoch 20780: loss 0.006448246538639069",
      "\n",
      "epoch 20790: loss 0.004847650416195393",
      "\n",
      "epoch 20800: loss 0.005371739622205496",
      "\n",
      "20800 test percentage 0.9437515995184045",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 20810: loss 0.00528092822059989",
      "\n",
      "epoch 20820: loss 0.003942938055843115",
      "\n",
      "epoch 20830: loss 0.004374198615550995",
      "\n",
      "epoch 20840: loss 0.004959967453032732",
      "\n",
      "epoch 20850: loss 0.004764717072248459",
      "\n",
      "epoch 20860: loss 0.004410143010318279",
      "\n",
      "epoch 20870: loss 0.004752983804792166",
      "\n",
      "epoch 20880: loss 0.0047504655085504055",
      "\n",
      "epoch 20890: loss 0.00463429419323802",
      "\n",
      "epoch 20900: loss 0.004647309426218271",
      "\n",
      "epoch 20910: loss 0.004409069661051035",
      "\n",
      "epoch 20920: loss 0.0051281084306538105",
      "\n",
      "epoch 20930: loss 0.004797800909727812",
      "\n",
      "epoch 20940: loss 0.004243183881044388",
      "\n",
      "epoch 20950: loss 0.004581729881465435",
      "\n",
      "epoch 20960: loss 0.0056946794502437115",
      "\n",
      "epoch 20970: loss 0.00409042788669467",
      "\n",
      "epoch 20980: loss 0.004011990502476692",
      "\n",
      "epoch 20990: loss 0.004740091972053051",
      "\n",
      "epoch 21000: loss 0.004460541531443596",
      "\n",
      "21000 test percentage 0.9552097341963471",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 21010: loss 0.004279425833374262",
      "\n",
      "epoch 21020: loss 0.005526399705559015",
      "\n",
      "epoch 21030: loss 0.005273701623082161",
      "\n",
      "epoch 21040: loss 0.004918443039059639",
      "\n",
      "epoch 21050: loss 0.004553942941129208",
      "\n",
      "epoch 21060: loss 0.004545274190604687",
      "\n",
      "epoch 21070: loss 0.004825024865567684",
      "\n",
      "epoch 21080: loss 0.004708156455308199",
      "\n",
      "epoch 21090: loss 0.0046256547793745995",
      "\n",
      "epoch 21100: loss 0.00422182772308588",
      "\n",
      "epoch 21110: loss 0.004580351524055004",
      "\n",
      "epoch 21120: loss 0.005439562723040581",
      "\n",
      "epoch 21130: loss 0.004632933530956507",
      "\n",
      "epoch 21140: loss 0.004282829817384481",
      "\n",
      "epoch 21150: loss 0.004261818248778582",
      "\n",
      "epoch 21160: loss 0.00497635081410408",
      "\n",
      "epoch 21170: loss 0.004674958996474743",
      "\n",
      "epoch 21180: loss 0.0042008450254797935",
      "\n",
      "epoch 21190: loss 0.004913655575364828",
      "\n",
      "epoch 21200: loss 0.004466507118195295",
      "\n",
      "21200 test percentage 0.9545165938560409",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 21210: loss 0.004684882238507271",
      "\n",
      "epoch 21220: loss 0.0045735775493085384",
      "\n",
      "epoch 21230: loss 0.004631279967725277",
      "\n",
      "epoch 21240: loss 0.004013847094029188",
      "\n",
      "epoch 21250: loss 0.004468460101634264",
      "\n",
      "epoch 21260: loss 0.004753393121063709",
      "\n",
      "epoch 21270: loss 0.00457072164863348",
      "\n",
      "epoch 21280: loss 0.004535100422799587",
      "\n",
      "epoch 21290: loss 0.004771264735609293",
      "\n",
      "epoch 21300: loss 0.004212086088955402",
      "\n",
      "epoch 21310: loss 0.004658589139580727",
      "\n",
      "epoch 21320: loss 0.004534394480288029",
      "\n",
      "epoch 21330: loss 0.005142782349139452",
      "\n",
      "epoch 21340: loss 0.004908467642962933",
      "\n",
      "epoch 21350: loss 0.004440711811184883",
      "\n",
      "epoch 21360: loss 0.004336990881711245",
      "\n",
      "epoch 21370: loss 0.004860741086304188",
      "\n",
      "epoch 21380: loss 0.005159599706530571",
      "\n",
      "epoch 21390: loss 0.0038238714914768934",
      "\n",
      "epoch 21400: loss 0.004212662111967802",
      "\n",
      "21400 test percentage 0.8750116110650779",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 21410: loss 0.004855915904045105",
      "\n",
      "epoch 21420: loss 0.005470698233693838",
      "\n",
      "epoch 21430: loss 0.0049690967425704",
      "\n",
      "epoch 21440: loss 0.004927347414195538",
      "\n",
      "epoch 21450: loss 0.0046430169604718685",
      "\n",
      "epoch 21460: loss 0.0044608707539737225",
      "\n",
      "epoch 21470: loss 0.004222405608743429",
      "\n",
      "epoch 21480: loss 0.00436782743781805",
      "\n",
      "epoch 21490: loss 0.004244420677423477",
      "\n",
      "epoch 21500: loss 0.0040566748939454556",
      "\n",
      "epoch 21510: loss 0.004634428303688765",
      "\n",
      "epoch 21520: loss 0.004412115551531315",
      "\n",
      "epoch 21530: loss 0.005453100893646479",
      "\n",
      "epoch 21540: loss 0.004065921995788813",
      "\n",
      "epoch 21550: loss 0.004632327705621719",
      "\n",
      "epoch 21560: loss 0.005661484319716692",
      "\n",
      "epoch 21570: loss 0.00449995044618845",
      "\n",
      "epoch 21580: loss 0.004567726980894804",
      "\n",
      "epoch 21590: loss 0.004766740370541811",
      "\n",
      "epoch 21600: loss 0.005282190162688494",
      "\n",
      "21600 test percentage 0.9354430647142541",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 21610: loss 0.005780740641057491",
      "\n",
      "epoch 21620: loss 0.00457446463406086",
      "\n",
      "epoch 21630: loss 0.00434194877743721",
      "\n",
      "epoch 21640: loss 0.004456170368939638",
      "\n",
      "epoch 21650: loss 0.004662525840103626",
      "\n",
      "epoch 21660: loss 0.005268837325274944",
      "\n",
      "epoch 21670: loss 0.00462491437792778",
      "\n",
      "epoch 21680: loss 0.005278908181935549",
      "\n",
      "epoch 21690: loss 0.004986980464309454",
      "\n",
      "epoch 21700: loss 0.004057765938341618",
      "\n",
      "epoch 21710: loss 0.004297827370464802",
      "\n",
      "epoch 21720: loss 0.005022907629609108",
      "\n",
      "epoch 21730: loss 0.004707050509750843",
      "\n",
      "epoch 21740: loss 0.004478214308619499",
      "\n",
      "epoch 21750: loss 0.005166291259229183",
      "\n",
      "epoch 21760: loss 0.0049029262736439705",
      "\n",
      "epoch 21770: loss 0.005008767358958721",
      "\n",
      "epoch 21780: loss 0.004683491308242083",
      "\n",
      "epoch 21790: loss 0.004373092669993639",
      "\n",
      "epoch 21800: loss 0.003987250383943319",
      "\n",
      "21800 test percentage 0.9374710750900936",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 21810: loss 0.0050870152190327644",
      "\n",
      "epoch 21820: loss 0.004386902321130037",
      "\n",
      "epoch 21830: loss 0.004477826878428459",
      "\n",
      "epoch 21840: loss 0.00506965396925807",
      "\n",
      "epoch 21850: loss 0.004693817347288132",
      "\n",
      "epoch 21860: loss 0.004326909780502319",
      "\n",
      "epoch 21870: loss 0.004465484991669655",
      "\n",
      "epoch 21880: loss 0.004806198179721832",
      "\n",
      "epoch 21890: loss 0.004451056011021137",
      "\n",
      "epoch 21900: loss 0.004984610714018345",
      "\n",
      "epoch 21910: loss 0.004443182609975338",
      "\n",
      "epoch 21920: loss 0.005478764418512583",
      "\n",
      "epoch 21930: loss 0.004034944344311953",
      "\n",
      "epoch 21940: loss 0.005002354271709919",
      "\n",
      "epoch 21950: loss 0.004100380931049585",
      "\n",
      "epoch 21960: loss 0.006003555841743946",
      "\n",
      "epoch 21970: loss 0.0050880517810583115",
      "\n",
      "epoch 21980: loss 0.004615447949618101",
      "\n",
      "epoch 21990: loss 0.004291439428925514",
      "\n",
      "epoch 22000: loss 0.0043733371421694756",
      "\n",
      "22000 test percentage 0.9514702048767295",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 22010: loss 0.0047993045300245285",
      "\n",
      "epoch 22020: loss 0.004124578554183245",
      "\n",
      "epoch 22030: loss 0.004330201540142298",
      "\n",
      "epoch 22040: loss 0.004331016447395086",
      "\n",
      "epoch 22050: loss 0.004717535339295864",
      "\n",
      "epoch 22060: loss 0.00441167363896966",
      "\n",
      "epoch 22070: loss 0.004919585771858692",
      "\n",
      "epoch 22080: loss 0.0043993061408400536",
      "\n",
      "epoch 22090: loss 0.004350127652287483",
      "\n",
      "epoch 22100: loss 0.0047011105343699455",
      "\n",
      "epoch 22110: loss 0.004746630322188139",
      "\n",
      "epoch 22120: loss 0.004438364878296852",
      "\n",
      "epoch 22130: loss 0.004511168692260981",
      "\n",
      "epoch 22140: loss 0.005563948303461075",
      "\n",
      "epoch 22150: loss 0.004751616157591343",
      "\n",
      "epoch 22160: loss 0.005213906057178974",
      "\n",
      "epoch 22170: loss 0.004985561594367027",
      "\n",
      "epoch 22180: loss 0.004335954785346985",
      "\n",
      "epoch 22190: loss 0.004338019527494907",
      "\n",
      "epoch 22200: loss 0.004569974262267351",
      "\n",
      "22200 test percentage 0.9289024258837287",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 22210: loss 0.0051706712692976",
      "\n",
      "epoch 22220: loss 0.00442486722022295",
      "\n",
      "epoch 22230: loss 0.0045411428436636925",
      "\n",
      "epoch 22240: loss 0.004620788618922234",
      "\n",
      "epoch 22250: loss 0.004325259476900101",
      "\n",
      "epoch 22260: loss 0.004847368691116571",
      "\n",
      "epoch 22270: loss 0.004703228361904621",
      "\n",
      "epoch 22280: loss 0.0047380332835018635",
      "\n",
      "epoch 22290: loss 0.004541355185210705",
      "\n",
      "epoch 22300: loss 0.005205437541007996",
      "\n",
      "epoch 22310: loss 0.0044376733712852",
      "\n",
      "epoch 22320: loss 0.004779760725796223",
      "\n",
      "epoch 22330: loss 0.0042320601642131805",
      "\n",
      "epoch 22340: loss 0.004641961771994829",
      "\n",
      "epoch 22350: loss 0.005505401641130447",
      "\n",
      "epoch 22360: loss 0.004521195776760578",
      "\n",
      "epoch 22370: loss 0.0046313065104186535",
      "\n",
      "epoch 22380: loss 0.0041187177412211895",
      "\n",
      "epoch 22390: loss 0.005255507305264473",
      "\n",
      "epoch 22400: loss 0.004571496043354273",
      "\n",
      "22400 test percentage 0.950053025576402",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 22410: loss 0.0045449440367519855",
      "\n",
      "epoch 22420: loss 0.00539785111322999",
      "\n",
      "epoch 22430: loss 0.004803478717803955",
      "\n",
      "epoch 22440: loss 0.004474610090255737",
      "\n",
      "epoch 22450: loss 0.004381668753921986",
      "\n",
      "epoch 22460: loss 0.005191106349229813",
      "\n",
      "epoch 22470: loss 0.004538616165518761",
      "\n",
      "epoch 22480: loss 0.00459341099485755",
      "\n",
      "epoch 22490: loss 0.00567343644797802",
      "\n",
      "epoch 22500: loss 0.004940933547914028",
      "\n",
      "epoch 22510: loss 0.0042540542781353",
      "\n",
      "epoch 22520: loss 0.004226107615977526",
      "\n",
      "epoch 22530: loss 0.004691640846431255",
      "\n",
      "epoch 22540: loss 0.004023339133709669",
      "\n",
      "epoch 22550: loss 0.0038059744983911514",
      "\n",
      "epoch 22560: loss 0.004229010082781315",
      "\n",
      "epoch 22570: loss 0.004446255974471569",
      "\n",
      "epoch 22580: loss 0.004660395439714193",
      "\n",
      "epoch 22590: loss 0.004158146679401398",
      "\n",
      "epoch 22600: loss 0.00462971068918705",
      "\n",
      "22600 test percentage 0.940961296175733",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 22610: loss 0.0046896240673959255",
      "\n",
      "epoch 22620: loss 0.0051071676425635815",
      "\n",
      "epoch 22630: loss 0.005560481920838356",
      "\n",
      "epoch 22640: loss 0.004428695421665907",
      "\n",
      "epoch 22650: loss 0.004864702466875315",
      "\n",
      "epoch 22660: loss 0.0040106638334691525",
      "\n",
      "epoch 22670: loss 0.0043038260191679",
      "\n",
      "epoch 22680: loss 0.0043802764266729355",
      "\n",
      "epoch 22690: loss 0.004901235923171043",
      "\n",
      "epoch 22700: loss 0.0057253227569162846",
      "\n",
      "epoch 22710: loss 0.005514213815331459",
      "\n",
      "epoch 22720: loss 0.005612541455775499",
      "\n",
      "epoch 22730: loss 0.005258230492472649",
      "\n",
      "epoch 22740: loss 0.0047633531503379345",
      "\n",
      "epoch 22750: loss 0.004831093829125166",
      "\n",
      "epoch 22760: loss 0.004959397483617067",
      "\n",
      "epoch 22770: loss 0.005464440677314997",
      "\n",
      "epoch 22780: loss 0.0047852532006800175",
      "\n",
      "epoch 22790: loss 0.0050151292234659195",
      "\n",
      "epoch 22800: loss 0.004661457613110542",
      "\n",
      "22800 test percentage 0.9475208372379393",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 22810: loss 0.004705324769020081",
      "\n",
      "epoch 22820: loss 0.0052927397191524506",
      "\n",
      "epoch 22830: loss 0.004685936030000448",
      "\n",
      "epoch 22840: loss 0.004859526641666889",
      "\n",
      "epoch 22850: loss 0.004891465418040752",
      "\n",
      "epoch 22860: loss 0.004310640972107649",
      "\n",
      "epoch 22870: loss 0.004959950689226389",
      "\n",
      "epoch 22880: loss 0.004785098135471344",
      "\n",
      "epoch 22890: loss 0.00446169963106513",
      "\n",
      "epoch 22900: loss 0.004809447564184666",
      "\n",
      "epoch 22910: loss 0.004603033419698477",
      "\n",
      "epoch 22920: loss 0.004507678560912609",
      "\n",
      "epoch 22930: loss 0.006527402903884649",
      "\n",
      "epoch 22940: loss 0.004310161806643009",
      "\n",
      "epoch 22950: loss 0.004349734168499708",
      "\n",
      "epoch 22960: loss 0.004329375457018614",
      "\n",
      "epoch 22970: loss 0.004579323809593916",
      "\n",
      "epoch 22980: loss 0.005565243773162365",
      "\n",
      "epoch 22990: loss 0.005158935207873583",
      "\n",
      "epoch 23000: loss 0.004045732319355011",
      "\n",
      "23000 test percentage 0.9527253515926408",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 23010: loss 0.004331360571086407",
      "\n",
      "epoch 23020: loss 0.004928322043269873",
      "\n",
      "epoch 23030: loss 0.00534133380278945",
      "\n",
      "epoch 23040: loss 0.004525677300989628",
      "\n",
      "epoch 23050: loss 0.004594593774527311",
      "\n",
      "epoch 23060: loss 0.004432756453752518",
      "\n",
      "epoch 23070: loss 0.004970724228769541",
      "\n",
      "epoch 23080: loss 0.004021756816655397",
      "\n",
      "epoch 23090: loss 0.004965501371771097",
      "\n",
      "epoch 23100: loss 0.004419359378516674",
      "\n",
      "epoch 23110: loss 0.004472597036510706",
      "\n",
      "epoch 23120: loss 0.004962044768035412",
      "\n",
      "epoch 23130: loss 0.0045217121951282024",
      "\n",
      "epoch 23140: loss 0.005255816504359245",
      "\n",
      "epoch 23150: loss 0.004297444596886635",
      "\n",
      "epoch 23160: loss 0.0042352862656116486",
      "\n",
      "epoch 23170: loss 0.004843099042773247",
      "\n",
      "epoch 23180: loss 0.004892811644822359",
      "\n",
      "epoch 23190: loss 0.004913059528917074",
      "\n",
      "epoch 23200: loss 0.004377469886094332",
      "\n",
      "23200 test percentage 0.9311582434725949",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 23210: loss 0.004021032247692347",
      "\n",
      "epoch 23220: loss 0.005064366385340691",
      "\n",
      "epoch 23230: loss 0.0051157367415726185",
      "\n",
      "epoch 23240: loss 0.004820166155695915",
      "\n",
      "epoch 23250: loss 0.005206910893321037",
      "\n",
      "epoch 23260: loss 0.004705214407294989",
      "\n",
      "epoch 23270: loss 0.003748638089746237",
      "\n",
      "epoch 23280: loss 0.004373158328235149",
      "\n",
      "epoch 23290: loss 0.004322892054915428",
      "\n",
      "epoch 23300: loss 0.004438589792698622",
      "\n",
      "epoch 23310: loss 0.005205564200878143",
      "\n",
      "epoch 23320: loss 0.004114551469683647",
      "\n",
      "epoch 23330: loss 0.004661818500608206",
      "\n",
      "epoch 23340: loss 0.004219734109938145",
      "\n",
      "epoch 23350: loss 0.004032081458717585",
      "\n",
      "epoch 23360: loss 0.005031306762248278",
      "\n",
      "epoch 23370: loss 0.005722744390368462",
      "\n",
      "epoch 23380: loss 0.004289626143872738",
      "\n",
      "epoch 23390: loss 0.005298044066876173",
      "\n",
      "epoch 23400: loss 0.004331233911216259",
      "\n",
      "23400 test percentage 0.9224060092844679",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 23410: loss 0.005225493106991053",
      "\n",
      "epoch 23420: loss 0.005206688307225704",
      "\n",
      "epoch 23430: loss 0.00516103208065033",
      "\n",
      "epoch 23440: loss 0.005598226562142372",
      "\n",
      "epoch 23450: loss 0.004644026514142752",
      "\n",
      "epoch 23460: loss 0.004722473211586475",
      "\n",
      "epoch 23470: loss 0.005046337842941284",
      "\n",
      "epoch 23480: loss 0.005275373347103596",
      "\n",
      "epoch 23490: loss 0.004322881810367107",
      "\n",
      "epoch 23500: loss 0.004291379824280739",
      "\n",
      "epoch 23510: loss 0.004417639225721359",
      "\n",
      "epoch 23520: loss 0.004216529428958893",
      "\n",
      "epoch 23530: loss 0.005505048204213381",
      "\n",
      "epoch 23540: loss 0.00490207364782691",
      "\n",
      "epoch 23550: loss 0.004295573569834232",
      "\n",
      "epoch 23560: loss 0.004269912838935852",
      "\n",
      "epoch 23570: loss 0.004545006901025772",
      "\n",
      "epoch 23580: loss 0.004326373804360628",
      "\n",
      "epoch 23590: loss 0.004128162283450365",
      "\n",
      "epoch 23600: loss 0.004605979658663273",
      "\n",
      "23600 test percentage 0.9425966795847472",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 23610: loss 0.00471020070835948",
      "\n",
      "epoch 23620: loss 0.004786777775734663",
      "\n",
      "epoch 23630: loss 0.005029602907598019",
      "\n",
      "epoch 23640: loss 0.005060915369540453",
      "\n",
      "epoch 23650: loss 0.005450224969536066",
      "\n",
      "epoch 23660: loss 0.00531489634886384",
      "\n",
      "epoch 23670: loss 0.004453257191926241",
      "\n",
      "epoch 23680: loss 0.004264314193278551",
      "\n",
      "epoch 23690: loss 0.005280851386487484",
      "\n",
      "epoch 23700: loss 0.004644742235541344",
      "\n",
      "epoch 23710: loss 0.0050393082201480865",
      "\n",
      "epoch 23720: loss 0.0043061356991529465",
      "\n",
      "epoch 23730: loss 0.004382002633064985",
      "\n",
      "epoch 23740: loss 0.004138885997235775",
      "\n",
      "epoch 23750: loss 0.0047721294686198235",
      "\n",
      "epoch 23760: loss 0.004477900452911854",
      "\n",
      "epoch 23770: loss 0.005393606144934893",
      "\n",
      "epoch 23780: loss 0.004728530999273062",
      "\n",
      "epoch 23790: loss 0.0049570766277611256",
      "\n",
      "epoch 23800: loss 0.004331676755100489",
      "\n",
      "23800 test percentage 0.9056223260299392",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 23810: loss 0.003915606997907162",
      "\n",
      "epoch 23820: loss 0.004398312419652939",
      "\n",
      "epoch 23830: loss 0.004836040083318949",
      "\n",
      "epoch 23840: loss 0.004523764830082655",
      "\n",
      "epoch 23850: loss 0.004742113873362541",
      "\n",
      "epoch 23860: loss 0.004467009101063013",
      "\n",
      "epoch 23870: loss 0.004859749227762222",
      "\n",
      "epoch 23880: loss 0.003983564209192991",
      "\n",
      "epoch 23890: loss 0.004469861276447773",
      "\n",
      "epoch 23900: loss 0.004613627213984728",
      "\n",
      "epoch 23910: loss 0.004549605771899223",
      "\n",
      "epoch 23920: loss 0.004504109732806683",
      "\n",
      "epoch 23930: loss 0.004736260510981083",
      "\n",
      "epoch 23940: loss 0.004774953238666058",
      "\n",
      "epoch 23950: loss 0.003930504899471998",
      "\n",
      "epoch 23960: loss 0.00405261991545558",
      "\n",
      "epoch 23970: loss 0.004504654556512833",
      "\n",
      "epoch 23980: loss 0.005686840508133173",
      "\n",
      "epoch 23990: loss 0.005061180330812931",
      "\n",
      "epoch 24000: loss 0.0048566716723144054",
      "\n",
      "24000 test percentage 0.9492187114677044",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 24010: loss 0.004721703007817268",
      "\n",
      "epoch 24020: loss 0.005552353803068399",
      "\n",
      "epoch 24030: loss 0.0043540531769394875",
      "\n",
      "epoch 24040: loss 0.004524030722677708",
      "\n",
      "epoch 24050: loss 0.004846871364861727",
      "\n",
      "epoch 24060: loss 0.003863615682348609",
      "\n",
      "epoch 24070: loss 0.0044012125581502914",
      "\n",
      "epoch 24080: loss 0.005008053500205278",
      "\n",
      "epoch 24090: loss 0.004306270740926266",
      "\n",
      "epoch 24100: loss 0.004452174063771963",
      "\n",
      "epoch 24110: loss 0.004866732284426689",
      "\n",
      "epoch 24120: loss 0.004148275591433048",
      "\n",
      "epoch 24130: loss 0.005031939595937729",
      "\n",
      "epoch 24140: loss 0.0043557435274124146",
      "\n",
      "epoch 24150: loss 0.004325796850025654",
      "\n",
      "epoch 24160: loss 0.005408347584307194",
      "\n",
      "epoch 24170: loss 0.005692387465387583",
      "\n",
      "epoch 24180: loss 0.004180411342531443",
      "\n",
      "epoch 24190: loss 0.004839460365474224",
      "\n",
      "epoch 24200: loss 0.0047423928044736385",
      "\n",
      "24200 test percentage 0.9304587024898507",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 24210: loss 0.0044904607348144054",
      "\n",
      "epoch 24220: loss 0.0050154151394963264",
      "\n",
      "epoch 24230: loss 0.004080825485289097",
      "\n",
      "epoch 24240: loss 0.00488165533170104",
      "\n",
      "epoch 24250: loss 0.0045070829801261425",
      "\n",
      "epoch 24260: loss 0.00529556255787611",
      "\n",
      "epoch 24270: loss 0.005565197207033634",
      "\n",
      "epoch 24280: loss 0.0055991243571043015",
      "\n",
      "epoch 24290: loss 0.004436030518263578",
      "\n",
      "epoch 24300: loss 0.004370317328721285",
      "\n",
      "epoch 24310: loss 0.004001588560640812",
      "\n",
      "epoch 24320: loss 0.004530031234025955",
      "\n",
      "epoch 24330: loss 0.0046257623471319675",
      "\n",
      "epoch 24340: loss 0.004359730053693056",
      "\n",
      "epoch 24350: loss 0.004005567170679569",
      "\n",
      "epoch 24360: loss 0.004750806838274002",
      "\n",
      "epoch 24370: loss 0.004001084249466658",
      "\n",
      "epoch 24380: loss 0.005044227931648493",
      "\n",
      "epoch 24390: loss 0.004367929417639971",
      "\n",
      "epoch 24400: loss 0.004377299454063177",
      "\n",
      "24400 test percentage 0.9282010824458232",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 24410: loss 0.0041367532685399055",
      "\n",
      "epoch 24420: loss 0.0048538739793002605",
      "\n",
      "epoch 24430: loss 0.004168082028627396",
      "\n",
      "epoch 24440: loss 0.004921211861073971",
      "\n",
      "epoch 24450: loss 0.0046141305938363075",
      "\n",
      "epoch 24460: loss 0.0037168306298553944",
      "\n",
      "epoch 24470: loss 0.004112813156098127",
      "\n",
      "epoch 24480: loss 0.0050871591083705425",
      "\n",
      "epoch 24490: loss 0.004548249766230583",
      "\n",
      "epoch 24500: loss 0.00475334282964468",
      "\n",
      "epoch 24510: loss 0.004230588208884001",
      "\n",
      "epoch 24520: loss 0.00418450403958559",
      "\n",
      "epoch 24530: loss 0.004042964894324541",
      "\n",
      "epoch 24540: loss 0.004863022826611996",
      "\n",
      "epoch 24550: loss 0.0050714630633592606",
      "\n",
      "epoch 24560: loss 0.004349555820226669",
      "\n",
      "epoch 24570: loss 0.003907852806150913",
      "\n",
      "epoch 24580: loss 0.004565757233649492",
      "\n",
      "epoch 24590: loss 0.00451699597761035",
      "\n",
      "epoch 24600: loss 0.004082224797457457",
      "\n",
      "24600 test percentage 0.9216649219243214",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 24610: loss 0.004552055150270462",
      "\n",
      "epoch 24620: loss 0.004519675392657518",
      "\n",
      "epoch 24630: loss 0.004406267777085304",
      "\n",
      "epoch 24640: loss 0.004910930059850216",
      "\n",
      "epoch 24650: loss 0.005174663849174976",
      "\n",
      "epoch 24660: loss 0.004038700368255377",
      "\n",
      "epoch 24670: loss 0.004355419427156448",
      "\n",
      "epoch 24680: loss 0.003924379125237465",
      "\n",
      "epoch 24690: loss 0.004234434105455875",
      "\n",
      "epoch 24700: loss 0.004628801252692938",
      "\n",
      "epoch 24710: loss 0.004785018973052502",
      "\n",
      "epoch 24720: loss 0.004454384092241526",
      "\n",
      "epoch 24730: loss 0.004253101535141468",
      "\n",
      "epoch 24740: loss 0.00496287876740098",
      "\n",
      "epoch 24750: loss 0.004371150396764278",
      "\n",
      "epoch 24760: loss 0.004999696277081966",
      "\n",
      "epoch 24770: loss 0.004066247493028641",
      "\n",
      "epoch 24780: loss 0.004397990182042122",
      "\n",
      "epoch 24790: loss 0.004492449574172497",
      "\n",
      "epoch 24800: loss 0.004658016376197338",
      "\n",
      "24800 test percentage 0.9533488897629726",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 24810: loss 0.004081707447767258",
      "\n",
      "epoch 24820: loss 0.0047858720645308495",
      "\n",
      "epoch 24830: loss 0.004140310455113649",
      "\n",
      "epoch 24840: loss 0.0041625406593084335",
      "\n",
      "epoch 24850: loss 0.004185624420642853",
      "\n",
      "epoch 24860: loss 0.004302127752453089",
      "\n",
      "epoch 24870: loss 0.004811855033040047",
      "\n",
      "epoch 24880: loss 0.004265173338353634",
      "\n",
      "epoch 24890: loss 0.0049682012759149075",
      "\n",
      "epoch 24900: loss 0.004361563827842474",
      "\n",
      "epoch 24910: loss 0.0048116277903318405",
      "\n",
      "epoch 24920: loss 0.004101389553397894",
      "\n",
      "epoch 24930: loss 0.00467529846355319",
      "\n",
      "epoch 24940: loss 0.004712109919637442",
      "\n",
      "epoch 24950: loss 0.0040684291161596775",
      "\n",
      "epoch 24960: loss 0.004522991832345724",
      "\n",
      "epoch 24970: loss 0.005211910232901573",
      "\n",
      "epoch 24980: loss 0.0041058179922401905",
      "\n",
      "epoch 24990: loss 0.004165336024016142",
      "\n",
      "epoch 25000: loss 0.005177258513867855",
      "\n",
      "25000 test percentage 0.8937591312977868",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 25010: loss 0.004270654637366533",
      "\n",
      "epoch 25020: loss 0.00464358925819397",
      "\n",
      "epoch 25030: loss 0.004307215102016926",
      "\n",
      "epoch 25040: loss 0.0037901103496551514",
      "\n",
      "epoch 25050: loss 0.004004594869911671",
      "\n",
      "epoch 25060: loss 0.005148631986230612",
      "\n",
      "epoch 25070: loss 0.0054819341748952866",
      "\n",
      "epoch 25080: loss 0.004831896163523197",
      "\n",
      "epoch 25090: loss 0.004270479548722506",
      "\n",
      "epoch 25100: loss 0.004519365727901459",
      "\n",
      "epoch 25110: loss 0.004586642142385244",
      "\n",
      "epoch 25120: loss 0.005183729808777571",
      "\n",
      "epoch 25130: loss 0.004774345550686121",
      "\n",
      "epoch 25140: loss 0.003945863805711269",
      "\n",
      "epoch 25150: loss 0.004508645739406347",
      "\n",
      "epoch 25160: loss 0.004259048495441675",
      "\n",
      "epoch 25170: loss 0.004927022848278284",
      "\n",
      "epoch 25180: loss 0.004542618989944458",
      "\n",
      "epoch 25190: loss 0.005097896326333284",
      "\n",
      "epoch 25200: loss 0.004667672794312239",
      "\n",
      "25200 test percentage 0.941346576318195",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 25210: loss 0.004113572649657726",
      "\n",
      "epoch 25220: loss 0.00475168926641345",
      "\n",
      "epoch 25230: loss 0.0040052649565041065",
      "\n",
      "epoch 25240: loss 0.004100623540580273",
      "\n",
      "epoch 25250: loss 0.0043243407271802425",
      "\n",
      "epoch 25260: loss 0.004146993160247803",
      "\n",
      "epoch 25270: loss 0.004669341258704662",
      "\n",
      "epoch 25280: loss 0.004018516279757023",
      "\n",
      "epoch 25290: loss 0.00409092428162694",
      "\n",
      "epoch 25300: loss 0.004904653877019882",
      "\n",
      "epoch 25310: loss 0.005018246825784445",
      "\n",
      "epoch 25320: loss 0.004901045933365822",
      "\n",
      "epoch 25330: loss 0.004242615774273872",
      "\n",
      "epoch 25340: loss 0.004798638168722391",
      "\n",
      "epoch 25350: loss 0.004032054450362921",
      "\n",
      "epoch 25360: loss 0.00392157630994916",
      "\n",
      "epoch 25370: loss 0.004653492011129856",
      "\n",
      "epoch 25380: loss 0.004797440953552723",
      "\n",
      "epoch 25390: loss 0.003843363607302308",
      "\n",
      "epoch 25400: loss 0.004251099657267332",
      "\n",
      "25400 test percentage 0.9520352553036879",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 25410: loss 0.004160122945904732",
      "\n",
      "epoch 25420: loss 0.004616983700543642",
      "\n",
      "epoch 25430: loss 0.004116430878639221",
      "\n",
      "epoch 25440: loss 0.00427844375371933",
      "\n",
      "epoch 25450: loss 0.0049086203798651695",
      "\n",
      "epoch 25460: loss 0.004633394535630941",
      "\n",
      "epoch 25470: loss 0.003951655700802803",
      "\n",
      "epoch 25480: loss 0.004608744289726019",
      "\n",
      "epoch 25490: loss 0.004969186149537563",
      "\n",
      "epoch 25500: loss 0.0041047376580536366",
      "\n",
      "epoch 25510: loss 0.0046720001846551895",
      "\n",
      "epoch 25520: loss 0.004542769398540258",
      "\n",
      "epoch 25530: loss 0.005012598354369402",
      "\n",
      "epoch 25540: loss 0.005138264503329992",
      "\n",
      "epoch 25550: loss 0.004642643965780735",
      "\n",
      "epoch 25560: loss 0.005032828077673912",
      "\n",
      "epoch 25570: loss 0.004061948042362928",
      "\n",
      "epoch 25580: loss 0.005193925462663174",
      "\n",
      "epoch 25590: loss 0.004621530883014202",
      "\n",
      "epoch 25600: loss 0.004530586302280426",
      "\n",
      "25600 test percentage 0.956221973320718",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 25610: loss 0.005256554111838341",
      "\n",
      "epoch 25620: loss 0.006216379348188639",
      "\n",
      "epoch 25630: loss 0.004036820959299803",
      "\n",
      "epoch 25640: loss 0.004769009537994862",
      "\n",
      "epoch 25650: loss 0.004532395396381617",
      "\n",
      "epoch 25660: loss 0.004108094610273838",
      "\n",
      "epoch 25670: loss 0.00468629552051425",
      "\n",
      "epoch 25680: loss 0.004407104570418596",
      "\n",
      "epoch 25690: loss 0.0048730443231761456",
      "\n",
      "epoch 25700: loss 0.004104907158762217",
      "\n",
      "epoch 25710: loss 0.005654844921082258",
      "\n",
      "epoch 25720: loss 0.004456710070371628",
      "\n",
      "epoch 25730: loss 0.004509440623223782",
      "\n",
      "epoch 25740: loss 0.0037393001839518547",
      "\n",
      "epoch 25750: loss 0.004183126613497734",
      "\n",
      "epoch 25760: loss 0.004782706033438444",
      "\n",
      "epoch 25770: loss 0.004851707257330418",
      "\n",
      "epoch 25780: loss 0.004151199944317341",
      "\n",
      "epoch 25790: loss 0.004075460135936737",
      "\n",
      "epoch 25800: loss 0.003777030622586608",
      "\n",
      "25800 test percentage 0.9442796418161103",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 25810: loss 0.004178963601589203",
      "\n",
      "epoch 25820: loss 0.004030860494822264",
      "\n",
      "epoch 25830: loss 0.003953386563807726",
      "\n",
      "epoch 25840: loss 0.004645113833248615",
      "\n",
      "epoch 25850: loss 0.004708625841885805",
      "\n",
      "epoch 25860: loss 0.004871781449764967",
      "\n",
      "epoch 25870: loss 0.004377081524580717",
      "\n",
      "epoch 25880: loss 0.0039429618045687675",
      "\n",
      "epoch 25890: loss 0.0044405460357666016",
      "\n",
      "epoch 25900: loss 0.0049284398555755615",
      "\n",
      "epoch 25910: loss 0.00411316379904747",
      "\n",
      "epoch 25920: loss 0.004388807807117701",
      "\n",
      "epoch 25930: loss 0.005374339409172535",
      "\n",
      "epoch 25940: loss 0.004703814163804054",
      "\n",
      "epoch 25950: loss 0.004595909267663956",
      "\n",
      "epoch 25960: loss 0.005379269365221262",
      "\n",
      "epoch 25970: loss 0.004323899745941162",
      "\n",
      "epoch 25980: loss 0.005583267193287611",
      "\n",
      "epoch 25990: loss 0.005145617760717869",
      "\n",
      "epoch 26000: loss 0.004468030296266079",
      "\n",
      "26000 test percentage 0.9348182763849979",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 26010: loss 0.0050895377062261105",
      "\n",
      "epoch 26020: loss 0.0046441941522061825",
      "\n",
      "epoch 26030: loss 0.00422557070851326",
      "\n",
      "epoch 26040: loss 0.004614948760718107",
      "\n",
      "epoch 26050: loss 0.004936800803989172",
      "\n",
      "epoch 26060: loss 0.0042442986741662025",
      "\n",
      "epoch 26070: loss 0.0042170574888587",
      "\n",
      "epoch 26080: loss 0.004340799525380135",
      "\n",
      "epoch 26090: loss 0.0041982512921094894",
      "\n",
      "epoch 26100: loss 0.004107125103473663",
      "\n",
      "epoch 26110: loss 0.004901168402284384",
      "\n",
      "epoch 26120: loss 0.004753652028739452",
      "\n",
      "epoch 26130: loss 0.0038064802065491676",
      "\n",
      "epoch 26140: loss 0.003976550418883562",
      "\n",
      "epoch 26150: loss 0.004591755103319883",
      "\n",
      "epoch 26160: loss 0.004721423611044884",
      "\n",
      "epoch 26170: loss 0.004548133350908756",
      "\n",
      "epoch 26180: loss 0.005245760083198547",
      "\n",
      "epoch 26190: loss 0.004950887989252806",
      "\n",
      "epoch 26200: loss 0.00520824920386076",
      "\n",
      "26200 test percentage 0.92503386903157",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 26210: loss 0.00527590187266469",
      "\n",
      "epoch 26220: loss 0.004214492626488209",
      "\n",
      "epoch 26230: loss 0.004343540873378515",
      "\n",
      "epoch 26240: loss 0.004784340970218182",
      "\n",
      "epoch 26250: loss 0.004453723784536123",
      "\n",
      "epoch 26260: loss 0.005321623291820288",
      "\n",
      "epoch 26270: loss 0.004224664997309446",
      "\n",
      "epoch 26280: loss 0.004540801513940096",
      "\n",
      "epoch 26290: loss 0.0046784295700490475",
      "\n",
      "epoch 26300: loss 0.0040389420464634895",
      "\n",
      "epoch 26310: loss 0.005342091433703899",
      "\n",
      "epoch 26320: loss 0.00408353004604578",
      "\n",
      "epoch 26330: loss 0.004583828616887331",
      "\n",
      "epoch 26340: loss 0.0043101683259010315",
      "\n",
      "epoch 26350: loss 0.004314292222261429",
      "\n",
      "epoch 26360: loss 0.005828153807669878",
      "\n",
      "epoch 26370: loss 0.004326159600168467",
      "\n",
      "epoch 26380: loss 0.0052152229472994804",
      "\n",
      "epoch 26390: loss 0.004183931276202202",
      "\n",
      "epoch 26400: loss 0.004677277524024248",
      "\n",
      "26400 test percentage 0.9334806448682791",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 26410: loss 0.005626336671411991",
      "\n",
      "epoch 26420: loss 0.004203770775347948",
      "\n",
      "epoch 26430: loss 0.004744043108075857",
      "\n",
      "epoch 26440: loss 0.0046006725169718266",
      "\n",
      "epoch 26450: loss 0.0042460463009774685",
      "\n",
      "epoch 26460: loss 0.004486949183046818",
      "\n",
      "epoch 26470: loss 0.005050159525126219",
      "\n",
      "epoch 26480: loss 0.003841238096356392",
      "\n",
      "epoch 26490: loss 0.00485902838408947",
      "\n",
      "epoch 26500: loss 0.005021361634135246",
      "\n",
      "epoch 26510: loss 0.0038154153153300285",
      "\n",
      "epoch 26520: loss 0.004069390706717968",
      "\n",
      "epoch 26530: loss 0.00411107437685132",
      "\n",
      "epoch 26540: loss 0.004679990001022816",
      "\n",
      "epoch 26550: loss 0.0041445582173764706",
      "\n",
      "epoch 26560: loss 0.004517499357461929",
      "\n",
      "epoch 26570: loss 0.0045496802777051926",
      "\n",
      "epoch 26580: loss 0.004400934092700481",
      "\n",
      "epoch 26590: loss 0.0041526309214532375",
      "\n",
      "epoch 26600: loss 0.004882471635937691",
      "\n",
      "26600 test percentage 0.8678731693563236",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 26610: loss 0.004209096077829599",
      "\n",
      "epoch 26620: loss 0.004128337372094393",
      "\n",
      "epoch 26630: loss 0.005455613136291504",
      "\n",
      "epoch 26640: loss 0.005133245140314102",
      "\n",
      "epoch 26650: loss 0.0041346075013279915",
      "\n",
      "epoch 26660: loss 0.004283370915800333",
      "\n",
      "epoch 26670: loss 0.003544718725606799",
      "\n",
      "epoch 26680: loss 0.0047502899542450905",
      "\n",
      "epoch 26690: loss 0.004682525061070919",
      "\n",
      "epoch 26700: loss 0.004582321736961603",
      "\n",
      "epoch 26710: loss 0.005025344900786877",
      "\n",
      "epoch 26720: loss 0.00429464690387249",
      "\n",
      "epoch 26730: loss 0.003933044616132975",
      "\n",
      "epoch 26740: loss 0.004138193558901548",
      "\n",
      "epoch 26750: loss 0.003770567709580064",
      "\n",
      "epoch 26760: loss 0.004200780298560858",
      "\n",
      "epoch 26770: loss 0.0047152964398264885",
      "\n",
      "epoch 26780: loss 0.00458822026848793",
      "\n",
      "epoch 26790: loss 0.0045484318397939205",
      "\n",
      "epoch 26800: loss 0.004344658926129341",
      "\n",
      "26800 test percentage 0.9511655985171814",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 26810: loss 0.003959551453590393",
      "\n",
      "epoch 26820: loss 0.004489620681852102",
      "\n",
      "epoch 26830: loss 0.004588268231600523",
      "\n",
      "epoch 26840: loss 0.0038565434515476227",
      "\n",
      "epoch 26850: loss 0.004191838204860687",
      "\n",
      "epoch 26860: loss 0.004166686907410622",
      "\n",
      "epoch 26870: loss 0.004055169876664877",
      "\n",
      "epoch 26880: loss 0.0038760732859373093",
      "\n",
      "epoch 26890: loss 0.004267540294677019",
      "\n",
      "epoch 26900: loss 0.004289740696549416",
      "\n",
      "epoch 26910: loss 0.004363980144262314",
      "\n",
      "epoch 26920: loss 0.004470387008041143",
      "\n",
      "epoch 26930: loss 0.003739395411685109",
      "\n",
      "epoch 26940: loss 0.0043421234004199505",
      "\n",
      "epoch 26950: loss 0.005229994188994169",
      "\n",
      "epoch 26960: loss 0.004216934088617563",
      "\n",
      "epoch 26970: loss 0.004414517432451248",
      "\n",
      "epoch 26980: loss 0.004511406645178795",
      "\n",
      "epoch 26990: loss 0.0037660016678273678",
      "\n",
      "epoch 27000: loss 0.0048475610092282295",
      "\n",
      "27000 test percentage 0.9266240626205633",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 27010: loss 0.003483935259282589",
      "\n",
      "epoch 27020: loss 0.005589417181909084",
      "\n",
      "epoch 27030: loss 0.004520778078585863",
      "\n",
      "epoch 27040: loss 0.0044670552015304565",
      "\n",
      "epoch 27050: loss 0.0042329104617238045",
      "\n",
      "epoch 27060: loss 0.0042637065052986145",
      "\n",
      "epoch 27070: loss 0.0041440571658313274",
      "\n",
      "epoch 27080: loss 0.004404645878821611",
      "\n",
      "epoch 27090: loss 0.004017793573439121",
      "\n",
      "epoch 27100: loss 0.004064252600073814",
      "\n",
      "epoch 27110: loss 0.004195557441562414",
      "\n",
      "epoch 27120: loss 0.004387642722576857",
      "\n",
      "epoch 27130: loss 0.004440548364073038",
      "\n",
      "epoch 27140: loss 0.004440419375896454",
      "\n",
      "epoch 27150: loss 0.00498526357114315",
      "\n",
      "epoch 27160: loss 0.004267632495611906",
      "\n",
      "epoch 27170: loss 0.00468140235170722",
      "\n",
      "epoch 27180: loss 0.004998467396944761",
      "\n",
      "epoch 27190: loss 0.004180286079645157",
      "\n",
      "epoch 27200: loss 0.004251108504831791",
      "\n",
      "27200 test percentage 0.9542051458733384",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 27210: loss 0.004834907129406929",
      "\n",
      "epoch 27220: loss 0.004128912463784218",
      "\n",
      "epoch 27230: loss 0.0048032719641923904",
      "\n",
      "epoch 27240: loss 0.00514954375103116",
      "\n",
      "epoch 27250: loss 0.004232053179293871",
      "\n",
      "epoch 27260: loss 0.0041137272492051125",
      "\n",
      "epoch 27270: loss 0.00384751008823514",
      "\n",
      "epoch 27280: loss 0.004107503220438957",
      "\n",
      "epoch 27290: loss 0.004194248467683792",
      "\n",
      "epoch 27300: loss 0.004451007582247257",
      "\n",
      "epoch 27310: loss 0.004178238101303577",
      "\n",
      "epoch 27320: loss 0.004142178688198328",
      "\n",
      "epoch 27330: loss 0.00493857404217124",
      "\n",
      "epoch 27340: loss 0.005109330639243126",
      "\n",
      "epoch 27350: loss 0.004154802765697241",
      "\n",
      "epoch 27360: loss 0.003995716571807861",
      "\n",
      "epoch 27370: loss 0.004367544315755367",
      "\n",
      "epoch 27380: loss 0.004426749888807535",
      "\n",
      "epoch 27390: loss 0.004050446208566427",
      "\n",
      "epoch 27400: loss 0.004427014384418726",
      "\n",
      "27400 test percentage 0.953477660413543",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 27410: loss 0.004386586137115955",
      "\n",
      "epoch 27420: loss 0.004084485117346048",
      "\n",
      "epoch 27430: loss 0.004685280378907919",
      "\n",
      "epoch 27440: loss 0.004573387559503317",
      "\n",
      "epoch 27450: loss 0.00446315947920084",
      "\n",
      "epoch 27460: loss 0.004131711553782225",
      "\n",
      "epoch 27470: loss 0.004220429342240095",
      "\n",
      "epoch 27480: loss 0.004364812280982733",
      "\n",
      "epoch 27490: loss 0.005423675291240215",
      "\n",
      "epoch 27500: loss 0.005080262199044228",
      "\n",
      "epoch 27510: loss 0.004133956506848335",
      "\n",
      "epoch 27520: loss 0.004097679629921913",
      "\n",
      "epoch 27530: loss 0.0036628232337534428",
      "\n",
      "epoch 27540: loss 0.00410793861374259",
      "\n",
      "epoch 27550: loss 0.004915889818221331",
      "\n",
      "epoch 27560: loss 0.004373564850538969",
      "\n",
      "epoch 27570: loss 0.0038183778524398804",
      "\n",
      "epoch 27580: loss 0.004636107478290796",
      "\n",
      "epoch 27590: loss 0.004287144169211388",
      "\n",
      "epoch 27600: loss 0.004319038242101669",
      "\n",
      "27600 test percentage 0.9473215396422997",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 27610: loss 0.004702336620539427",
      "\n",
      "epoch 27620: loss 0.004148969426751137",
      "\n",
      "epoch 27630: loss 0.004367940127849579",
      "\n",
      "epoch 27640: loss 0.004158801399171352",
      "\n",
      "epoch 27650: loss 0.0045654964633286",
      "\n",
      "epoch 27660: loss 0.005141093861311674",
      "\n",
      "epoch 27670: loss 0.004089349880814552",
      "\n",
      "epoch 27680: loss 0.005188764072954655",
      "\n",
      "epoch 27690: loss 0.003809222485870123",
      "\n",
      "epoch 27700: loss 0.004183008335530758",
      "\n",
      "epoch 27710: loss 0.0054535819217562675",
      "\n",
      "epoch 27720: loss 0.004300803877413273",
      "\n",
      "epoch 27730: loss 0.0042746164835989475",
      "\n",
      "epoch 27740: loss 0.004237177781760693",
      "\n",
      "epoch 27750: loss 0.004210604354739189",
      "\n",
      "epoch 27760: loss 0.004627993796020746",
      "\n",
      "epoch 27770: loss 0.004655282013118267",
      "\n",
      "epoch 27780: loss 0.004218745976686478",
      "\n",
      "epoch 27790: loss 0.004264912102371454",
      "\n",
      "epoch 27800: loss 0.0038344995118677616",
      "\n",
      "27800 test percentage 0.9500398518126688",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 27810: loss 0.004615684039890766",
      "\n",
      "epoch 27820: loss 0.00383004080504179",
      "\n",
      "epoch 27830: loss 0.004549748729914427",
      "\n",
      "epoch 27840: loss 0.0052576130256056786",
      "\n",
      "epoch 27850: loss 0.0044967238791286945",
      "\n",
      "epoch 27860: loss 0.004553840495646",
      "\n",
      "epoch 27870: loss 0.004369040951132774",
      "\n",
      "epoch 27880: loss 0.004456587601453066",
      "\n",
      "epoch 27890: loss 0.004440233577042818",
      "\n",
      "epoch 27900: loss 0.004138774238526821",
      "\n",
      "epoch 27910: loss 0.004350921139121056",
      "\n",
      "epoch 27920: loss 0.004720182158052921",
      "\n",
      "epoch 27930: loss 0.004577063489705324",
      "\n",
      "epoch 27940: loss 0.004585235845297575",
      "\n",
      "epoch 27950: loss 0.004325547255575657",
      "\n",
      "epoch 27960: loss 0.004595092032104731",
      "\n",
      "epoch 27970: loss 0.004298042505979538",
      "\n",
      "epoch 27980: loss 0.004682304337620735",
      "\n",
      "epoch 27990: loss 0.0045723579823970795",
      "\n",
      "epoch 28000: loss 0.004388265777379274",
      "\n",
      "28000 test percentage 0.9558477690725615",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 28010: loss 0.005145561415702105",
      "\n",
      "epoch 28020: loss 0.004420551937073469",
      "\n",
      "epoch 28030: loss 0.005695764906704426",
      "\n",
      "epoch 28040: loss 0.004075270611792803",
      "\n",
      "epoch 28050: loss 0.00500910822302103",
      "\n",
      "epoch 28060: loss 0.004132540430873632",
      "\n",
      "epoch 28070: loss 0.004348851274698973",
      "\n",
      "epoch 28080: loss 0.005429096519947052",
      "\n",
      "epoch 28090: loss 0.004314042627811432",
      "\n",
      "epoch 28100: loss 0.004246906843036413",
      "\n",
      "epoch 28110: loss 0.004456416703760624",
      "\n",
      "epoch 28120: loss 0.0039070830680429935",
      "\n",
      "epoch 28130: loss 0.004578390158712864",
      "\n",
      "epoch 28140: loss 0.004770993255078793",
      "\n",
      "epoch 28150: loss 0.004987636115401983",
      "\n",
      "epoch 28160: loss 0.004190774634480476",
      "\n",
      "epoch 28170: loss 0.003971792757511139",
      "\n",
      "epoch 28180: loss 0.004335400648415089",
      "\n",
      "epoch 28190: loss 0.0039863791316747665",
      "\n",
      "epoch 28200: loss 0.004073929972946644",
      "\n",
      "28200 test percentage 0.9568434692793824",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 28210: loss 0.0048309555277228355",
      "\n",
      "epoch 28220: loss 0.0039945561438798904",
      "\n",
      "epoch 28230: loss 0.004052824806421995",
      "\n",
      "epoch 28240: loss 0.005267984699457884",
      "\n",
      "epoch 28250: loss 0.004377793986350298",
      "\n",
      "epoch 28260: loss 0.004379855934530497",
      "\n",
      "epoch 28270: loss 0.004475306253880262",
      "\n",
      "epoch 28280: loss 0.004488413687795401",
      "\n",
      "epoch 28290: loss 0.004639134276658297",
      "\n",
      "epoch 28300: loss 0.004064500797539949",
      "\n",
      "epoch 28310: loss 0.004566879477351904",
      "\n",
      "epoch 28320: loss 0.004605280235409737",
      "\n",
      "epoch 28330: loss 0.004331410396844149",
      "\n",
      "epoch 28340: loss 0.004104425199329853",
      "\n",
      "epoch 28350: loss 0.004483106080442667",
      "\n",
      "epoch 28360: loss 0.004107838962227106",
      "\n",
      "epoch 28370: loss 0.004752052016556263",
      "\n",
      "epoch 28380: loss 0.004479572642594576",
      "\n",
      "epoch 28390: loss 0.005314385052770376",
      "\n",
      "epoch 28400: loss 0.004806517157703638",
      "\n",
      "28400 test percentage 0.9000688375179748",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 28410: loss 0.004994862247258425",
      "\n",
      "epoch 28420: loss 0.004235738422721624",
      "\n",
      "epoch 28430: loss 0.0040815104730427265",
      "\n",
      "epoch 28440: loss 0.004447546787559986",
      "\n",
      "epoch 28450: loss 0.0041303569450974464",
      "\n",
      "epoch 28460: loss 0.0042747510597109795",
      "\n",
      "epoch 28470: loss 0.004051707684993744",
      "\n",
      "epoch 28480: loss 0.0045073204673826694",
      "\n",
      "epoch 28490: loss 0.0045412080362439156",
      "\n",
      "epoch 28500: loss 0.004037521313875914",
      "\n",
      "epoch 28510: loss 0.0044435616582632065",
      "\n",
      "epoch 28520: loss 0.004998570308089256",
      "\n",
      "epoch 28530: loss 0.004701100755482912",
      "\n",
      "epoch 28540: loss 0.004572746809571981",
      "\n",
      "epoch 28550: loss 0.00438346341252327",
      "\n",
      "epoch 28560: loss 0.004245677962899208",
      "\n",
      "epoch 28570: loss 0.0036655222065746784",
      "\n",
      "epoch 28580: loss 0.003766475711017847",
      "\n",
      "epoch 28590: loss 0.004497045185416937",
      "\n",
      "epoch 28600: loss 0.004140189848840237",
      "\n",
      "28600 test percentage 0.9255549712346994",
      "\n",
      "save model at models/Resbnlnn_order/",
      "\n",
      "epoch 28610: loss 0.004031729884445667",
      "\n",
      "epoch 28620: loss 0.004218720365315676",
      "\n",
      "epoch 28630: loss 0.004165638703852892",
      "\n",
      "epoch 28640: loss 0.004764650948345661",
      "\n",
      "epoch 28650: loss 0.003848460502922535",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "training_ResBNLNN_order()\n",
    "# training_LNN_startup()\n",
    "# training_BNLNN_startup()\n",
    "# training_ResLNN_startup()\n",
    "training_ResBNLNN_startup()\n",
    "# training_LNN()\n",
    "# training_BNLNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      Sex  Survived\n0  female  0.742038\n1    male  0.188908",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>0.742038</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>male</td>\n      <td>0.188908</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "train, test = import_data()\n",
    "\n",
    "train['Title'] = train.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col', \\\n",
    "'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "# train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()\n",
    "train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()\n",
    "\n",
    "# C > Q > S\n",
    "# Female > male\n",
    "# Mrs > Miss > Master > Rare > Mr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% mapping analysis\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "     PassengerId  Survived\n0            892       0.0\n1            893       0.0\n2            894       0.0\n3            895       1.0\n4            896       0.0\n5            897       0.0\n6            898       1.0\n7            899       0.0\n8            900       1.0\n9            901      -0.0\n10           902       0.0\n11           903       1.0\n12           904       1.0\n13           905       0.0\n14           906       0.0\n15           907       0.0\n16           908       0.0\n17           909       0.0\n18           910       0.0\n19           911       0.0\n20           912       0.0\n21           913       0.0\n22           914       0.0\n23           915       0.0\n24           916       0.0\n25           917       0.0\n26           918       1.0\n27           919       0.0\n28           920       0.0\n29           921       0.0\n..           ...       ...\n388         1280      -0.0\n389         1281       0.0\n390         1282       0.0\n391         1283       0.0\n392         1284       0.0\n393         1285      -0.0\n394         1286      -0.0\n395         1287       0.0\n396         1288       0.0\n397         1289       1.0\n398         1290      -0.0\n399         1291       0.0\n400         1292       0.0\n401         1293       0.0\n402         1294       1.0\n403         1295       0.0\n404         1296       0.0\n405         1297       0.0\n406         1298       1.0\n407         1299       0.0\n408         1300       0.0\n409         1301       0.0\n410         1302       0.0\n411         1303       1.0\n412         1304       0.0\n413         1305       0.0\n414         1306       0.0\n415         1307       0.0\n416         1308       0.0\n417         1309       0.0\n\n[418 rows x 2 columns]",
      "\n",
      "     PassengerId  Survived\n0            892       0.0\n1            893       0.0\n2            894       0.0\n3            895       1.0\n4            896       0.0\n5            897       0.0\n6            898       0.0\n7            899       0.0\n8            900       1.0\n9            901       0.0\n10           902      -0.0\n11           903       0.0\n12           904       1.0\n13           905       0.0\n14           906       1.0\n15           907       1.0\n16           908       0.0\n17           909       0.0\n18           910       0.0\n19           911       0.0\n20           912       0.0\n21           913       0.0\n22           914       1.0\n23           915       1.0\n24           916       1.0\n25           917       0.0\n26           918       1.0\n27           919       0.0\n28           920       1.0\n29           921       0.0\n..           ...       ...\n388         1280       0.0\n389         1281       0.0\n390         1282       0.0\n391         1283       1.0\n392         1284       1.0\n393         1285       1.0\n394         1286       0.0\n395         1287       1.0\n396         1288       1.0\n397         1289       1.0\n398         1290       0.0\n399         1291       0.0\n400         1292       1.0\n401         1293       0.0\n402         1294       1.0\n403         1295      -0.0\n404         1296       0.0\n405         1297       0.0\n406         1298       0.0\n407         1299       0.0\n408         1300       0.0\n409         1301       1.0\n410         1302       1.0\n411         1303       1.0\n412         1304       0.0\n413         1305      -0.0\n414         1306       1.0\n415         1307       0.0\n416         1308      -0.0\n417         1309       1.0\n\n[418 rows x 2 columns]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "testing_ResBNLNN_startup()\n",
    "testing_ResBNLNN_order()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}